{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3b64753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyfaidx import Fasta\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# ================= 1. C·∫§U H√åNH H·ªÜ TH·ªêNG (QUAN TR·ªåNG) =================\n",
    "# H√£y ƒë·∫£m b·∫£o ƒë∆∞·ªùng d·∫´n file ch√≠nh x√°c\n",
    "GTF_FILE = r'D:\\Study\\5-FA25\\AiTa_Lab_Research\\Sequence_GENCODE\\gencode.v49.basic.annotation.gtf'      # File GTF\n",
    "FASTA_FILE = r'D:\\Study\\5-FA25\\AiTa_Lab_Research\\Sequence_GENCODE\\Homo_sapiens.GRCh38.dna.primary_assembly.fa'   # File FASTA\n",
    "OUTPUT_FILE = r'D:\\Study\\5-FA25\\AiTa_Lab_Research\\Sequence_GENCODE\\pre_train_splicing_prediction.csv'       # File k·∫øt qu·∫£ (~9-10GB)\n",
    "\n",
    "# C·∫•u h√¨nh Sequence\n",
    "WINDOW = 300                # B√°n k√≠nh 200bp\n",
    "SEQ_LEN = (WINDOW * 2) + 1  # T·ªïng ƒë·ªô d√†i 401bp (T√¢m t·∫°i index 200)\n",
    "WRITE_BATCH_SIZE = 10000    # Ghi ƒëƒ©a m·ªói 10k d√≤ng ƒë·ªÉ ti·∫øt ki·ªám RAM\n",
    "\n",
    "# C·∫•u h√¨nh T·ªâ l·ªá (Ratio)\n",
    "# B·∫°n mu·ªën 100 Negative : 1 Donor : 1 Acceptor\n",
    "# T·ª©c l√† Negative = 50 l·∫ßn (Donor + Acceptor)\n",
    "NEGATIVE_MULTIPLIER = 50 \n",
    "\n",
    "# Danh s√°ch nhi·ªÖm s·∫Øc th·ªÉ chu·∫©n (B·ªè qua c√°c m·∫£nh contig r√°c ƒë·ªÉ data s·∫°ch)\n",
    "VALID_CHROMS = set([str(i) for i in range(1, 23)] + ['X', 'Y', 'M', 'MT'])\n",
    "\n",
    "# ================= 2. C√ÅC H√ÄM X·ª¨ L√ù C·ªêT L√ïI =================\n",
    "\n",
    "def normalize_chrom(chrom_name):\n",
    "    \"\"\"\n",
    "    Chu·∫©n h√≥a t√™n nhi·ªÖm s·∫Øc th·ªÉ ƒë·ªÉ kh·ªõp gi·ªØa GTF v√† FASTA.\n",
    "    Gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ: 'chr1' vs '1', 'NC_000001' vs '1'.\n",
    "    \"\"\"\n",
    "    s = str(chrom_name).strip()\n",
    "    \n",
    "    # X·ª≠ l√Ω d·∫°ng RefSeq (NC_...)\n",
    "    if s.startswith(\"NC_\"):\n",
    "        try:\n",
    "            val = int(s.split('_')[1].split('.')[0])\n",
    "            if val == 23: return 'X'\n",
    "            if val == 24: return 'Y'\n",
    "            if val == 12920: return 'M'\n",
    "            return str(val)\n",
    "        except: return s\n",
    "        \n",
    "    # X·ª≠ l√Ω d·∫°ng UCSC (chr...)\n",
    "    if s.lower().startswith('chr'):\n",
    "        raw = s[3:]\n",
    "        if raw == 'M': return 'M'\n",
    "        return raw\n",
    "        \n",
    "    return s\n",
    "\n",
    "def get_sequence_strict(genome, raw_chrom, center_pos, strand, window):\n",
    "    \"\"\"\n",
    "    Tr√≠ch xu·∫•t sequence t·∫°i t√¢m (1-based).\n",
    "    Y√™u c·∫ßu: Kh√¥ng padding, kh√¥ng 'N', ƒë·∫£o m·∫°ch n·∫øu l√† Strand (-).\n",
    "    \"\"\"\n",
    "    norm_chrom = normalize_chrom(raw_chrom)\n",
    "    \n",
    "    # T√¨m key t∆∞∆°ng ·ª©ng trong file FASTA\n",
    "    fasta_key = None\n",
    "    if norm_chrom in genome: fasta_key = norm_chrom\n",
    "    elif f\"chr{norm_chrom}\" in genome: fasta_key = f\"chr{norm_chrom}\"\n",
    "    elif norm_chrom == 'M' and 'chrM' in genome: fasta_key = 'chrM'\n",
    "    \n",
    "    if fasta_key is None: return None # Kh√¥ng t√¨m th·∫•y chromosome\n",
    "\n",
    "    # T√≠nh t·ªça ƒë·ªô 0-based\n",
    "    start_idx = center_pos - 1 - window\n",
    "    end_idx = center_pos + window\n",
    "    \n",
    "    # Check bi√™n gi·ªõi\n",
    "    if start_idx < 0 or end_idx >= len(genome[fasta_key]): return None\n",
    "        \n",
    "    try:\n",
    "        seq_obj = genome[fasta_key][start_idx : end_idx]\n",
    "        seq = seq_obj.seq.upper()\n",
    "        \n",
    "        # Check ch·∫•t l∆∞·ª£ng\n",
    "        if len(seq) != (window * 2 + 1): return None\n",
    "        if 'N' in seq: return None # Lo·∫°i b·ªè sequence ch·ª©a N\n",
    "\n",
    "        # ƒê·∫£o m·∫°ch (Reverse Complement) cho Strand (-)\n",
    "        if strand == '-':\n",
    "            mapping = str.maketrans(\"ATCG\", \"TAGC\")\n",
    "            seq = seq.translate(mapping)[::-1]\n",
    "            \n",
    "        return seq\n",
    "    except: return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b2bf555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- GENERATING MASSIVE DATASET (Ratio 100:1:1) ---\n",
      "Target: ~200k Donor, ~200k Acceptor, ~20M Negatives\n",
      "[1/4] Loading Genome (Lazy Load)...\n"
     ]
    }
   ],
   "source": [
    "# ================= 3. CH∆Ø∆†NG TR√åNH CH√çNH (STREAMING) =================\n",
    "\n",
    "print(f\"--- GENERATING MASSIVE DATASET (Ratio 100:1:1) ---\")\n",
    "print(f\"Target: ~200k Donor, ~200k Acceptor, ~20M Negatives\")\n",
    "\n",
    "# 1. Load Resources\n",
    "if not os.path.exists(FASTA_FILE):\n",
    "    print(f\"L·ªñI: Kh√¥ng t√¨m th·∫•y {FASTA_FILE}\"); \n",
    "if not os.path.exists(GTF_FILE):\n",
    "    print(f\"L·ªñI: Kh√¥ng t√¨m th·∫•y {GTF_FILE}\"); \n",
    "print(\"[1/4] Loading Genome (Lazy Load)...\")\n",
    "genome = Fasta(FASTA_FILE, sequence_always_upper=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a5d35cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/4] Parsing GTF...\n",
      "      -> 2241203 exons found.\n"
     ]
    }
   ],
   "source": [
    "print(\"[2/4] Parsing GTF...\")\n",
    "# ƒê·ªçc GTF, l·ªçc l·∫•y Exon c·ªßa Protein Coding Genes\n",
    "df = pd.read_csv(GTF_FILE, sep='\\t', comment='#', header=None, usecols=[0, 2, 3, 4, 6, 8],\n",
    "                    names=['chrom', 'feature', 'start', 'end', 'strand', 'attribute'])\n",
    "df = df[(df['feature'] == 'exon') & (df['attribute'].str.contains('gene_type \"protein_coding\"'))]\n",
    "print(f\"      -> {len(df)} exons found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab2f2167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/4] Processing Positives...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Positives: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2241203/2241203 [03:34<00:00, 10464.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      -> ƒê√£ ghi 496576 m·∫´u Positive s·∫°ch.\n",
      "[4/4] Generating 24828800 Negatives (Ratio 100:1:1)...\n",
      "      L∆∞u √Ω: B∆∞·ªõc n√†y s·∫Ω t·ªën RAM h∆°n ƒë·ªÉ l∆∞u set check tr√πng.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mining Negatives: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 24828773/24828800 [6:25:06<00:00, 942.85it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ HO√ÄN T·∫§T! File saved at: D:\\Study\\5-FA25\\AiTa_Lab_Research\\Sequence_GENCODE\\pre_train_splicing_prediction.csv\n",
      "      Dung l∆∞·ª£ng ∆∞·ªõc t√≠nh: ~9.5 GB\n",
      "      T·ªïng s·ªë d√≤ng: 25325376\n",
      "‚ö†Ô∏è QUAN TR·ªåNG: File n√†y ch∆∞a ƒë∆∞·ª£c shuffle (Positive n·∫±m ƒë·∫ßu, Negative n·∫±m cu·ªëi).\n",
      "   H√£y shuffle khi load v√†o model ho·∫∑c d√πng l·ªánh Linux: 'shuf D:\\Study\\5-FA25\\AiTa_Lab_Research\\Sequence_GENCODE\\pre_train_splicing_prediction.csv > shuffled.csv'\n"
     ]
    }
   ],
   "source": [
    "# M·ªü file CSV ƒë·ªÉ ghi lu·ªìng (Stream Writing)\n",
    "with open(OUTPUT_FILE, 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['id', 'dna', 'label']) # Header\n",
    "\n",
    "    # --- B∆Ø·ªöC 3: X·ª¨ L√ù POSITIVE (Labels 1 & 2) ---\n",
    "    print(\"[3/4] Processing Positives...\")\n",
    "    seen_sites = set() # Set kh·ª≠ tr√πng l·∫∑p\n",
    "    pos_buffer = []    # B·ªô nh·ªõ ƒë·ªám t·∫°m th·ªùi\n",
    "    total_positives = 0\n",
    "    \n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Positives\"):\n",
    "        raw_chrom = row['chrom']\n",
    "        norm_chrom = normalize_chrom(raw_chrom)\n",
    "        if norm_chrom not in VALID_CHROMS: continue\n",
    "        strand = row['strand']\n",
    "\n",
    "        # T√≠nh t·ªça ƒë·ªô t√¢m (Center at G)\n",
    "        if strand == '+':\n",
    "            donor_center = row['end'] + 1\n",
    "            acc_center = row['start'] - 1\n",
    "        else:\n",
    "            donor_center = row['start'] - 1\n",
    "            acc_center = row['end'] + 1\n",
    "\n",
    "        # --- LABEL 1: DONOR (GT & GC) ---\n",
    "        if (norm_chrom, donor_center, strand, 1) not in seen_sites:\n",
    "            seq = get_sequence_strict(genome, raw_chrom, donor_center, strand, WINDOW)\n",
    "            if seq:\n",
    "                # Ki·ªÉm tra t√¢m: Ch·∫•p nh·∫≠n GT v√† GC\n",
    "                center_motif = seq[WINDOW : WINDOW+2]\n",
    "                if center_motif in ['GT', 'GC']:\n",
    "                    pos_buffer.append([f\"Donor_{norm_chrom}_{donor_center}_{strand}\", seq, 1])\n",
    "                    seen_sites.add((norm_chrom, donor_center, strand, 1))\n",
    "                    total_positives += 1\n",
    "\n",
    "        # --- LABEL 2: ACCEPTOR (AG) ---\n",
    "        if (norm_chrom, acc_center, strand, 2) not in seen_sites:\n",
    "            seq = get_sequence_strict(genome, raw_chrom, acc_center, strand, WINDOW)\n",
    "            if seq:\n",
    "                # Ki·ªÉm tra t√¢m: Ch·∫•p nh·∫≠n AG\n",
    "                center_motif = seq[WINDOW-1 : WINDOW+1]\n",
    "                if center_motif == 'AG':\n",
    "                    pos_buffer.append([f\"Acc_{norm_chrom}_{acc_center}_{strand}\", seq, 2])\n",
    "                    seen_sites.add((norm_chrom, acc_center, strand, 2))\n",
    "                    total_positives += 1\n",
    "        \n",
    "        # Ghi v√†o ƒëƒ©a khi buffer ƒë·∫ßy (tr√°nh t·ªën RAM)\n",
    "        if len(pos_buffer) >= WRITE_BATCH_SIZE:\n",
    "            writer.writerows(pos_buffer)\n",
    "            pos_buffer = [] \n",
    "\n",
    "    # Ghi n·ªët ph·∫ßn d∆∞\n",
    "    if pos_buffer:\n",
    "        writer.writerows(pos_buffer)\n",
    "        pos_buffer = [] # Clear RAM ho√†n to√†n\n",
    "        \n",
    "    print(f\"      -> ƒê√£ ghi {total_positives} m·∫´u Positive s·∫°ch.\")\n",
    "    \n",
    "# --- B∆Ø·ªöC 4: SINH D·ªÆ LI·ªÜU NEGATIVE KH·ªîNG L·ªí (ƒê√É S·ª¨A L·ªñI DUPLICATE) ---\n",
    "    target_neg = total_positives * NEGATIVE_MULTIPLIER\n",
    "    print(f\"[4/4] Generating {target_neg} Negatives (Ratio 100:1:1)...\")\n",
    "    print(\"      L∆∞u √Ω: B∆∞·ªõc n√†y s·∫Ω t·ªën RAM h∆°n ƒë·ªÉ l∆∞u set check tr√πng.\")\n",
    "    \n",
    "    neg_count = 0\n",
    "    neg_buffer = []\n",
    "    \n",
    "    # Iterator tu·∫ßn ho√†n\n",
    "    df_sample = df.sample(frac=1).reset_index(drop=True)\n",
    "    iter_rows = iter(df_sample.iterrows())\n",
    "    \n",
    "    pbar = tqdm(total=target_neg, desc=\"Mining Negatives\")\n",
    "    \n",
    "    while neg_count < target_neg:\n",
    "        try:\n",
    "            _, row = next(iter_rows)\n",
    "        except StopIteration:\n",
    "            df_sample = df.sample(frac=1).reset_index(drop=True)\n",
    "            iter_rows = iter(df_sample.iterrows())\n",
    "            _, row = next(iter_rows)\n",
    "        \n",
    "        raw_chrom = row['chrom']\n",
    "        norm_chrom = normalize_chrom(raw_chrom)\n",
    "        if norm_chrom not in VALID_CHROMS: continue\n",
    "        strand = row['strand']\n",
    "        \n",
    "        # Random v·ªã tr√≠\n",
    "        rand_pos = random.randint(row['start'] - 10000, row['end'] + 10000)\n",
    "        \n",
    "        # --- [S·ª¨A ƒê·ªîI QUAN TR·ªåNG] ---\n",
    "        # T·∫°o key ƒë·∫°i di·ªán cho m·∫´u Negative ƒë·ªãnh l·∫•y\n",
    "        neg_key = (norm_chrom, rand_pos, strand, 0)\n",
    "        \n",
    "        # 1. Check tr√πng Positive (Site th·∫≠t)\n",
    "        if (norm_chrom, rand_pos, strand, 1) in seen_sites or \\\n",
    "           (norm_chrom, rand_pos, strand, 2) in seen_sites:\n",
    "            continue\n",
    "\n",
    "        # 2. Check tr√πng Negative ƒë√£ l·∫•y tr∆∞·ªõc ƒë√≥ (FIX BUG DUPLICATE)\n",
    "        if neg_key in seen_sites:\n",
    "            continue\n",
    "        # ----------------------------\n",
    "\n",
    "        seq = get_sequence_strict(genome, raw_chrom, rand_pos, strand, WINDOW)\n",
    "        if not seq: continue\n",
    "        \n",
    "        # Hard Negative Check\n",
    "        center = seq[WINDOW]\n",
    "        next_b = seq[WINDOW+1]\n",
    "        prev_b = seq[WINDOW-1]\n",
    "        \n",
    "        is_fake_donor = (center == 'G' and next_b in ['T', 'C'])\n",
    "        is_fake_acc   = (prev_b == 'A' and center == 'G')\n",
    "        \n",
    "        if is_fake_donor or is_fake_acc:\n",
    "            neg_buffer.append([f\"Neg_{norm_chrom}_{rand_pos}_{strand}\", seq, 0])\n",
    "            \n",
    "            # --- [TH√äM M·ªöI] ƒê√°nh d·∫•u ƒë√£ s·ª≠ d·ª•ng ---\n",
    "            seen_sites.add(neg_key) \n",
    "            # --------------------------------------\n",
    "\n",
    "            neg_count += 1\n",
    "            pbar.update(1)\n",
    "            \n",
    "            if len(neg_buffer) >= WRITE_BATCH_SIZE:\n",
    "                writer.writerows(neg_buffer)\n",
    "                neg_buffer = []\n",
    "\n",
    "    # Ghi n·ªët ph·∫ßn cu·ªëi\n",
    "    if neg_buffer:\n",
    "        writer.writerows(neg_buffer)\n",
    "\n",
    "print(f\"‚úÖ HO√ÄN T·∫§T! File saved at: {OUTPUT_FILE}\")\n",
    "print(f\"      Dung l∆∞·ª£ng ∆∞·ªõc t√≠nh: ~9.5 GB\")\n",
    "print(f\"      T·ªïng s·ªë d√≤ng: {total_positives + neg_count}\")\n",
    "print(f\"‚ö†Ô∏è QUAN TR·ªåNG: File n√†y ch∆∞a ƒë∆∞·ª£c shuffle (Positive n·∫±m ƒë·∫ßu, Negative n·∫±m cu·ªëi).\")\n",
    "print(f\"   H√£y shuffle khi load v√†o model ho·∫∑c d√πng l·ªánh Linux: 'shuf {OUTPUT_FILE} > shuffled.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21830b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ ƒêang x·ª≠ l√Ω file: D:\\Study\\5-FA25\\AiTa_Lab_Research\\Sequence_GENCODE\\pre_train_splicing_prediction.csv\n",
      "   - ƒê·ªïi t√™n c·ªôt: {'label': 'Splicing_types', 'dna': 'sequence'}\n",
      "   - Th√™m/Update c·ªôt: CHROM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows: 25325376 rows [08:53, 47475.31 rows/s]:25:19<00:00, 942.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ HO√ÄN T·∫§T! File ƒë√£ ƒë∆∞·ª£c c·∫≠p nh·∫≠t.\n",
      "   Header m·ªõi: ['id', 'sequence', 'Splicing_types', 'CHROM']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- C·∫§U H√åNH ---\n",
    "TARGET_FILE = r'D:\\Study\\5-FA25\\AiTa_Lab_Research\\Sequence_GENCODE\\pre_train_splicing_prediction.csv'\n",
    "TEMP_FILE = TARGET_FILE + '.tmp'\n",
    "NEW_CHROM_COL = 'CHROM'\n",
    "\n",
    "# Map ƒë·ªïi t√™n: {'T√™n c≈©': 'T√™n m·ªõi'}\n",
    "RENAME_MAP = {\n",
    "    'label': 'Splicing_types',\n",
    "    'dna': 'sequence'\n",
    "}\n",
    "\n",
    "print(f\"üîÑ ƒêang x·ª≠ l√Ω file: {TARGET_FILE}\")\n",
    "print(f\"   - ƒê·ªïi t√™n c·ªôt: {RENAME_MAP}\")\n",
    "print(f\"   - Th√™m/Update c·ªôt: {NEW_CHROM_COL}\")\n",
    "\n",
    "try:\n",
    "    with open(TARGET_FILE, 'r', encoding='utf-8') as f_in, \\\n",
    "         open(TEMP_FILE, 'w', encoding='utf-8', newline='') as f_out:\n",
    "        \n",
    "        reader = csv.reader(f_in)\n",
    "        writer = csv.writer(f_out)\n",
    "        \n",
    "        # 1. X·ª¨ L√ù HEADER (ƒê·ªïi t√™n & Th√™m c·ªôt)\n",
    "        try:\n",
    "            original_header = next(reader)\n",
    "        except StopIteration:\n",
    "            print(\"‚ùå File r·ªóng!\")\n",
    "            raise Exception(\"File empty\")\n",
    "            \n",
    "        # B∆∞·ªõc A: ƒê·ªïi t√™n c√°c c·ªôt c≈© (label -> Splicing_types, dna -> sequence)\n",
    "        renamed_header = [RENAME_MAP.get(col, col) for col in original_header]\n",
    "        \n",
    "        # B∆∞·ªõc B: Ki·ªÉm tra c·ªôt CHROM\n",
    "        if NEW_CHROM_COL in renamed_header:\n",
    "            print(f\"‚ö†Ô∏è C·ªôt '{NEW_CHROM_COL}' ƒë√£ t·ªìn t·∫°i -> S·∫Ω c·∫≠p nh·∫≠t d·ªØ li·ªáu.\")\n",
    "            final_header = renamed_header\n",
    "            chrom_idx = renamed_header.index(NEW_CHROM_COL)\n",
    "        else:\n",
    "            final_header = renamed_header + [NEW_CHROM_COL]\n",
    "            chrom_idx = None # Ch∆∞a c√≥, s·∫Ω append v√†o cu·ªëi\n",
    "            \n",
    "        writer.writerow(final_header)\n",
    "        \n",
    "        # 2. X·ª¨ L√ù D·ªÆ LI·ªÜU (Streaming)\n",
    "        for row in tqdm(reader, desc=\"Processing Rows\", unit=\" rows\"):\n",
    "            if not row: continue\n",
    "            \n",
    "            # Logic l·∫•y Chromosome t·ª´ ID (Donor_1_65434_+)\n",
    "            row_id = row[0]\n",
    "            try:\n",
    "                parts = row_id.split('_')\n",
    "                if len(parts) > 1:\n",
    "                    raw_chrom = parts[1]\n",
    "                    # Format: chr1, chr2, chrX...\n",
    "                    chrom_val = raw_chrom if raw_chrom.startswith('chr') else f\"chr{raw_chrom}\"\n",
    "                else:\n",
    "                    chrom_val = \"unknown\"\n",
    "                \n",
    "                # Logic ghi v√†o d√≤ng\n",
    "                if chrom_idx is not None:\n",
    "                    # N·∫øu c·ªôt CHROM ƒë√£ c√≥ s·∫µn (do ch·∫°y l·∫°i nhi·ªÅu l·∫ßn) -> Ghi ƒë√®\n",
    "                    if len(row) > chrom_idx:\n",
    "                        row[chrom_idx] = chrom_val\n",
    "                    else:\n",
    "                        row.append(chrom_val)\n",
    "                    writer.writerow(row)\n",
    "                else:\n",
    "                    # N·∫øu ch∆∞a c√≥ -> Th√™m m·ªõi v√†o cu·ªëi\n",
    "                    writer.writerow(row + [chrom_val])\n",
    "                    \n",
    "            except Exception:\n",
    "                # Fallback an to√†n cho d√≤ng l·ªói\n",
    "                writer.writerow(row + (['unknown'] if chrom_idx is None else []))\n",
    "\n",
    "    # 3. Thay th·∫ø file c≈©\n",
    "    os.replace(TEMP_FILE, TARGET_FILE)\n",
    "    print(f\"‚úÖ HO√ÄN T·∫§T! File ƒë√£ ƒë∆∞·ª£c c·∫≠p nh·∫≠t.\")\n",
    "    print(f\"   Header m·ªõi: {final_header}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y file '{TARGET_FILE}'.\")\n",
    "except Exception as e:\n",
    "    if os.path.exists(TEMP_FILE): os.remove(TEMP_FILE)\n",
    "    print(f\"‚ùå L·ªói Runtime: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d9844c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ B·∫ÆT ƒê·∫¶U KI·ªÇM TRA FILE (C·∫§U TR√öC M·ªöI): D:\\Study\\5-FA25\\AiTa_Lab_Research\\Sequence_GENCODE\\pre_train_splicing_prediction.csv\n",
      "   -> Header t√¨m th·∫•y: ['id', 'sequence', 'Splicing_types', 'CHROM']\n",
      "   -> Mapping index: Seq=1, Label=2, Chrom=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing: 25325376 rows [03:36, 116985.01 rows/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìä B√ÅO C√ÅO D·ªÆ LI·ªÜU (Time: 216.53s | Total: 25,325,376 rows)\n",
      "================================================================================\n",
      "\n",
      "1. M·∫™U D·ªÆ LI·ªÜU (5 d√≤ng ƒë·∫ßu):\n",
      "   ID                        | Sequence (Preview)   | Type       | Chrom   \n",
      "   ------------------------- | -------------------- | ---------- | --------\n",
      "   Donor_1_65434_+           | AAAAGT...TTAA        | 1          | chr1    \n",
      "   Donor_1_65574_+           | GATAGC...TTCC        | 1          | chr1    \n",
      "   Acc_1_65519_+             | CTTTAT...CTCC        | 2          | chr1    \n",
      "   Acc_1_69036_+             | AAAGGA...GCGC        | 2          | chr1    \n",
      "   Donor_1_924949_+          | ACCTCA...GAGC        | 1          | chr1    \n",
      "\n",
      "2. KI·ªÇM TRA NULL (COMPLETENESS):\n",
      "   T√™n C·ªôt              | S·ªë Null    | % L·ªói\n",
      "   id                   | ‚úÖ          | 0.0000%\n",
      "   sequence             | ‚úÖ          | 0.0000%\n",
      "   Splicing_types       | ‚úÖ          | 0.0000%\n",
      "   CHROM                | ‚úÖ          | 0.0000%\n",
      "   -> S·∫°ch 100%.\n",
      "\n",
      "3. PH√ÇN B·ªê TYPE (Splicing_types):\n",
      "   - '1': 250,830 m·∫´u\n",
      "   - '2': 245,746 m·∫´u\n",
      "   - '0': 24,828,800 m·∫´u\n",
      "\n",
      "4. PH√ÇN B·ªê CHROMOSOME (Top 5):\n",
      "   - chr1: 2,532,052 m·∫´u\n",
      "   - chr2: 1,963,427 m·∫´u\n",
      "   - chr3: 1,651,569 m·∫´u\n",
      "   - chr11: 1,477,481 m·∫´u\n",
      "   - chr19: 1,467,852 m·∫´u\n",
      "   ... v√† 19 chrom kh√°c.\n",
      "\n",
      "5. SEQUENCE LENGTH:\n",
      "   - Length 601: 25,325,376 m·∫´u (‚úÖ Chu·∫©n)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import sys\n",
    "import time\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ================= C·∫§U H√åNH =================\n",
    "# S·ª≠a ƒë∆∞·ªùng d·∫´n file n·∫øu c·∫ßn\n",
    "FILE_PATH = r'D:\\Study\\5-FA25\\AiTa_Lab_Research\\Sequence_GENCODE\\pre_train_splicing_prediction.csv'\n",
    "SAMPLE_ROWS = 5  # S·ªë d√≤ng in m·∫´u\n",
    "\n",
    "def inspect_and_validate_full(file_path):\n",
    "    print(f\"üöÄ B·∫ÆT ƒê·∫¶U KI·ªÇM TRA FILE (C·∫§U TR√öC M·ªöI): {file_path}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 1. BI·∫æN TH·ªêNG K√ä\n",
    "    stats = {\n",
    "        \"total_rows\": 0,\n",
    "        \"null_counts\": {},\n",
    "        \"seq_lengths\": Counter(),      # Th·ªëng k√™ ƒë·ªô d√†i sequence\n",
    "        \"label_counts\": Counter(),     # Th·ªëng k√™ Splicing_types\n",
    "        \"chrom_counts\": Counter(),     # Th·ªëng k√™ CHROM (M·ªõi)\n",
    "        \"samples\": []\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            reader = csv.reader(f)\n",
    "            \n",
    "            # --- 2. ƒê·ªåC & MAP HEADER ---\n",
    "            try:\n",
    "                header = next(reader)\n",
    "                # Kh·ªüi t·∫°o ƒë·∫øm null\n",
    "                for col in header: stats[\"null_counts\"][col] = 0\n",
    "                \n",
    "                # T√¨m v·ªã tr√≠ (index) c·ªßa c√°c c·ªôt quan tr·ªçng theo t√™n m·ªõi\n",
    "                # D√πng next(..., None) ƒë·ªÉ tr√°nh l·ªói n·∫øu kh√¥ng t√¨m th·∫•y c·ªôt\n",
    "                idx_seq = next((i for i, c in enumerate(header) if c in ['sequence', 'dna']), None)\n",
    "                idx_lbl = next((i for i, c in enumerate(header) if c in ['Splicing_types', 'label']), None)\n",
    "                idx_chr = next((i for i, c in enumerate(header) if c in ['CHROM', 'chrom']), None)\n",
    "                \n",
    "                print(f\"   -> Header t√¨m th·∫•y: {header}\")\n",
    "                print(f\"   -> Mapping index: Seq={idx_seq}, Label={idx_lbl}, Chrom={idx_chr}\")\n",
    "                \n",
    "            except StopIteration:\n",
    "                print(\"‚ùå L·ªñI: File r·ªóng!\")\n",
    "                return\n",
    "\n",
    "            # --- 3. QU√âT D·ªÆ LI·ªÜU (SINGLE PASS) ---\n",
    "            pbar = tqdm(reader, desc=\"Analyzing\", unit=\" rows\")\n",
    "            \n",
    "            for i, row in enumerate(pbar):\n",
    "                stats[\"total_rows\"] += 1\n",
    "                \n",
    "                # A. L·∫§Y M·∫™U\n",
    "                if i < SAMPLE_ROWS:\n",
    "                    stats[\"samples\"].append(row)\n",
    "                \n",
    "                # B. CHECK NULL & VALIDATE\n",
    "                for col_idx, val in enumerate(row):\n",
    "                    if col_idx >= len(header): break\n",
    "                    if not val.strip():\n",
    "                        col_name = header[col_idx]\n",
    "                        stats[\"null_counts\"][col_name] += 1\n",
    "                \n",
    "                # C. TH·ªêNG K√ä GI√Å TR·ªä (D·ª±a tr√™n index ƒë√£ map)\n",
    "                if idx_seq is not None and len(row) > idx_seq:\n",
    "                    stats[\"seq_lengths\"][len(row[idx_seq])] += 1\n",
    "                    \n",
    "                if idx_lbl is not None and len(row) > idx_lbl:\n",
    "                    stats[\"label_counts\"][row[idx_lbl]] += 1\n",
    "                    \n",
    "                if idx_chr is not None and len(row) > idx_chr:\n",
    "                    stats[\"chrom_counts\"][row[idx_chr]] += 1\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y file {file_path}\")\n",
    "        return\n",
    "\n",
    "    # --- 4. B√ÅO C√ÅO K·∫æT QU·∫¢ ---\n",
    "    elapsed = time.time() - start_time\n",
    "    total = stats[\"total_rows\"]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"üìä B√ÅO C√ÅO D·ªÆ LI·ªÜU (Time: {elapsed:.2f}s | Total: {total:,} rows)\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # 4.1 B·∫£ng m·∫´u (C·∫≠p nh·∫≠t 4 c·ªôt)\n",
    "    print(f\"\\n1. M·∫™U D·ªÆ LI·ªÜU ({SAMPLE_ROWS} d√≤ng ƒë·∫ßu):\")\n",
    "    # Format in: ID | Sequence | Type | Chrom\n",
    "    print(f\"   {'ID':<25} | {'Sequence (Preview)':<20} | {'Type':<10} | {'Chrom':<8}\")\n",
    "    print(f\"   {'-'*25} | {'-'*20} | {'-'*10} | {'-'*8}\")\n",
    "    \n",
    "    for row in stats[\"samples\"]:\n",
    "        # L·∫•y gi√° tr·ªã an to√†n (ph√≤ng tr∆∞·ªùng h·ª£p d√≤ng thi·∫øu c·ªôt)\n",
    "        _id = row[0] if len(row) > 0 else \"\"\n",
    "        _seq = row[idx_seq] if idx_seq is not None and len(row) > idx_seq else \"N/A\"\n",
    "        _lbl = row[idx_lbl] if idx_lbl is not None and len(row) > idx_lbl else \"N/A\"\n",
    "        _chr = row[idx_chr] if idx_chr is not None and len(row) > idx_chr else \"N/A\"\n",
    "        \n",
    "        # C·∫Øt ng·∫Øn sequence\n",
    "        seq_show = _seq[:6] + \"...\" + _seq[-4:] if len(_seq) > 10 else _seq\n",
    "        print(f\"   {_id:<25} | {seq_show:<20} | {_lbl:<10} | {_chr:<8}\")\n",
    "\n",
    "    # 4.2 B√°o c√°o Null\n",
    "    print(f\"\\n2. KI·ªÇM TRA NULL (COMPLETENESS):\")\n",
    "    has_null = False\n",
    "    print(f\"   {'T√™n C·ªôt':<20} | {'S·ªë Null':<10} | {'% L·ªói'}\")\n",
    "    for col, count in stats[\"null_counts\"].items():\n",
    "        pct = (count / total * 100) if total > 0 else 0\n",
    "        status = \"‚úÖ\" if count == 0 else f\"‚ùå {count:,}\"\n",
    "        print(f\"   {col:<20} | {status:<10} | {pct:.4f}%\")\n",
    "        if count > 0: has_null = True\n",
    "    if not has_null: print(\"   -> S·∫°ch 100%.\")\n",
    "\n",
    "    # 4.3 Ph√¢n b·ªë Label\n",
    "    print(f\"\\n3. PH√ÇN B·ªê TYPE (Splicing_types):\")\n",
    "    for lbl, count in stats[\"label_counts\"].items():\n",
    "        print(f\"   - '{lbl}': {count:,} m·∫´u\")\n",
    "\n",
    "    # 4.4 Ph√¢n b·ªë Chrom (M·ªõi)\n",
    "    print(f\"\\n4. PH√ÇN B·ªê CHROMOSOME (Top 5):\")\n",
    "    # Ch·ªâ in 5 chrom ph·ªï bi·∫øn nh·∫•t ƒë·ªÉ ƒë·ª° d√†i d√≤ng\n",
    "    for ch, count in stats[\"chrom_counts\"].most_common(5):\n",
    "        print(f\"   - {ch}: {count:,} m·∫´u\")\n",
    "    if len(stats[\"chrom_counts\"]) > 5: print(f\"   ... v√† {len(stats['chrom_counts'])-5} chrom kh√°c.\")\n",
    "\n",
    "    # 4.5 Sequence Length\n",
    "    print(f\"\\n5. SEQUENCE LENGTH:\")\n",
    "    for length, count in stats[\"seq_lengths\"].items():\n",
    "        status = \"‚úÖ Chu·∫©n\" if length == 601 else \"‚ö†Ô∏è L·ªÜCH\"\n",
    "        print(f\"   - Length {length}: {count:,} m·∫´u ({status})\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    inspect_and_validate_full(FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0514964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß¨ B·∫ÆT ƒê·∫¶U KI·ªÇM TRA LOGIC SINH H·ªåC: D:\\Study\\5-FA25\\AiTa_Lab_Research\\Sequence_GENCODE\\pre_train_splicing_prediction.csv\n",
      "   -> Mapping OK: Seq=1, Label=2, Chrom=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bio-Checking: 25325376 rows [05:15, 80376.29 rows/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üî¨ K·∫æT QU·∫¢ KI·ªÇM TRA SINH H·ªåC (25,325,376 m·∫´u)\n",
      "============================================================\n",
      "1. T·ª™ V·ª∞NG DNA (Ch·ªâ A,C,G,T,N): ‚úÖ S·∫°ch\n",
      "2. MOTIF CONSISTENCY (GT/AG): ‚úÖ Chu·∫©n x√°c\n",
      "3. CHROMOSOME COVERAGE:\n",
      "   - T√¨m th·∫•y 24 nhi·ªÖm s·∫Øc th·ªÉ.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import sys\n",
    "import time\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ================= C·∫§U H√åNH =================\n",
    "FILE_PATH = r'D:\\Study\\5-FA25\\AiTa_Lab_Research\\Sequence_GENCODE\\pre_train_splicing_prediction.csv'\n",
    "WINDOW = 300 # B√°n k√≠nh nh∆∞ thi·∫øt l·∫≠p ban ƒë·∫ßu\n",
    "CENTER_IDX = WINDOW # V·ªã tr√≠ t√¢m (300)\n",
    "\n",
    "def validate_biological_data(file_path):\n",
    "    print(f\"üß¨ B·∫ÆT ƒê·∫¶U KI·ªÇM TRA LOGIC SINH H·ªåC: {file_path}\")\n",
    "    \n",
    "    stats = {\n",
    "        \"total\": 0,\n",
    "        \"invalid_chars\": 0,   # Sequence ch·ª©a k√Ω t·ª± l·∫°\n",
    "        \"motif_errors\": 0,    # Sai Motif (Donor k ph·∫£i GT, Acc k ph·∫£i AG)\n",
    "        \"label_dist\": Counter(),\n",
    "        \"chrom_dist\": Counter()\n",
    "    }\n",
    "    \n",
    "    valid_bases = set(\"ACGTN\")\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            reader = csv.reader(f)\n",
    "            header = next(reader, None)\n",
    "            \n",
    "            # Map index c·ªôt (ƒë·ªÉ code ch·∫°y ƒë√∫ng d√π c·ªôt ƒë·ªïi ch·ªó)\n",
    "            # T√¨m c·ªôt theo t√™n m·ªõi ho·∫∑c c≈©\n",
    "            try:\n",
    "                idx_seq = next(i for i, c in enumerate(header) if c in ['sequence', 'dna'])\n",
    "                idx_lbl = next(i for i, c in enumerate(header) if c in ['Splicing_types', 'label'])\n",
    "                idx_chr = next(i for i, c in enumerate(header) if c in ['CHROM', 'chrom'])\n",
    "            except StopIteration:\n",
    "                print(\"‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y ƒë·ªß c√°c c·ªôt sequence, label, CHROM!\")\n",
    "                return\n",
    "\n",
    "            print(f\"   -> Mapping OK: Seq={idx_seq}, Label={idx_lbl}, Chrom={idx_chr}\")\n",
    "\n",
    "            # QU√âT D·ªÆ LI·ªÜU\n",
    "            for row in tqdm(reader, desc=\"Bio-Checking\", unit=\" rows\"):\n",
    "                if not row: continue\n",
    "                stats[\"total\"] += 1\n",
    "                \n",
    "                seq = row[idx_seq]\n",
    "                label = row[idx_lbl]\n",
    "                chrom = row[idx_chr]\n",
    "                \n",
    "                stats[\"label_dist\"][label] += 1\n",
    "                stats[\"chrom_dist\"][chrom] += 1\n",
    "                \n",
    "                # 1. CHECK K√ù T·ª∞ L·∫† (Vocabulary)\n",
    "                # D√πng set check cho nhanh\n",
    "                if not set(seq).issubset(valid_bases):\n",
    "                    stats[\"invalid_chars\"] += 1\n",
    "\n",
    "                # 2. CHECK MOTIF SINH H·ªåC (Quan tr·ªçng!)\n",
    "                # Ch·ªâ check n·∫øu ƒë·ªô d√†i sequence ƒë√∫ng 601\n",
    "                if len(seq) == (WINDOW * 2 + 1):\n",
    "                    # Donor (Label 1): T√¢m ph·∫£i l√† GT ho·∫∑c GC\n",
    "                    # Logic c·∫Øt: seq[300:302]\n",
    "                    if label == '1':\n",
    "                        motif = seq[CENTER_IDX : CENTER_IDX+2]\n",
    "                        if motif not in ['GT', 'GC']:\n",
    "                            stats[\"motif_errors\"] += 1\n",
    "                            \n",
    "                    # Acceptor (Label 2): T√¢m ph·∫£i l√† AG\n",
    "                    # Logic c·∫Øt: seq[299:301] (V√¨ AG n·∫±m ngay tr∆∞·ªõc exon)\n",
    "                    elif label == '2':\n",
    "                        motif = seq[CENTER_IDX-1 : CENTER_IDX+1]\n",
    "                        if motif != 'AG':\n",
    "                            stats[\"motif_errors\"] += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå L·ªói Runtime: {e}\")\n",
    "        return\n",
    "\n",
    "    # B√ÅO C√ÅO\n",
    "    total = stats[\"total\"]\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"üî¨ K·∫æT QU·∫¢ KI·ªÇM TRA SINH H·ªåC ({total:,} m·∫´u)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 1. K√Ω t·ª± l·∫°\n",
    "    status_char = \"‚úÖ S·∫°ch\" if stats[\"invalid_chars\"] == 0 else f\"‚ùå {stats['invalid_chars']:,} m·∫´u l·ªói\"\n",
    "    print(f\"1. T·ª™ V·ª∞NG DNA (Ch·ªâ A,C,G,T,N): {status_char}\")\n",
    "    \n",
    "    # 2. Motif\n",
    "    # L∆∞u √Ω: N·∫øu Motif l·ªói nhi·ªÅu -> Code sinh d·ªØ li·ªáu b·ªã l·ªách index slicing\n",
    "    pct_motif = (stats[\"motif_errors\"] / total * 100)\n",
    "    status_motif = \"‚úÖ Chu·∫©n x√°c\" if pct_motif < 1.0 else f\"‚ö†Ô∏è ƒê√ÅNG NG·ªú ({stats['motif_errors']:,} m·∫´u sai motif)\"\n",
    "    print(f\"2. MOTIF CONSISTENCY (GT/AG): {status_motif}\")\n",
    "    if stats[\"motif_errors\"] > 0:\n",
    "        print(\"   (N·∫øu s·ªë l∆∞·ª£ng l·ªói motif qu√° l·ªõn, h√£y ki·ªÉm tra l·∫°i logic c·∫Øt chu·ªói!)\")\n",
    "\n",
    "    # 3. Chromosome Check\n",
    "    print(f\"3. CHROMOSOME COVERAGE:\")\n",
    "    print(f\"   - T√¨m th·∫•y {len(stats['chrom_dist'])} nhi·ªÖm s·∫Øc th·ªÉ.\")\n",
    "    # In c·∫£nh b√°o n·∫øu thi·∫øu chr1 (th∆∞·ªùng l√† do file GTF l·ªói ho·∫∑c filter sai)\n",
    "    if 'chr1' not in stats['chrom_dist']:\n",
    "        print(\"   ‚ö†Ô∏è C·∫¢NH B√ÅO: Kh√¥ng th·∫•y d·ªØ li·ªáu t·ª´ chr1!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    validate_biological_data(FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb372bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ B·∫ÆT ƒê·∫¶U KI·ªÇM TRA FILE: D:\\Study\\5-FA25\\AiTa_Lab_Research\\Sequence_GENCODE\\pre_train_splicing_prediction.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning: 25325376 rows [03:28, 121466.89 rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "üìä B·∫¢NG TH·ªêNG K√ä D·ªÆ LI·ªÜU (Time: 208.51s)\n",
      "========================================\n",
      "1. T·ªîNG QUAN:\n",
      "   - T·ªïng s·ªë d√≤ng: 25,325,376\n",
      "   - Null rows   : 0  (0.0000%)\n",
      "   - Duplicate ID: 0\n",
      "\n",
      "2. VALUE COUNT & CLASS STATISTICS:\n",
      "   Label      | Count           | Percentage\n",
      "   ---------- | --------------- | ----------\n",
      "   0 (Neg)    | 24,828,800      | 98.0392%\n",
      "   1 (Donor)  | 250,830         | 0.9904%\n",
      "   2 (Acc)    | 245,746         | 0.9704%\n",
      "========================================\n",
      "‚úÖ D·ªØ li·ªáu S·∫†CH (Kh√¥ng Null, Kh√¥ng Tr√πng).\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import sys\n",
    "import time\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "# C·∫§U H√åNH FILE\n",
    "FILE_PATH = r'D:\\Study\\5-FA25\\AiTa_Lab_Research\\Sequence_GENCODE\\pre_train_splicing_prediction.csv'\n",
    "MAX_RAM_IDS = 30_000_000  # Gi·ªõi h·∫°n l∆∞u 30 tri·ªáu ID ƒë·ªÉ tr√°nh tr√†n RAM\n",
    "\n",
    "def check_data_stats(file_path):\n",
    "    print(f\"üöÄ B·∫ÆT ƒê·∫¶U KI·ªÇM TRA FILE: {file_path}\")\n",
    "    \n",
    "    # 1. Kh·ªüi t·∫°o bi·∫øn ƒë·∫øm\n",
    "    stats = {\n",
    "        \"total_rows\": 0,\n",
    "        \"null_rows\": 0,       # D√≤ng c√≥ gi√° tr·ªã r·ªóng\n",
    "        \"duplicate_ids\": 0,   # ID b·ªã tr√πng\n",
    "    }\n",
    "    label_counts = Counter()  # ƒê·∫øm Value Count cho Label\n",
    "    seen_ids = set()          # Set l∆∞u ID ƒë·ªÉ check tr√πng\n",
    "    check_dup = True          # C·ªù b·∫≠t/t·∫Øt check tr√πng (b·∫£o v·ªá RAM)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            reader = csv.reader(f)\n",
    "            header = next(reader, None) # B·ªè qua header\n",
    "            \n",
    "            # Streaming Loop (ƒê·ªçc t·ª´ng d√≤ng -> X·ª≠ l√Ω -> X√≥a kh·ªèi RAM)\n",
    "            for row in tqdm(reader, desc=\"Scanning\", unit=\" rows\"):\n",
    "                stats[\"total_rows\"] += 1\n",
    "                \n",
    "                # Check c·∫•u tr√∫c c∆° b·∫£n (ƒë·ªÉ tr√°nh l·ªói index)\n",
    "                if len(row) < 3: continue \n",
    "                _id, _dna, _label = row[0], row[1], row[2]\n",
    "\n",
    "                # --- 1. CHECK NULL ---\n",
    "                if not _id.strip() or not _dna.strip() or not _label.strip():\n",
    "                    stats[\"null_rows\"] += 1\n",
    "\n",
    "                # --- 2. CHECK DUPLICATE ID ---\n",
    "                if check_dup:\n",
    "                    if _id in seen_ids:\n",
    "                        stats[\"duplicate_ids\"] += 1\n",
    "                    else:\n",
    "                        seen_ids.add(_id)\n",
    "                    \n",
    "                    # C∆° ch·∫ø an to√†n: T·ª± ng·∫Øt check l·∫∑p n·∫øu ID qu√° nhi·ªÅu (>30 tri·ªáu)\n",
    "                    if len(seen_ids) > MAX_RAM_IDS:\n",
    "                        print(\"‚ö†Ô∏è RAM Warning: T·∫°m d·ª´ng check Duplicate ƒë·ªÉ b·∫£o v·ªá m√°y.\")\n",
    "                        check_dup = False\n",
    "                        seen_ids.clear() # Gi·∫£i ph√≥ng RAM\n",
    "\n",
    "                # --- 3. VALUE COUNT (ƒê·∫øm Label) ---\n",
    "                label_counts[_label] += 1\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y file csv.\")\n",
    "        return\n",
    "\n",
    "    # --- 4. TH·ªêNG K√ä CLASS (B√ÅO C√ÅO) ---\n",
    "    total = stats[\"total_rows\"]\n",
    "    elapsed = time.time() - start_time\n",
    "\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(f\"üìä B·∫¢NG TH·ªêNG K√ä D·ªÆ LI·ªÜU (Time: {elapsed:.2f}s)\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    print(f\"1. T·ªîNG QUAN:\")\n",
    "    print(f\"   - T·ªïng s·ªë d√≤ng: {total:,}\")\n",
    "    print(f\"   - Null rows   : {stats['null_rows']:,}  ({(stats['null_rows']/total*100):.4f}%)\")\n",
    "    print(f\"   - Duplicate ID: {stats['duplicate_ids']:,}\")\n",
    "\n",
    "    print(f\"\\n2. VALUE COUNT & CLASS STATISTICS:\")\n",
    "    print(f\"   {'Label':<10} | {'Count':<15} | {'Percentage':<10}\")\n",
    "    print(f\"   {'-'*10} | {'-'*15} | {'-'*10}\")\n",
    "    \n",
    "    # S·∫Øp x·∫øp label theo th·ª© t·ª± 0, 1, 2\n",
    "    for label in sorted(label_counts.keys()):\n",
    "        count = label_counts[label]\n",
    "        percent = (count / total * 100) if total > 0 else 0\n",
    "        \n",
    "        # Mapping t√™n class cho d·ªÖ hi·ªÉu\n",
    "        label_name = label\n",
    "        if label == '0': label_name = \"0 (Neg)\"\n",
    "        elif label == '1': label_name = \"1 (Donor)\"\n",
    "        elif label == '2': label_name = \"2 (Acc)\"\n",
    "            \n",
    "        print(f\"   {label_name:<10} | {count:<15,} | {percent:.4f}%\")\n",
    "\n",
    "    print(\"=\"*40)\n",
    "\n",
    "    # ƒê√°nh gi√° nhanh\n",
    "    if stats['null_rows'] == 0 and stats['duplicate_ids'] == 0:\n",
    "        print(\"‚úÖ D·ªØ li·ªáu S·∫†CH (Kh√¥ng Null, Kh√¥ng Tr√πng).\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è D·ªØ li·ªáu C√ì V·∫§N ƒê·ªÄ. Vui l√≤ng ki·ªÉm tra l·∫°i logic sinh m·∫´u.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    check_data_stats(FILE_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
