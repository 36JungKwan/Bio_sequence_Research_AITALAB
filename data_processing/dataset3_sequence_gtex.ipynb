{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51ae7a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒêang x·ª≠ l√Ω C:\\Users\\dotru\\STUDIE\\FPTU\\AiTA_Lab\\GTEx_Analysis_2025-08-22_v11_STARv2.7.11b_junctions.gct.gz...\n",
      "\n",
      "üëÄ [PREVIEW] 5 d√≤ng ƒë·∫ßu ti√™n ghi v√†o file:\n",
      "--------------------------------------------------------------------------------\n",
      "chr20\tGTEx_v11\tjunction\t87360\t96004\t.\t+\t.\tgene_id \"ENSG00000178591.7\"; junction_id \"chr20:87360-96004:+\";\n",
      "chr20\tGTEx_v11\tjunction\t87768\t96004\t.\t+\t.\tgene_id \"ENSG00000178591.7\"; junction_id \"chr20:87768-96004:+\";\n",
      "chr20\tGTEx_v11\tjunction\t142687\t145414\t.\t+\t.\tgene_id \"ENSG00000125788.6\"; junction_id \"chr20:142687-145414:+\";\n",
      "chr20\tGTEx_v11\tjunction\t145489\t145578\t.\t+\t.\tgene_id \"ENSG00000125788.6\"; junction_id \"chr20:145489-145578:+\";\n",
      "chr20\tGTEx_v11\tjunction\t157594\t158773\t.\t+\t.\tgene_id \"ENSG00000088782.5\"; junction_id \"chr20:157594-158773:+\";\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Xong! File ƒë√£ l∆∞u t·∫°i: C:\\Users\\dotru\\STUDIE\\FPTU\\AiTA_Lab\\GTEx_Chr20_21.gtf\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import gzip\n",
    "\n",
    "input_file = r\"C:\\Users\\dotru\\STUDIE\\FPTU\\AiTA_Lab\\GTEx_Analysis_2025-08-22_v11_STARv2.7.11b_junctions.gct.gz\"\n",
    "output_file = r\"C:\\Users\\dotru\\STUDIE\\FPTU\\AiTA_Lab\\GTEx_Chr20_21.gtf\"\n",
    "# GTEx v11 GCT th∆∞·ªùng b·ªè qua 2 d√≤ng ƒë·∫ßu (version v√† dimensions)\n",
    "# C·ªôt 0 l√† 'Name', c·ªôt 1 l√† 'Description' (th∆∞·ªùng l√† Gene ID)\n",
    "chunk_size = 100000\n",
    "preview_count = 0\n",
    "\n",
    "print(f\"ƒêang x·ª≠ l√Ω {input_file}...\")\n",
    "\n",
    "with open(output_file, 'w') as f_out:\n",
    "    # Header chu·∫©n GTF (kh√¥ng b·∫Øt bu·ªôc nh∆∞ng n√™n c√≥)\n",
    "    f_out.write(\"##description: GTEx v11 junctions converted to GTF\\n\")\n",
    "    \n",
    "    # ƒê·ªçc t·ª´ng ph·∫ßn\n",
    "    reader = pd.read_csv(input_file, sep='\\t', compression='gzip', \n",
    "                            skiprows=2, usecols=[0, 1], chunksize=chunk_size)\n",
    "    \n",
    "    for chunk in reader:\n",
    "        # 1. L·ªçc Chr 20 v√† 21\n",
    "        mask = chunk['Name'].str.startswith(('chr20:', 'chr21:'))\n",
    "        filtered_chunk = chunk[mask]\n",
    "        \n",
    "        for _, row in filtered_chunk.iterrows():\n",
    "            # ID format: chr20:263353-285482:- \n",
    "            # Ch√∫ng ta t√°ch c√°c th√†nh ph·∫ßn\n",
    "            name = row['Name']\n",
    "            # 1. T√°ch theo d·∫•u ':' tr∆∞·ªõc ƒë·ªÉ l·∫•y 3 ph·∫ßn ch√≠nh\n",
    "            # V√≠ d·ª•: 'chr20:188119-189574:-' -> ['chr20', '188119-189574', '-']\n",
    "            main_parts = name.split(':')\n",
    "            chrom = main_parts[0]\n",
    "            strand = main_parts[2]\n",
    "            \n",
    "            # 2. T√°ch ri√™ng ph·∫ßn t·ªça ƒë·ªô b·∫±ng d·∫•u '-'\n",
    "            # V√≠ d·ª•: '188119-189574' -> ['188119', '189574']\n",
    "            coords = main_parts[1].split('-')\n",
    "            i_start = coords[0]\n",
    "            i_end = coords[1]\n",
    "\n",
    "            # Trong GTF, ch√∫ng ta bi·ªÉu di·ªÖn Junction nh∆∞ m·ªôt \"v√πng\"\n",
    "            # Start = Intron Start, End = Intron End\n",
    "            # Source: GTEx_v11, Feature: junction\n",
    "            \n",
    "            # Attribute: L∆∞u Gene ID v√† s·ªë l∆∞·ª£ng read n·∫øu c·∫ßn\n",
    "            attributes = f'gene_id \"{row[\"Description\"]}\"; junction_id \"{row[\"Name\"]}\";'\n",
    "            \n",
    "            # ƒê·ªãnh d·∫°ng d√≤ng GTF: \n",
    "            # chrom | source | feature | start | end | score | strand | frame | attribute\n",
    "            gtf_line = f\"{chrom}\\tGTEx_v11\\tjunction\\t{i_start}\\t{i_end}\\t.\\t{strand}\\t.\\t{attributes}\\n\"\n",
    "            f_out.write(gtf_line)\n",
    "                        \n",
    "            # IN N·ªòI DUNG 5 D√íNG ƒê·∫¶U TI√äN ƒê·ªÇ KI·ªÇM TRA\n",
    "            if preview_count < 5:\n",
    "                if preview_count == 0:\n",
    "                    print(\"\\nüëÄ [PREVIEW] 5 d√≤ng ƒë·∫ßu ti√™n ghi v√†o file:\")\n",
    "                    print(\"-\" * 80)\n",
    "                print(gtf_line.strip())\n",
    "                preview_count += 1\n",
    "                if preview_count == 5:\n",
    "                    print(\"-\" * 80 + \"\\n\")\n",
    "\n",
    "print(f\"Xong! File ƒë√£ l∆∞u t·∫°i: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3b64753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyfaidx import Fasta\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# ================= 1. C·∫§U H√åNH H·ªÜ TH·ªêNG (QUAN TR·ªåNG) =================\n",
    "# H√£y ƒë·∫£m b·∫£o ƒë∆∞·ªùng d·∫´n file ch√≠nh x√°c\n",
    "GTF_FILE = r'C:\\Users\\dotru\\STUDIE\\FPTU\\AiTA_Lab\\GTEx_Chr20_21.gtf'      # File GTF\n",
    "FASTA_FILE = r\"C:\\Users\\dotru\\STUDIE\\FPTU\\AiTA_Lab\\Homo_sapiens.GRCh38.dna.primary_assembly.fa\"   # File FASTA\n",
    "OUTPUT_FILE = r'C:\\Users\\dotru\\STUDIE\\FPTU\\AiTA_Lab\\Bio_sequence_Research_AITALAB\\train\\task1_splicing_prediction\\data_preparation\\train_val\\gtex_test_dataset.csv'       # File k·∫øt qu·∫£ \n",
    "\n",
    "# C·∫•u h√¨nh Sequence\n",
    "WINDOW = 300                # B√°n k√≠nh 200bp\n",
    "SEQ_LEN = (WINDOW * 2) + 1  # T·ªïng ƒë·ªô d√†i 401bp (T√¢m t·∫°i index 200)\n",
    "WRITE_BATCH_SIZE = 10000    # Ghi ƒëƒ©a m·ªói 10k d√≤ng ƒë·ªÉ ti·∫øt ki·ªám RAM\n",
    "\n",
    "# C·∫•u h√¨nh T·ªâ l·ªá (Ratio)\n",
    "# B·∫°n mu·ªën 100 Negative : 1 Donor : 1 Acceptor\n",
    "# T·ª©c l√† Negative = 50 l·∫ßn (Donor + Acceptor)\n",
    "NEGATIVE_MULTIPLIER = 50 \n",
    "\n",
    "# Danh s√°ch nhi·ªÖm s·∫Øc th·ªÉ chu·∫©n (B·ªè qua c√°c m·∫£nh contig r√°c ƒë·ªÉ data s·∫°ch)\n",
    "VALID_CHROMS = set([str(i) for i in range(1, 23)] + ['X', 'Y', 'M', 'MT'])\n",
    "\n",
    "# ================= 2. C√ÅC H√ÄM X·ª¨ L√ù C·ªêT L√ïI =================\n",
    "\n",
    "def normalize_chrom(chrom_name):\n",
    "    \"\"\"\n",
    "    Chu·∫©n h√≥a t√™n nhi·ªÖm s·∫Øc th·ªÉ ƒë·ªÉ kh·ªõp gi·ªØa GTF v√† FASTA.\n",
    "    Gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ: 'chr1' vs '1', 'NC_000001' vs '1'.\n",
    "    \"\"\"\n",
    "    s = str(chrom_name).strip()\n",
    "    \n",
    "    # X·ª≠ l√Ω d·∫°ng RefSeq (NC_...)\n",
    "    if s.startswith(\"NC_\"):\n",
    "        try:\n",
    "            val = int(s.split('_')[1].split('.')[0])\n",
    "            if val == 23: return 'X'\n",
    "            if val == 24: return 'Y'\n",
    "            if val == 12920: return 'M'\n",
    "            return str(val)\n",
    "        except: return s\n",
    "        \n",
    "    # X·ª≠ l√Ω d·∫°ng UCSC (chr...)\n",
    "    if s.lower().startswith('chr'):\n",
    "        raw = s[3:]\n",
    "        if raw == 'M': return 'M'\n",
    "        return raw\n",
    "        \n",
    "    return s\n",
    "\n",
    "def get_sequence_strict(genome, raw_chrom, center_pos, strand, window):\n",
    "    \"\"\"\n",
    "    Tr√≠ch xu·∫•t sequence t·∫°i t√¢m (1-based).\n",
    "    Y√™u c·∫ßu: Kh√¥ng padding, kh√¥ng 'N', ƒë·∫£o m·∫°ch n·∫øu l√† Strand (-).\n",
    "    \"\"\"\n",
    "    norm_chrom = normalize_chrom(raw_chrom)\n",
    "    \n",
    "    # T√¨m key t∆∞∆°ng ·ª©ng trong file FASTA\n",
    "    fasta_key = None\n",
    "    if norm_chrom in genome: fasta_key = norm_chrom\n",
    "    elif f\"chr{norm_chrom}\" in genome: fasta_key = f\"chr{norm_chrom}\"\n",
    "    elif norm_chrom == 'M' and 'chrM' in genome: fasta_key = 'chrM'\n",
    "    \n",
    "    if fasta_key is None: return None # Kh√¥ng t√¨m th·∫•y chromosome\n",
    "\n",
    "    # T√≠nh t·ªça ƒë·ªô 0-based\n",
    "    start_idx = center_pos - 1 - window\n",
    "    end_idx = center_pos + window\n",
    "    \n",
    "    # Check bi√™n gi·ªõi\n",
    "    if start_idx < 0 or end_idx >= len(genome[fasta_key]): return None\n",
    "        \n",
    "    try:\n",
    "        seq_obj = genome[fasta_key][start_idx : end_idx]\n",
    "        seq = seq_obj.seq.upper()\n",
    "        \n",
    "        # Check ch·∫•t l∆∞·ª£ng\n",
    "        if len(seq) != (window * 2 + 1): return None\n",
    "        if 'N' in seq: return None # Lo·∫°i b·ªè sequence ch·ª©a N\n",
    "\n",
    "        # ƒê·∫£o m·∫°ch (Reverse Complement) cho Strand (-)\n",
    "        if strand == '-':\n",
    "            mapping = str.maketrans(\"ATCG\", \"TAGC\")\n",
    "            seq = seq.translate(mapping)[::-1]\n",
    "            \n",
    "        return seq\n",
    "    except: return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b2bf555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- GENERATING MASSIVE DATASET (Ratio 100:1:1) ---\n",
      "Target: ~10k Donor, ~10k Acceptor, ~1M Negatives\n",
      "[1/4] Loading Genome (Lazy Load)...\n"
     ]
    }
   ],
   "source": [
    "# ================= 3. CH∆Ø∆†NG TR√åNH CH√çNH (STREAMING) =================\n",
    "\n",
    "print(f\"--- GENERATING MASSIVE DATASET (Ratio 100:1:1) ---\")\n",
    "print(f\"Target: ~10k Donor, ~10k Acceptor, ~1M Negatives\")\n",
    "\n",
    "# 1. Load Resources\n",
    "if not os.path.exists(FASTA_FILE):\n",
    "    print(f\"L·ªñI: Kh√¥ng t√¨m th·∫•y {FASTA_FILE}\"); \n",
    "if not os.path.exists(GTF_FILE):\n",
    "    print(f\"L·ªñI: Kh√¥ng t√¨m th·∫•y {GTF_FILE}\"); \n",
    "print(\"[1/4] Loading Genome (Lazy Load)...\")\n",
    "genome = Fasta(FASTA_FILE, sequence_always_upper=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a5d35cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/4] Parsing GTF...\n",
      "      -> 19714 junctions found in GTEx data.\n"
     ]
    }
   ],
   "source": [
    "print(\"[2/4] Parsing GTF...\")\n",
    "# ƒê·ªçc GTF, l·ªçc l·∫•y Exon c·ªßa Protein Coding Genes\n",
    "df = pd.read_csv(GTF_FILE, sep='\\t', comment='#', header=None, usecols=[0, 2, 3, 4, 6, 8],\n",
    "                    names=['chrom', 'feature', 'start', 'end', 'strand', 'attribute'])\n",
    "df = df[df['feature'] == 'junction']\n",
    "print(f\"      -> {len(df)} junctions found in GTEx data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab2f2167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/4] Processing Positives...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Positives: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19714/19714 [00:02<00:00, 6656.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      -> ƒê√£ ghi 27507 m·∫´u Positive s·∫°ch.\n",
      "[4/4] Generating 1375350 Negatives (Ratio 100:1:1)...\n",
      "      L∆∞u √Ω: B∆∞·ªõc n√†y s·∫Ω t·ªën RAM h∆°n ƒë·ªÉ l∆∞u set check tr√πng.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mining Negatives: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 1375318/1375350 [30:58<00:00, 646.19it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ HO√ÄN T·∫§T! File saved at: C:\\Users\\dotru\\STUDIE\\FPTU\\AiTA_Lab\\Bio_sequence_Research_AITALAB\\train\\task1_splicing_prediction\\data_preparation\\train_val\\gtex_test_dataset.csv\n",
      "      Dung l∆∞·ª£ng ∆∞·ªõc t√≠nh: ~9.5 GB\n",
      "      T·ªïng s·ªë d√≤ng: 1402857\n",
      "‚ö†Ô∏è QUAN TR·ªåNG: File n√†y ch∆∞a ƒë∆∞·ª£c shuffle (Positive n·∫±m ƒë·∫ßu, Negative n·∫±m cu·ªëi).\n",
      "   H√£y shuffle khi load v√†o model ho·∫∑c d√πng l·ªánh Linux: 'shuf C:\\Users\\dotru\\STUDIE\\FPTU\\AiTA_Lab\\Bio_sequence_Research_AITALAB\\train\\task1_splicing_prediction\\data_preparation\\train_val\\gtex_test_dataset.csv > shuffled.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mining Negatives: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1375350/1375350 [31:08<00:00, 646.19it/s]"
     ]
    }
   ],
   "source": [
    "# M·ªü file CSV ƒë·ªÉ ghi lu·ªìng (Stream Writing)\n",
    "with open(OUTPUT_FILE, 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['id', 'dna', 'label']) # Header\n",
    "\n",
    "    # --- B∆Ø·ªöC 3: X·ª¨ L√ù POSITIVE (Labels 1 & 2) ---\n",
    "    print(\"[3/4] Processing Positives...\")\n",
    "    seen_sites = set() # Set kh·ª≠ tr√πng l·∫∑p\n",
    "    pos_buffer = []    # B·ªô nh·ªõ ƒë·ªám t·∫°m th·ªùi\n",
    "    total_positives = 0\n",
    "    \n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Positives\"):\n",
    "        raw_chrom = row['chrom']\n",
    "        norm_chrom = normalize_chrom(raw_chrom)\n",
    "        if norm_chrom not in VALID_CHROMS: continue\n",
    "        strand = row['strand']\n",
    "\n",
    "        # T√≠nh t·ªça ƒë·ªô t√¢m (Center at G)\n",
    "        if strand == '+':\n",
    "            donor_center = row['start']\n",
    "            acc_center = row['end']\n",
    "        else:\n",
    "            donor_center = row['end']\n",
    "            acc_center = row['start']\n",
    "\n",
    "        # --- LABEL 1: DONOR (GT & GC) ---\n",
    "        if (norm_chrom, donor_center, strand, 1) not in seen_sites:\n",
    "            seq = get_sequence_strict(genome, raw_chrom, donor_center, strand, WINDOW)\n",
    "            if seq:\n",
    "                # Ki·ªÉm tra t√¢m: Ch·∫•p nh·∫≠n GT v√† GC\n",
    "                center_motif = seq[WINDOW : WINDOW+2]\n",
    "                if center_motif in ['GT', 'GC']:\n",
    "                    pos_buffer.append([f\"Donor_{norm_chrom}_{donor_center}_{strand}\", seq, 1])\n",
    "                    seen_sites.add((norm_chrom, donor_center, strand, 1))\n",
    "                    total_positives += 1\n",
    "\n",
    "        # --- LABEL 2: ACCEPTOR (AG) ---\n",
    "        if (norm_chrom, acc_center, strand, 2) not in seen_sites:\n",
    "            seq = get_sequence_strict(genome, raw_chrom, acc_center, strand, WINDOW)\n",
    "            if seq:\n",
    "                # Ki·ªÉm tra t√¢m: Ch·∫•p nh·∫≠n AG\n",
    "                center_motif = seq[WINDOW-1 : WINDOW+1]\n",
    "                if center_motif == 'AG':\n",
    "                    pos_buffer.append([f\"Acc_{norm_chrom}_{acc_center}_{strand}\", seq, 2])\n",
    "                    seen_sites.add((norm_chrom, acc_center, strand, 2))\n",
    "                    total_positives += 1\n",
    "        \n",
    "        # Ghi v√†o ƒëƒ©a khi buffer ƒë·∫ßy (tr√°nh t·ªën RAM)\n",
    "        if len(pos_buffer) >= WRITE_BATCH_SIZE:\n",
    "            writer.writerows(pos_buffer)\n",
    "            pos_buffer = [] \n",
    "\n",
    "    # Ghi n·ªët ph·∫ßn d∆∞\n",
    "    if pos_buffer:\n",
    "        writer.writerows(pos_buffer)\n",
    "        pos_buffer = [] # Clear RAM ho√†n to√†n\n",
    "        \n",
    "    print(f\"      -> ƒê√£ ghi {total_positives} m·∫´u Positive s·∫°ch.\")\n",
    "    \n",
    "# --- B∆Ø·ªöC 4: SINH D·ªÆ LI·ªÜU NEGATIVE KH·ªîNG L·ªí (ƒê√É S·ª¨A L·ªñI DUPLICATE) ---\n",
    "    target_neg = total_positives * NEGATIVE_MULTIPLIER\n",
    "    print(f\"[4/4] Generating {target_neg} Negatives (Ratio 100:1:1)...\")\n",
    "    print(\"      L∆∞u √Ω: B∆∞·ªõc n√†y s·∫Ω t·ªën RAM h∆°n ƒë·ªÉ l∆∞u set check tr√πng.\")\n",
    "    \n",
    "    neg_count = 0\n",
    "    neg_buffer = []\n",
    "    \n",
    "    # Iterator tu·∫ßn ho√†n\n",
    "    df_sample = df.sample(frac=1).reset_index(drop=True)\n",
    "    iter_rows = iter(df_sample.iterrows())\n",
    "    \n",
    "    pbar = tqdm(total=target_neg, desc=\"Mining Negatives\")\n",
    "    \n",
    "    while neg_count < target_neg:\n",
    "        try:\n",
    "            _, row = next(iter_rows)\n",
    "        except StopIteration:\n",
    "            df_sample = df.sample(frac=1).reset_index(drop=True)\n",
    "            iter_rows = iter(df_sample.iterrows())\n",
    "            _, row = next(iter_rows)\n",
    "        \n",
    "        raw_chrom = row['chrom']\n",
    "        norm_chrom = normalize_chrom(raw_chrom)\n",
    "        if norm_chrom not in VALID_CHROMS: continue\n",
    "        strand = row['strand']\n",
    "        \n",
    "        # Random v·ªã tr√≠\n",
    "        rand_pos = random.randint(row['start'] - 10000, row['end'] + 10000)\n",
    "        \n",
    "        # --- [S·ª¨A ƒê·ªîI QUAN TR·ªåNG] ---\n",
    "        # T·∫°o key ƒë·∫°i di·ªán cho m·∫´u Negative ƒë·ªãnh l·∫•y\n",
    "        neg_key = (norm_chrom, rand_pos, strand, 0)\n",
    "        \n",
    "        # 1. Check tr√πng Positive (Site th·∫≠t)\n",
    "        if (norm_chrom, rand_pos, strand, 1) in seen_sites or \\\n",
    "           (norm_chrom, rand_pos, strand, 2) in seen_sites:\n",
    "            continue\n",
    "\n",
    "        # 2. Check tr√πng Negative ƒë√£ l·∫•y tr∆∞·ªõc ƒë√≥ (FIX BUG DUPLICATE)\n",
    "        if neg_key in seen_sites:\n",
    "            continue\n",
    "        # ----------------------------\n",
    "\n",
    "        seq = get_sequence_strict(genome, raw_chrom, rand_pos, strand, WINDOW)\n",
    "        if not seq: continue\n",
    "        \n",
    "        # Hard Negative Check\n",
    "        center = seq[WINDOW]\n",
    "        next_b = seq[WINDOW+1]\n",
    "        prev_b = seq[WINDOW-1]\n",
    "        \n",
    "        is_fake_donor = (center == 'G' and next_b in ['T', 'C'])\n",
    "        is_fake_acc   = (prev_b == 'A' and center == 'G')\n",
    "        \n",
    "        if is_fake_donor or is_fake_acc:\n",
    "            neg_buffer.append([f\"Neg_{norm_chrom}_{rand_pos}_{strand}\", seq, 0])\n",
    "            \n",
    "            # --- [TH√äM M·ªöI] ƒê√°nh d·∫•u ƒë√£ s·ª≠ d·ª•ng ---\n",
    "            seen_sites.add(neg_key) \n",
    "            # --------------------------------------\n",
    "\n",
    "            neg_count += 1\n",
    "            pbar.update(1)\n",
    "            \n",
    "            if len(neg_buffer) >= WRITE_BATCH_SIZE:\n",
    "                writer.writerows(neg_buffer)\n",
    "                neg_buffer = []\n",
    "\n",
    "    # Ghi n·ªët ph·∫ßn cu·ªëi\n",
    "    if neg_buffer:\n",
    "        writer.writerows(neg_buffer)\n",
    "\n",
    "print(f\"‚úÖ HO√ÄN T·∫§T! File saved at: {OUTPUT_FILE}\")\n",
    "print(f\"      Dung l∆∞·ª£ng ∆∞·ªõc t√≠nh: ~9.5 GB\")\n",
    "print(f\"      T·ªïng s·ªë d√≤ng: {total_positives + neg_count}\")\n",
    "print(f\"‚ö†Ô∏è QUAN TR·ªåNG: File n√†y ch∆∞a ƒë∆∞·ª£c shuffle (Positive n·∫±m ƒë·∫ßu, Negative n·∫±m cu·ªëi).\")\n",
    "print(f\"   H√£y shuffle khi load v√†o model ho·∫∑c d√πng l·ªánh Linux: 'shuf {OUTPUT_FILE} > shuffled.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21830b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ ƒêang x·ª≠ l√Ω file: C:\\Users\\dotru\\STUDIE\\FPTU\\AiTA_Lab\\Bio_sequence_Research_AITALAB\\train\\task1_splicing_prediction\\data_preparation\\train_val\\gtex_test_dataset.csv\n",
      "   - ƒê·ªïi t√™n c·ªôt: {'label': 'Splicing_types', 'dna': 'sequence'}\n",
      "   - Th√™m/Update c·ªôt: CHROM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows: 1402857 rows [01:03, 22040.87 rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ HO√ÄN T·∫§T! File ƒë√£ ƒë∆∞·ª£c c·∫≠p nh·∫≠t.\n",
      "   Header m·ªõi: ['id', 'sequence', 'Splicing_types', 'CHROM']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- C·∫§U H√åNH ---\n",
    "TARGET_FILE = r'C:\\Users\\dotru\\STUDIE\\FPTU\\AiTA_Lab\\Bio_sequence_Research_AITALAB\\train\\task1_splicing_prediction\\data_preparation\\train_val\\gtex_test_dataset.csv'\n",
    "TEMP_FILE = TARGET_FILE + '.tmp'\n",
    "NEW_CHROM_COL = 'CHROM'\n",
    "\n",
    "# Map ƒë·ªïi t√™n: {'T√™n c≈©': 'T√™n m·ªõi'}\n",
    "RENAME_MAP = {\n",
    "    'label': 'Splicing_types',\n",
    "    'dna': 'sequence'\n",
    "}\n",
    "\n",
    "print(f\"üîÑ ƒêang x·ª≠ l√Ω file: {TARGET_FILE}\")\n",
    "print(f\"   - ƒê·ªïi t√™n c·ªôt: {RENAME_MAP}\")\n",
    "print(f\"   - Th√™m/Update c·ªôt: {NEW_CHROM_COL}\")\n",
    "\n",
    "try:\n",
    "    with open(TARGET_FILE, 'r', encoding='utf-8') as f_in, \\\n",
    "         open(TEMP_FILE, 'w', encoding='utf-8', newline='') as f_out:\n",
    "        \n",
    "        reader = csv.reader(f_in)\n",
    "        writer = csv.writer(f_out)\n",
    "        \n",
    "        # 1. X·ª¨ L√ù HEADER (ƒê·ªïi t√™n & Th√™m c·ªôt)\n",
    "        try:\n",
    "            original_header = next(reader)\n",
    "        except StopIteration:\n",
    "            print(\"‚ùå File r·ªóng!\")\n",
    "            raise Exception(\"File empty\")\n",
    "            \n",
    "        # B∆∞·ªõc A: ƒê·ªïi t√™n c√°c c·ªôt c≈© (label -> Splicing_types, dna -> sequence)\n",
    "        renamed_header = [RENAME_MAP.get(col, col) for col in original_header]\n",
    "        \n",
    "        # B∆∞·ªõc B: Ki·ªÉm tra c·ªôt CHROM\n",
    "        if NEW_CHROM_COL in renamed_header:\n",
    "            print(f\"‚ö†Ô∏è C·ªôt '{NEW_CHROM_COL}' ƒë√£ t·ªìn t·∫°i -> S·∫Ω c·∫≠p nh·∫≠t d·ªØ li·ªáu.\")\n",
    "            final_header = renamed_header\n",
    "            chrom_idx = renamed_header.index(NEW_CHROM_COL)\n",
    "        else:\n",
    "            final_header = renamed_header + [NEW_CHROM_COL]\n",
    "            chrom_idx = None # Ch∆∞a c√≥, s·∫Ω append v√†o cu·ªëi\n",
    "            \n",
    "        writer.writerow(final_header)\n",
    "        \n",
    "        # 2. X·ª¨ L√ù D·ªÆ LI·ªÜU (Streaming)\n",
    "        for row in tqdm(reader, desc=\"Processing Rows\", unit=\" rows\"):\n",
    "            if not row: continue\n",
    "            \n",
    "            # Logic l·∫•y Chromosome t·ª´ ID (Donor_1_65434_+)\n",
    "            row_id = row[0]\n",
    "            try:\n",
    "                parts = row_id.split('_')\n",
    "                if len(parts) > 1:\n",
    "                    raw_chrom = parts[1]\n",
    "                    # Format: chr1, chr2, chrX...\n",
    "                    chrom_val = raw_chrom if raw_chrom.startswith('chr') else f\"chr{raw_chrom}\"\n",
    "                else:\n",
    "                    chrom_val = \"unknown\"\n",
    "                \n",
    "                # Logic ghi v√†o d√≤ng\n",
    "                if chrom_idx is not None:\n",
    "                    # N·∫øu c·ªôt CHROM ƒë√£ c√≥ s·∫µn (do ch·∫°y l·∫°i nhi·ªÅu l·∫ßn) -> Ghi ƒë√®\n",
    "                    if len(row) > chrom_idx:\n",
    "                        row[chrom_idx] = chrom_val\n",
    "                    else:\n",
    "                        row.append(chrom_val)\n",
    "                    writer.writerow(row)\n",
    "                else:\n",
    "                    # N·∫øu ch∆∞a c√≥ -> Th√™m m·ªõi v√†o cu·ªëi\n",
    "                    writer.writerow(row + [chrom_val])\n",
    "                    \n",
    "            except Exception:\n",
    "                # Fallback an to√†n cho d√≤ng l·ªói\n",
    "                writer.writerow(row + (['unknown'] if chrom_idx is None else []))\n",
    "\n",
    "    # 3. Thay th·∫ø file c≈©\n",
    "    os.replace(TEMP_FILE, TARGET_FILE)\n",
    "    print(f\"‚úÖ HO√ÄN T·∫§T! File ƒë√£ ƒë∆∞·ª£c c·∫≠p nh·∫≠t.\")\n",
    "    print(f\"   Header m·ªõi: {final_header}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y file '{TARGET_FILE}'.\")\n",
    "except Exception as e:\n",
    "    if os.path.exists(TEMP_FILE): os.remove(TEMP_FILE)\n",
    "    print(f\"‚ùå L·ªói Runtime: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d9844c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ B·∫ÆT ƒê·∫¶U KI·ªÇM TRA FILE (C·∫§U TR√öC M·ªöI): C:\\Users\\dotru\\STUDIE\\FPTU\\AiTA_Lab\\Bio_sequence_Research_AITALAB\\train\\task1_splicing_prediction\\data_preparation\\train_val\\gtex_test_dataset.csv\n",
      "   -> Header t√¨m th·∫•y: ['id', 'sequence', 'Splicing_types', 'CHROM']\n",
      "   -> Mapping index: Seq=1, Label=2, Chrom=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing: 1402857 rows [00:18, 76376.17 rows/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìä B√ÅO C√ÅO D·ªÆ LI·ªÜU (Time: 18.39s | Total: 1,402,857 rows)\n",
      "================================================================================\n",
      "\n",
      "1. M·∫™U D·ªÆ LI·ªÜU (5 d√≤ng ƒë·∫ßu):\n",
      "   ID                        | Sequence (Preview)   | Type       | Chrom   \n",
      "   ------------------------- | -------------------- | ---------- | --------\n",
      "   Donor_20_87360_+          | TCTCAA...TGTG        | 1          | chr20   \n",
      "   Acc_20_96004_+            | CTGGTC...GAGA        | 2          | chr20   \n",
      "   Donor_20_87768_+          | CTACGG...CTTC        | 1          | chr20   \n",
      "   Donor_20_142687_+         | GTTTGC...GTCA        | 1          | chr20   \n",
      "   Acc_20_145414_+           | TGTTCA...CCTG        | 2          | chr20   \n",
      "\n",
      "2. KI·ªÇM TRA NULL (COMPLETENESS):\n",
      "   T√™n C·ªôt              | S·ªë Null    | % L·ªói\n",
      "   id                   | ‚úÖ          | 0.0000%\n",
      "   sequence             | ‚úÖ          | 0.0000%\n",
      "   Splicing_types       | ‚úÖ          | 0.0000%\n",
      "   CHROM                | ‚úÖ          | 0.0000%\n",
      "   -> S·∫°ch 100%.\n",
      "\n",
      "3. PH√ÇN B·ªê TYPE (Splicing_types):\n",
      "   - '1': 13,776 m·∫´u\n",
      "   - '2': 13,731 m·∫´u\n",
      "   - '0': 1,375,350 m·∫´u\n",
      "\n",
      "4. PH√ÇN B·ªê CHROMOSOME (Top 5):\n",
      "   - chr20: 910,544 m·∫´u\n",
      "   - chr21: 492,313 m·∫´u\n",
      "\n",
      "5. SEQUENCE LENGTH:\n",
      "   - Length 601: 1,402,857 m·∫´u (‚úÖ Chu·∫©n)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import sys\n",
    "import time\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ================= C·∫§U H√åNH =================\n",
    "# S·ª≠a ƒë∆∞·ªùng d·∫´n file n·∫øu c·∫ßn\n",
    "FILE_PATH = r'C:\\Users\\dotru\\STUDIE\\FPTU\\AiTA_Lab\\Bio_sequence_Research_AITALAB\\train\\task1_splicing_prediction\\data_preparation\\train_val\\gtex_test_dataset.csv'\n",
    "SAMPLE_ROWS = 5  # S·ªë d√≤ng in m·∫´u\n",
    "\n",
    "def inspect_and_validate_full(file_path):\n",
    "    print(f\"üöÄ B·∫ÆT ƒê·∫¶U KI·ªÇM TRA FILE (C·∫§U TR√öC M·ªöI): {file_path}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 1. BI·∫æN TH·ªêNG K√ä\n",
    "    stats = {\n",
    "        \"total_rows\": 0,\n",
    "        \"null_counts\": {},\n",
    "        \"seq_lengths\": Counter(),      # Th·ªëng k√™ ƒë·ªô d√†i sequence\n",
    "        \"label_counts\": Counter(),     # Th·ªëng k√™ Splicing_types\n",
    "        \"chrom_counts\": Counter(),     # Th·ªëng k√™ CHROM (M·ªõi)\n",
    "        \"samples\": []\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            reader = csv.reader(f)\n",
    "            \n",
    "            # --- 2. ƒê·ªåC & MAP HEADER ---\n",
    "            try:\n",
    "                header = next(reader)\n",
    "                # Kh·ªüi t·∫°o ƒë·∫øm null\n",
    "                for col in header: stats[\"null_counts\"][col] = 0\n",
    "                \n",
    "                # T√¨m v·ªã tr√≠ (index) c·ªßa c√°c c·ªôt quan tr·ªçng theo t√™n m·ªõi\n",
    "                # D√πng next(..., None) ƒë·ªÉ tr√°nh l·ªói n·∫øu kh√¥ng t√¨m th·∫•y c·ªôt\n",
    "                idx_seq = next((i for i, c in enumerate(header) if c in ['sequence', 'dna']), None)\n",
    "                idx_lbl = next((i for i, c in enumerate(header) if c in ['Splicing_types', 'label']), None)\n",
    "                idx_chr = next((i for i, c in enumerate(header) if c in ['CHROM', 'chrom']), None)\n",
    "                \n",
    "                print(f\"   -> Header t√¨m th·∫•y: {header}\")\n",
    "                print(f\"   -> Mapping index: Seq={idx_seq}, Label={idx_lbl}, Chrom={idx_chr}\")\n",
    "                \n",
    "            except StopIteration:\n",
    "                print(\"‚ùå L·ªñI: File r·ªóng!\")\n",
    "                return\n",
    "\n",
    "            # --- 3. QU√âT D·ªÆ LI·ªÜU (SINGLE PASS) ---\n",
    "            pbar = tqdm(reader, desc=\"Analyzing\", unit=\" rows\")\n",
    "            \n",
    "            for i, row in enumerate(pbar):\n",
    "                stats[\"total_rows\"] += 1\n",
    "                \n",
    "                # A. L·∫§Y M·∫™U\n",
    "                if i < SAMPLE_ROWS:\n",
    "                    stats[\"samples\"].append(row)\n",
    "                \n",
    "                # B. CHECK NULL & VALIDATE\n",
    "                for col_idx, val in enumerate(row):\n",
    "                    if col_idx >= len(header): break\n",
    "                    if not val.strip():\n",
    "                        col_name = header[col_idx]\n",
    "                        stats[\"null_counts\"][col_name] += 1\n",
    "                \n",
    "                # C. TH·ªêNG K√ä GI√Å TR·ªä (D·ª±a tr√™n index ƒë√£ map)\n",
    "                if idx_seq is not None and len(row) > idx_seq:\n",
    "                    stats[\"seq_lengths\"][len(row[idx_seq])] += 1\n",
    "                    \n",
    "                if idx_lbl is not None and len(row) > idx_lbl:\n",
    "                    stats[\"label_counts\"][row[idx_lbl]] += 1\n",
    "                    \n",
    "                if idx_chr is not None and len(row) > idx_chr:\n",
    "                    stats[\"chrom_counts\"][row[idx_chr]] += 1\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y file {file_path}\")\n",
    "        return\n",
    "\n",
    "    # --- 4. B√ÅO C√ÅO K·∫æT QU·∫¢ ---\n",
    "    elapsed = time.time() - start_time\n",
    "    total = stats[\"total_rows\"]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"üìä B√ÅO C√ÅO D·ªÆ LI·ªÜU (Time: {elapsed:.2f}s | Total: {total:,} rows)\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # 4.1 B·∫£ng m·∫´u (C·∫≠p nh·∫≠t 4 c·ªôt)\n",
    "    print(f\"\\n1. M·∫™U D·ªÆ LI·ªÜU ({SAMPLE_ROWS} d√≤ng ƒë·∫ßu):\")\n",
    "    # Format in: ID | Sequence | Type | Chrom\n",
    "    print(f\"   {'ID':<25} | {'Sequence (Preview)':<20} | {'Type':<10} | {'Chrom':<8}\")\n",
    "    print(f\"   {'-'*25} | {'-'*20} | {'-'*10} | {'-'*8}\")\n",
    "    \n",
    "    for row in stats[\"samples\"]:\n",
    "        # L·∫•y gi√° tr·ªã an to√†n (ph√≤ng tr∆∞·ªùng h·ª£p d√≤ng thi·∫øu c·ªôt)\n",
    "        _id = row[0] if len(row) > 0 else \"\"\n",
    "        _seq = row[idx_seq] if idx_seq is not None and len(row) > idx_seq else \"N/A\"\n",
    "        _lbl = row[idx_lbl] if idx_lbl is not None and len(row) > idx_lbl else \"N/A\"\n",
    "        _chr = row[idx_chr] if idx_chr is not None and len(row) > idx_chr else \"N/A\"\n",
    "        \n",
    "        # C·∫Øt ng·∫Øn sequence\n",
    "        seq_show = _seq[:6] + \"...\" + _seq[-4:] if len(_seq) > 10 else _seq\n",
    "        print(f\"   {_id:<25} | {seq_show:<20} | {_lbl:<10} | {_chr:<8}\")\n",
    "\n",
    "    # 4.2 B√°o c√°o Null\n",
    "    print(f\"\\n2. KI·ªÇM TRA NULL (COMPLETENESS):\")\n",
    "    has_null = False\n",
    "    print(f\"   {'T√™n C·ªôt':<20} | {'S·ªë Null':<10} | {'% L·ªói'}\")\n",
    "    for col, count in stats[\"null_counts\"].items():\n",
    "        pct = (count / total * 100) if total > 0 else 0\n",
    "        status = \"‚úÖ\" if count == 0 else f\"‚ùå {count:,}\"\n",
    "        print(f\"   {col:<20} | {status:<10} | {pct:.4f}%\")\n",
    "        if count > 0: has_null = True\n",
    "    if not has_null: print(\"   -> S·∫°ch 100%.\")\n",
    "\n",
    "    # 4.3 Ph√¢n b·ªë Label\n",
    "    print(f\"\\n3. PH√ÇN B·ªê TYPE (Splicing_types):\")\n",
    "    for lbl, count in stats[\"label_counts\"].items():\n",
    "        print(f\"   - '{lbl}': {count:,} m·∫´u\")\n",
    "\n",
    "    # 4.4 Ph√¢n b·ªë Chrom (M·ªõi)\n",
    "    print(f\"\\n4. PH√ÇN B·ªê CHROMOSOME (Top 5):\")\n",
    "    # Ch·ªâ in 5 chrom ph·ªï bi·∫øn nh·∫•t ƒë·ªÉ ƒë·ª° d√†i d√≤ng\n",
    "    for ch, count in stats[\"chrom_counts\"].most_common(5):\n",
    "        print(f\"   - {ch}: {count:,} m·∫´u\")\n",
    "    if len(stats[\"chrom_counts\"]) > 5: print(f\"   ... v√† {len(stats['chrom_counts'])-5} chrom kh√°c.\")\n",
    "\n",
    "    # 4.5 Sequence Length\n",
    "    print(f\"\\n5. SEQUENCE LENGTH:\")\n",
    "    for length, count in stats[\"seq_lengths\"].items():\n",
    "        status = \"‚úÖ Chu·∫©n\" if length == 601 else \"‚ö†Ô∏è L·ªÜCH\"\n",
    "        print(f\"   - Length {length}: {count:,} m·∫´u ({status})\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    inspect_and_validate_full(FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0514964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß¨ B·∫ÆT ƒê·∫¶U KI·ªÇM TRA LOGIC SINH H·ªåC: C:\\Users\\dotru\\STUDIE\\FPTU\\AiTA_Lab\\Bio_sequence_Research_AITALAB\\train\\task1_splicing_prediction\\data_preparation\\train_val\\gtex_test_dataset.csv\n",
      "   -> Mapping OK: Seq=1, Label=2, Chrom=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bio-Checking: 1402857 rows [00:24, 57761.70 rows/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üî¨ K·∫æT QU·∫¢ KI·ªÇM TRA SINH H·ªåC (1,402,857 m·∫´u)\n",
      "============================================================\n",
      "1. T·ª™ V·ª∞NG DNA (Ch·ªâ A,C,G,T,N): ‚úÖ S·∫°ch\n",
      "2. MOTIF CONSISTENCY (GT/AG): ‚úÖ Chu·∫©n x√°c\n",
      "3. CHROMOSOME COVERAGE:\n",
      "   - T√¨m th·∫•y 2 nhi·ªÖm s·∫Øc th·ªÉ.\n",
      "   ‚ö†Ô∏è C·∫¢NH B√ÅO: Kh√¥ng th·∫•y d·ªØ li·ªáu t·ª´ chr1!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import sys\n",
    "import time\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ================= C·∫§U H√åNH =================\n",
    "FILE_PATH = r'C:\\Users\\dotru\\STUDIE\\FPTU\\AiTA_Lab\\Bio_sequence_Research_AITALAB\\train\\task1_splicing_prediction\\data_preparation\\train_val\\gtex_test_dataset.csv'\n",
    "WINDOW = 300 # B√°n k√≠nh nh∆∞ thi·∫øt l·∫≠p ban ƒë·∫ßu\n",
    "CENTER_IDX = WINDOW # V·ªã tr√≠ t√¢m (300)\n",
    "\n",
    "def validate_biological_data(file_path):\n",
    "    print(f\"üß¨ B·∫ÆT ƒê·∫¶U KI·ªÇM TRA LOGIC SINH H·ªåC: {file_path}\")\n",
    "    \n",
    "    stats = {\n",
    "        \"total\": 0,\n",
    "        \"invalid_chars\": 0,   # Sequence ch·ª©a k√Ω t·ª± l·∫°\n",
    "        \"motif_errors\": 0,    # Sai Motif (Donor k ph·∫£i GT, Acc k ph·∫£i AG)\n",
    "        \"label_dist\": Counter(),\n",
    "        \"chrom_dist\": Counter()\n",
    "    }\n",
    "    \n",
    "    valid_bases = set(\"ACGTN\")\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            reader = csv.reader(f)\n",
    "            header = next(reader, None)\n",
    "            \n",
    "            # Map index c·ªôt (ƒë·ªÉ code ch·∫°y ƒë√∫ng d√π c·ªôt ƒë·ªïi ch·ªó)\n",
    "            # T√¨m c·ªôt theo t√™n m·ªõi ho·∫∑c c≈©\n",
    "            try:\n",
    "                idx_seq = next(i for i, c in enumerate(header) if c in ['sequence', 'dna'])\n",
    "                idx_lbl = next(i for i, c in enumerate(header) if c in ['Splicing_types', 'label'])\n",
    "                idx_chr = next(i for i, c in enumerate(header) if c in ['CHROM', 'chrom'])\n",
    "            except StopIteration:\n",
    "                print(\"‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y ƒë·ªß c√°c c·ªôt sequence, label, CHROM!\")\n",
    "                return\n",
    "\n",
    "            print(f\"   -> Mapping OK: Seq={idx_seq}, Label={idx_lbl}, Chrom={idx_chr}\")\n",
    "\n",
    "            # QU√âT D·ªÆ LI·ªÜU\n",
    "            for row in tqdm(reader, desc=\"Bio-Checking\", unit=\" rows\"):\n",
    "                if not row: continue\n",
    "                stats[\"total\"] += 1\n",
    "                \n",
    "                seq = row[idx_seq]\n",
    "                label = row[idx_lbl]\n",
    "                chrom = row[idx_chr]\n",
    "                \n",
    "                stats[\"label_dist\"][label] += 1\n",
    "                stats[\"chrom_dist\"][chrom] += 1\n",
    "                \n",
    "                # 1. CHECK K√ù T·ª∞ L·∫† (Vocabulary)\n",
    "                # D√πng set check cho nhanh\n",
    "                if not set(seq).issubset(valid_bases):\n",
    "                    stats[\"invalid_chars\"] += 1\n",
    "\n",
    "                # 2. CHECK MOTIF SINH H·ªåC (Quan tr·ªçng!)\n",
    "                # Ch·ªâ check n·∫øu ƒë·ªô d√†i sequence ƒë√∫ng 601\n",
    "                if len(seq) == (WINDOW * 2 + 1):\n",
    "                    # Donor (Label 1): T√¢m ph·∫£i l√† GT ho·∫∑c GC\n",
    "                    # Logic c·∫Øt: seq[300:302]\n",
    "                    if label == '1':\n",
    "                        motif = seq[CENTER_IDX : CENTER_IDX+2]\n",
    "                        if motif not in ['GT', 'GC']:\n",
    "                            stats[\"motif_errors\"] += 1\n",
    "                            \n",
    "                    # Acceptor (Label 2): T√¢m ph·∫£i l√† AG\n",
    "                    # Logic c·∫Øt: seq[299:301] (V√¨ AG n·∫±m ngay tr∆∞·ªõc exon)\n",
    "                    elif label == '2':\n",
    "                        motif = seq[CENTER_IDX-1 : CENTER_IDX+1]\n",
    "                        if motif != 'AG':\n",
    "                            stats[\"motif_errors\"] += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå L·ªói Runtime: {e}\")\n",
    "        return\n",
    "\n",
    "    # B√ÅO C√ÅO\n",
    "    total = stats[\"total\"]\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"üî¨ K·∫æT QU·∫¢ KI·ªÇM TRA SINH H·ªåC ({total:,} m·∫´u)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 1. K√Ω t·ª± l·∫°\n",
    "    status_char = \"‚úÖ S·∫°ch\" if stats[\"invalid_chars\"] == 0 else f\"‚ùå {stats['invalid_chars']:,} m·∫´u l·ªói\"\n",
    "    print(f\"1. T·ª™ V·ª∞NG DNA (Ch·ªâ A,C,G,T,N): {status_char}\")\n",
    "    \n",
    "    # 2. Motif\n",
    "    # L∆∞u √Ω: N·∫øu Motif l·ªói nhi·ªÅu -> Code sinh d·ªØ li·ªáu b·ªã l·ªách index slicing\n",
    "    pct_motif = (stats[\"motif_errors\"] / total * 100)\n",
    "    status_motif = \"‚úÖ Chu·∫©n x√°c\" if pct_motif < 1.0 else f\"‚ö†Ô∏è ƒê√ÅNG NG·ªú ({stats['motif_errors']:,} m·∫´u sai motif)\"\n",
    "    print(f\"2. MOTIF CONSISTENCY (GT/AG): {status_motif}\")\n",
    "    if stats[\"motif_errors\"] > 0:\n",
    "        print(\"   (N·∫øu s·ªë l∆∞·ª£ng l·ªói motif qu√° l·ªõn, h√£y ki·ªÉm tra l·∫°i logic c·∫Øt chu·ªói!)\")\n",
    "\n",
    "    # 3. Chromosome Check\n",
    "    print(f\"3. CHROMOSOME COVERAGE:\")\n",
    "    print(f\"   - T√¨m th·∫•y {len(stats['chrom_dist'])} nhi·ªÖm s·∫Øc th·ªÉ.\")\n",
    "    # In c·∫£nh b√°o n·∫øu thi·∫øu chr1 (th∆∞·ªùng l√† do file GTF l·ªói ho·∫∑c filter sai)\n",
    "    if 'chr1' not in stats['chrom_dist']:\n",
    "        print(\"   ‚ö†Ô∏è C·∫¢NH B√ÅO: Kh√¥ng th·∫•y d·ªØ li·ªáu t·ª´ chr1!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    validate_biological_data(FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb372bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ B·∫ÆT ƒê·∫¶U KI·ªÇM TRA FILE: C:\\Users\\dotru\\STUDIE\\FPTU\\AiTA_Lab\\Bio_sequence_Research_AITALAB\\train\\task1_splicing_prediction\\data_preparation\\train_val\\gtex_test_dataset.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning: 1402857 rows [00:18, 76156.98 rows/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "üìä B·∫¢NG TH·ªêNG K√ä D·ªÆ LI·ªÜU (Time: 18.43s)\n",
      "========================================\n",
      "1. T·ªîNG QUAN:\n",
      "   - T·ªïng s·ªë d√≤ng: 1,402,857\n",
      "   - Null rows   : 0  (0.0000%)\n",
      "   - Duplicate ID: 0\n",
      "\n",
      "2. VALUE COUNT & CLASS STATISTICS:\n",
      "   Label      | Count           | Percentage\n",
      "   ---------- | --------------- | ----------\n",
      "   0 (Neg)    | 1,375,350       | 98.0392%\n",
      "   1 (Donor)  | 13,776          | 0.9820%\n",
      "   2 (Acc)    | 13,731          | 0.9788%\n",
      "========================================\n",
      "‚úÖ D·ªØ li·ªáu S·∫†CH (Kh√¥ng Null, Kh√¥ng Tr√πng).\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import sys\n",
    "import time\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "# C·∫§U H√åNH FILE\n",
    "FILE_PATH = r'C:\\Users\\dotru\\STUDIE\\FPTU\\AiTA_Lab\\Bio_sequence_Research_AITALAB\\train\\task1_splicing_prediction\\data_preparation\\train_val\\gtex_test_dataset.csv'\n",
    "MAX_RAM_IDS = 30_000_000  # Gi·ªõi h·∫°n l∆∞u 30 tri·ªáu ID ƒë·ªÉ tr√°nh tr√†n RAM\n",
    "\n",
    "def check_data_stats(file_path):\n",
    "    print(f\"üöÄ B·∫ÆT ƒê·∫¶U KI·ªÇM TRA FILE: {file_path}\")\n",
    "    \n",
    "    # 1. Kh·ªüi t·∫°o bi·∫øn ƒë·∫øm\n",
    "    stats = {\n",
    "        \"total_rows\": 0,\n",
    "        \"null_rows\": 0,       # D√≤ng c√≥ gi√° tr·ªã r·ªóng\n",
    "        \"duplicate_ids\": 0,   # ID b·ªã tr√πng\n",
    "    }\n",
    "    label_counts = Counter()  # ƒê·∫øm Value Count cho Label\n",
    "    seen_ids = set()          # Set l∆∞u ID ƒë·ªÉ check tr√πng\n",
    "    check_dup = True          # C·ªù b·∫≠t/t·∫Øt check tr√πng (b·∫£o v·ªá RAM)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            reader = csv.reader(f)\n",
    "            header = next(reader, None) # B·ªè qua header\n",
    "            \n",
    "            # Streaming Loop (ƒê·ªçc t·ª´ng d√≤ng -> X·ª≠ l√Ω -> X√≥a kh·ªèi RAM)\n",
    "            for row in tqdm(reader, desc=\"Scanning\", unit=\" rows\"):\n",
    "                stats[\"total_rows\"] += 1\n",
    "                \n",
    "                # Check c·∫•u tr√∫c c∆° b·∫£n (ƒë·ªÉ tr√°nh l·ªói index)\n",
    "                if len(row) < 3: continue \n",
    "                _id, _dna, _label = row[0], row[1], row[2]\n",
    "\n",
    "                # --- 1. CHECK NULL ---\n",
    "                if not _id.strip() or not _dna.strip() or not _label.strip():\n",
    "                    stats[\"null_rows\"] += 1\n",
    "\n",
    "                # --- 2. CHECK DUPLICATE ID ---\n",
    "                if check_dup:\n",
    "                    if _id in seen_ids:\n",
    "                        stats[\"duplicate_ids\"] += 1\n",
    "                    else:\n",
    "                        seen_ids.add(_id)\n",
    "                    \n",
    "                    # C∆° ch·∫ø an to√†n: T·ª± ng·∫Øt check l·∫∑p n·∫øu ID qu√° nhi·ªÅu (>30 tri·ªáu)\n",
    "                    if len(seen_ids) > MAX_RAM_IDS:\n",
    "                        print(\"‚ö†Ô∏è RAM Warning: T·∫°m d·ª´ng check Duplicate ƒë·ªÉ b·∫£o v·ªá m√°y.\")\n",
    "                        check_dup = False\n",
    "                        seen_ids.clear() # Gi·∫£i ph√≥ng RAM\n",
    "\n",
    "                # --- 3. VALUE COUNT (ƒê·∫øm Label) ---\n",
    "                label_counts[_label] += 1\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y file csv.\")\n",
    "        return\n",
    "\n",
    "    # --- 4. TH·ªêNG K√ä CLASS (B√ÅO C√ÅO) ---\n",
    "    total = stats[\"total_rows\"]\n",
    "    elapsed = time.time() - start_time\n",
    "\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(f\"üìä B·∫¢NG TH·ªêNG K√ä D·ªÆ LI·ªÜU (Time: {elapsed:.2f}s)\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    print(f\"1. T·ªîNG QUAN:\")\n",
    "    print(f\"   - T·ªïng s·ªë d√≤ng: {total:,}\")\n",
    "    print(f\"   - Null rows   : {stats['null_rows']:,}  ({(stats['null_rows']/total*100):.4f}%)\")\n",
    "    print(f\"   - Duplicate ID: {stats['duplicate_ids']:,}\")\n",
    "\n",
    "    print(f\"\\n2. VALUE COUNT & CLASS STATISTICS:\")\n",
    "    print(f\"   {'Label':<10} | {'Count':<15} | {'Percentage':<10}\")\n",
    "    print(f\"   {'-'*10} | {'-'*15} | {'-'*10}\")\n",
    "    \n",
    "    # S·∫Øp x·∫øp label theo th·ª© t·ª± 0, 1, 2\n",
    "    for label in sorted(label_counts.keys()):\n",
    "        count = label_counts[label]\n",
    "        percent = (count / total * 100) if total > 0 else 0\n",
    "        \n",
    "        # Mapping t√™n class cho d·ªÖ hi·ªÉu\n",
    "        label_name = label\n",
    "        if label == '0': label_name = \"0 (Neg)\"\n",
    "        elif label == '1': label_name = \"1 (Donor)\"\n",
    "        elif label == '2': label_name = \"2 (Acc)\"\n",
    "            \n",
    "        print(f\"   {label_name:<10} | {count:<15,} | {percent:.4f}%\")\n",
    "\n",
    "    print(\"=\"*40)\n",
    "\n",
    "    # ƒê√°nh gi√° nhanh\n",
    "    if stats['null_rows'] == 0 and stats['duplicate_ids'] == 0:\n",
    "        print(\"‚úÖ D·ªØ li·ªáu S·∫†CH (Kh√¥ng Null, Kh√¥ng Tr√πng).\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è D·ªØ li·ªáu C√ì V·∫§N ƒê·ªÄ. Vui l√≤ng ki·ªÉm tra l·∫°i logic sinh m·∫´u.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    check_data_stats(FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414ffb56",
   "metadata": {},
   "source": [
    "### Downscale class 0 from test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "947c9abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Splicing_types\n",
       "0    1375350\n",
       "1      13776\n",
       "2      13731\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r'C:\\Users\\dotru\\STUDIE\\FPTU\\AiTA_Lab\\Bio_sequence_Research_AITALAB\\train\\task1_splicing_prediction\\data_preparation\\train_val\\gtex_test_dataset.csv')\n",
    "df.value_counts('Splicing_types')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ca0c0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T·ªâ l·ªá 10:1:1 -> T·ªïng s·ªë m·∫´u: 165267\n",
      "0    137760\n",
      "1     13776\n",
      "2     13731\n",
      "Name: Splicing_types, dtype: int64\n",
      "------------------------------\n",
      "T·ªâ l·ªá 4:1:1 -> T·ªïng s·ªë m·∫´u: 82611\n",
      "0    55104\n",
      "1    13776\n",
      "2    13731\n",
      "Name: Splicing_types, dtype: int64\n",
      "------------------------------\n",
      "T·ªâ l·ªá 2:1:1 -> T·ªïng s·ªë m·∫´u: 55059\n",
      "0    27552\n",
      "1    13776\n",
      "2    13731\n",
      "Name: Splicing_types, dtype: int64\n",
      "------------------------------\n",
      "T·ªâ l·ªá 1:1:1 -> T·ªïng s·ªë m·∫´u: 41283\n",
      "0    13776\n",
      "1    13776\n",
      "2    13731\n",
      "Name: Splicing_types, dtype: int64\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "def undersample_by_ratio(df, label_col='Splicing_types', ratio_0=10, random_state=42):\n",
    "    \"\"\"\n",
    "    H√†m c·∫Øt gi·∫£m Class 0 theo t·ªâ l·ªá mong mu·ªën so v·ªõi Class 1.\n",
    "    Gi·ªØ nguy√™n Class 1 v√† Class 2.\n",
    "    \"\"\"\n",
    "    # T√°ch c√°c nh√≥m d·ªØ li·ªáu\n",
    "    df_0 = df[df[label_col] == 0]\n",
    "    df_1 = df[df[label_col] == 1]\n",
    "    df_2 = df[df[label_col] == 2]\n",
    "    \n",
    "    # L·∫•y s·ªë l∆∞·ª£ng c·ªßa Class 1 l√†m m·ªëc (8,822)\n",
    "    base_count = len(df_1)\n",
    "    \n",
    "    # T√≠nh s·ªë l∆∞·ª£ng c·∫ßn l·∫•y cho Class 0\n",
    "    target_n_0 = int(base_count * ratio_0)\n",
    "    \n",
    "    # Th·ª±c hi·ªán l·∫•y m·∫´u ng·∫´u nhi√™n cho Class 0\n",
    "    df_0_sampled = df_0.sample(n=min(len(df_0), target_n_0), random_state=random_state)\n",
    "    \n",
    "    # G·ªôp l·∫°i v√† x√°o tr·ªôn (shuffle) th·ª© t·ª± c√°c d√≤ng\n",
    "    df_final = pd.concat([df_0_sampled, df_1, df_2]).sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "    \n",
    "    return df_final\n",
    "\n",
    "ratios = [10, 4, 2, 1]\n",
    "datasets = {}\n",
    "\n",
    "for r in ratios:\n",
    "    name = f\"df_{r}_1_1\"\n",
    "    datasets[name] = undersample_by_ratio(df, ratio_0=r)\n",
    "    print(f\"T·ªâ l·ªá {r}:1:1 -> T·ªïng s·ªë m·∫´u: {len(datasets[name])}\")\n",
    "    print(datasets[name]['Splicing_types'].value_counts().sort_index())\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ddb0b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets['df_10_1_1'].to_csv(r'C:\\Users\\dotru\\STUDIE\\FPTU\\AiTA_Lab\\Bio_sequence_Research_AITALAB\\train\\task1_splicing_prediction\\data_preparation\\train_val\\gtex_test_10_1_1.csv', index=False)\n",
    "datasets['df_4_1_1'].to_csv(r'C:\\Users\\dotru\\STUDIE\\FPTU\\AiTA_Lab\\Bio_sequence_Research_AITALAB\\train\\task1_splicing_prediction\\data_preparation\\train_val\\gtex_test_4_1_1.csv', index=False)\n",
    "datasets['df_2_1_1'].to_csv(r'C:\\Users\\dotru\\STUDIE\\FPTU\\AiTA_Lab\\Bio_sequence_Research_AITALAB\\train\\task1_splicing_prediction\\data_preparation\\train_val\\gtex_test_2_1_1.csv', index=False)\n",
    "datasets['df_1_1_1'].to_csv(r'C:\\Users\\dotru\\STUDIE\\FPTU\\AiTA_Lab\\Bio_sequence_Research_AITALAB\\train\\task1_splicing_prediction\\data_preparation\\train_val\\gtex_test_1_1_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af09172d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
