{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb9b0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "import re\n",
    "import os\n",
    "\n",
    "# --- C·∫§U H√åNH ---\n",
    "FASTA_PATH = \"Homo_sapiens.GRCh38.pep.all.fa\"\n",
    "CSV_PATH = \"variant_annotated_official_clean.csv\"\n",
    "OUTPUT_PATH = \"variant_protein_sequence_101aa.csv\"\n",
    "\n",
    "WINDOW = 50 \n",
    "TARGET_LEN = 101 # 50 + 1 (ƒë·ªôt bi·∫øn) + 50\n",
    "PAD_CHAR = 'X'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787ed815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- H√ÄM TI·ªÜN √çCH ---\n",
    "\n",
    "def load_ensembl_protein_fasta(path):\n",
    "    \"\"\"\n",
    "    K·∫ø th·ª´a logic load genome: Map t·ª´ Transcript ID (ENST) sang Protein Sequence.\n",
    "    \"\"\"\n",
    "    mapping = {}\n",
    "    print(f\"üß¨ ƒêang n·∫°p FASTA t·ª´ {path}...\")\n",
    "    for record in SeqIO.parse(path, \"fasta\"):\n",
    "        # Tr√≠ch xu·∫•t ENST t·ª´ header: ... transcript:ENST00000641515.2 ...\n",
    "        match = re.search(r'transcript:(ENST\\d+)', record.description)\n",
    "        if match:\n",
    "            enst_id = match.group(1)\n",
    "            mapping[enst_id] = str(record.seq).upper()\n",
    "    print(f\"‚úÖ ƒê√£ n·∫°p {len(mapping)} m√£ transcript.\")\n",
    "    return mapping\n",
    "\n",
    "def normalize_centered_protein(seq, center_idx, target_len, pad_char='X'):\n",
    "    \"\"\"\n",
    "    K·∫ø th·ª´a ho√†n to√†n logic 'Symmetric Crop/Pad' t·ª´ notebook DNA c·ªßa b·∫°n.\n",
    "    \"\"\"\n",
    "    half = target_len // 2\n",
    "    start = center_idx - half\n",
    "    end = center_idx + half + 1\n",
    "    \n",
    "    pad_left = max(0, -start)\n",
    "    pad_right = max(0, end - len(seq))\n",
    "    \n",
    "    crop_left = max(0, start)\n",
    "    crop_right = min(len(seq), end)\n",
    "    \n",
    "    final_seq = (pad_char * pad_left) + seq[crop_left:crop_right] + (pad_char * pad_right)\n",
    "    return final_seq[:target_len] # ƒê·∫£m b·∫£o lu√¥n ƒë·ªß 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37da67b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- LOGIC X·ª¨ L√ù CH√çNH ---\n",
    "\n",
    "# 1. Load FASTA\n",
    "protein_dict = load_ensembl_protein_fasta(FASTA_PATH)\n",
    "\n",
    "# 2. ƒê·ªçc CSV theo chunk (cho 3 tri·ªáu d√≤ng)\n",
    "print(f\"üìä ƒêang x·ª≠ l√Ω file CSV: {CSV_PATH}\")\n",
    "chunk_size = 100000\n",
    "first_chunk = True\n",
    "\n",
    "for chunk in pd.read_csv(CSV_PATH, chunksize=chunk_size):\n",
    "    results = []\n",
    "    \n",
    "    for idx, row in chunk.iterrows():\n",
    "        try:\n",
    "            # Tr√≠ch xu·∫•t Transcript ID (Feature)\n",
    "            enst_id = str(row['Feature']).split('.')[0]\n",
    "            if enst_id not in protein_dict:\n",
    "                results.append((None, None))\n",
    "                continue\n",
    "            \n",
    "            full_ref_protein = protein_dict[enst_id]\n",
    "            \n",
    "            # X·ª≠ l√Ω v·ªã tr√≠ (L·∫•y s·ªë ƒë·∫ßu ti√™n n·∫øu l√† d·∫£i 226-228)\n",
    "            pos_str = str(row['Protein_position']).split('-')[0]\n",
    "            if pos_str == '-':\n",
    "                results.append((None, None))\n",
    "                continue\n",
    "            pos_1based = int(pos_str)\n",
    "            pos_0based = pos_1based - 1\n",
    "            \n",
    "            # X·ª≠ l√Ω Amino Acid (Ref/Alt)\n",
    "            aa_change = str(row['Amino_acids'])\n",
    "            if '/' not in aa_change:\n",
    "                results.append((None, None))\n",
    "                continue\n",
    "            ref_aa_part, alt_aa_part = aa_change.split('/')\n",
    "            \n",
    "            # --- X√ÅC MINH (K·∫ø th·ª´a verify_ref_seq_center) ---\n",
    "            actual_ref_aa = full_ref_protein[pos_0based : pos_0based + len(ref_aa_part)]\n",
    "            if actual_ref_aa != ref_aa_part:\n",
    "                # N·∫øu kh√¥ng kh·ªõp tuy·ªát ƒë·ªëi, ƒë√°nh d·∫•u l·ªói ho·∫∑c b·ªè qua\n",
    "                results.append((None, None))\n",
    "                continue\n",
    "\n",
    "            # --- T·∫†O CHU·ªñI ALT ---\n",
    "            # Thay th·∫ø ƒëo·∫°n ref b·∫±ng alt\n",
    "            alt_full_protein = (full_ref_protein[:pos_0based] + \n",
    "                                alt_aa_part + \n",
    "                                full_ref_protein[pos_0based + len(ref_aa_part):])\n",
    "            \n",
    "            # X·ª¨ L√ù NONSENSE/STOP: N·∫øu g·∫∑p * ho·∫∑c X trong ph·∫ßn Alt\n",
    "            # Bi·∫øn t·∫•t c·∫£ ph√≠a sau ƒëi·ªÉm d·ª´ng th√†nh PAD_CHAR 'X'\n",
    "            if '*' in alt_full_protein or 'X' in alt_aa_part:\n",
    "                stop_idx = alt_full_protein.find('*')\n",
    "                if stop_idx == -1: stop_idx = alt_full_protein.find('X', pos_0based)\n",
    "                # Gi·ªØ l·∫°i k√Ω t·ª± d·ª´ng, c√≤n l·∫°i ph√≠a sau l√† X\n",
    "                alt_full_protein = alt_full_protein[:stop_idx+1] + (PAD_CHAR * (len(full_ref_protein)))\n",
    "\n",
    "            # --- C·∫ÆT C·ª¨A S·ªî 101 AA ---\n",
    "            ref_101 = normalize_centered_protein(full_ref_protein, pos_0based, TARGET_LEN, PAD_CHAR)\n",
    "            alt_101 = normalize_centered_protein(alt_full_protein, pos_0based, TARGET_LEN, PAD_CHAR)\n",
    "            \n",
    "            results.append((ref_101, alt_101))\n",
    "            \n",
    "        except:\n",
    "            results.append((None, None))\n",
    "\n",
    "    # G√°n k·∫øt qu·∫£ v√†o chunk\n",
    "    chunk['prot_ref_seq'], chunk['prot_alt_seq'] = zip(*results)\n",
    "    \n",
    "    # L∆∞u xu·ªëng file (Append mode)\n",
    "    chunk.dropna(subset=['prot_ref_seq']).to_csv(\n",
    "        OUTPUT_PATH, \n",
    "        mode='a' if not first_chunk else 'w', \n",
    "        index=False, \n",
    "        header=first_chunk\n",
    "    )\n",
    "    first_chunk = False\n",
    "    print(f\" > ƒê√£ l∆∞u xong m·ªôt c·ª•m d·ªØ li·ªáu...\")\n",
    "\n",
    "print(f\"üéâ Ho√†n th√†nh! File k·∫øt qu·∫£: {OUTPUT_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
