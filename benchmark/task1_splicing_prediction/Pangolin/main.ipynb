{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fcd9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "import os\n",
    "from pyfaidx import Fasta\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from pangolin.model import Pangolin\n",
    "from pangolin.utils import sequence_to_onehot, rev_comp\n",
    "\n",
    "# Import hàm của bạn\n",
    "from metrics import compute_metrics\n",
    "\n",
    "# --- CẤU HÌNH ---\n",
    "FASTA_PATH = \"hg38.fa\" \n",
    "MODEL_WEIGHTS = \"final.1.0.3.v2\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "CONTEXT_WINDOW = 15000\n",
    "HALF_WINDOW = CONTEXT_WINDOW // 2\n",
    "\n",
    "TEST_FILES = ['test_1_1_1.csv', 'test_2_1_1.csv', 'test_4_1_1.csv', 'test_10_1_1.csv', 'test_data.csv']\n",
    "\n",
    "# --- KHỞI TẠO MODEL ---\n",
    "genome = Fasta(FASTA_PATH)\n",
    "model = Pangolin(L=CONTEXT_WINDOW)\n",
    "model.load_state_dict(torch.load(MODEL_WEIGHTS, map_location=DEVICE))\n",
    "model.to(DEVICE).eval()\n",
    "\n",
    "def get_sequence(chrom, pos, strand):\n",
    "    chrom_key = chrom if chrom.startswith(\"chr\") else f\"chr{chrom}\"\n",
    "    start, end = pos - HALF_WINDOW, pos + HALF_WINDOW\n",
    "    seq = genome[chrom_key][start:end].seq.upper()\n",
    "    return rev_comp(seq) if strand == '-' else seq\n",
    "\n",
    "def run_benchmark():\n",
    "    for file_name in TEST_FILES:\n",
    "        if not os.path.exists(file_name): continue\n",
    "            \n",
    "        print(f\"Đang xử lý: {file_name}...\")\n",
    "        df = pd.read_csv(file_name)\n",
    "        y_true = df['Splicing_types'].values\n",
    "        \n",
    "        preds_list = []\n",
    "        probs_list = []\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            parts = row['id'].split('_')\n",
    "            full_seq = get_sequence(parts[1], int(parts[2]), parts[3])\n",
    "            seq_tensor = sequence_to_onehot(full_seq).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                p_d, p_a = model(seq_tensor)\n",
    "                \n",
    "                # Lấy xác suất cao nhất giữa các mô (tissues) tại vị trí trung tâm\n",
    "                score_d = torch.max(p_d[0, HALF_WINDOW, :]).item()\n",
    "                score_a = torch.max(p_a[0, HALF_WINDOW, :]).item()\n",
    "\n",
    "                # Tính toán xác suất 3 lớp\n",
    "                score_n = max(0, 1 - (score_d + score_a))\n",
    "                total = score_n + score_d + score_a\n",
    "                prob_triple = [score_n/total, score_d/total, score_a/total]\n",
    "                \n",
    "                probs_list.append(prob_triple)\n",
    "                preds_list.append(np.argmax(prob_triple))\n",
    "\n",
    "        y_pred = np.array(preds_list)\n",
    "        probs = np.array(probs_list)\n",
    "\n",
    "        # 1. Tính toán metrics cơ bản từ hàm của bạn\n",
    "        metrics_results = compute_metrics(y_true, y_pred, probs)\n",
    "        \n",
    "        # 2. Tính toán Confusion Matrix cho 3 lớp\n",
    "        # Labels=[0, 1, 2] đảm bảo thứ tự ma trận là Neither, Donor, Acceptor\n",
    "        cm = confusion_matrix(y_true, y_pred, labels=[0, 1, 2])\n",
    "        \n",
    "        # 3. Thêm vào dict kết quả (Convert sang list để lưu JSON)\n",
    "        metrics_results['confusion_matrix'] = cm.tolist()\n",
    "        metrics_results['labels_order'] = ['Neither', 'Donor', 'Acceptor']\n",
    "\n",
    "        # Lưu kết quả\n",
    "        output_name = file_name.replace('.csv', '_results.json')\n",
    "        with open(output_name, 'w', encoding='utf-8') as f:\n",
    "            json.dump(metrics_results, f, indent=4, ensure_ascii=False)\n",
    "            \n",
    "        print(f\"Đã lưu kết quả vào {output_name}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
