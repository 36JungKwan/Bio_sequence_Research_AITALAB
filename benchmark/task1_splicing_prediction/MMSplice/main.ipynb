{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9a913ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pandas numpy==1.23.5 tensorflow-gpu==2.10.1 scikit-learn tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30f5d98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install -c conda-forge cudatoolkit=11.2 cudnn=8.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b521ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng GPU khả dụng:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Số lượng GPU khả dụng: \", len(tf.config.list_logical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03407f29",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6e0de321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang load models từ file .h5...\n",
      "Load donor thành công!\n",
      "Load acceptor thành công!\n",
      "Processing test_1_1_1.csv...\n",
      "Donor scores: Min=0.0006, Max=0.9998, Mean=0.3565\n",
      "Acceptor scores: Min=0.0000, Max=0.9999, Mean=0.3057\n",
      "Processing test_2_1_1.csv...\n",
      "Donor scores: Min=0.0006, Max=0.9998, Mean=0.2997\n",
      "Acceptor scores: Min=0.0000, Max=0.9999, Mean=0.2496\n",
      "Processing test_4_1_1.csv...\n",
      "Donor scores: Min=0.0006, Max=0.9998, Mean=0.2438\n",
      "Acceptor scores: Min=0.0000, Max=0.9999, Mean=0.1922\n",
      "Processing test_10_1_1.csv...\n",
      "Donor scores: Min=0.0006, Max=0.9998, Mean=0.1880\n",
      "Acceptor scores: Min=0.0000, Max=0.9999, Mean=0.1361\n",
      "Processing test_data.csv...\n",
      "Donor scores: Min=0.0004, Max=0.9998, Mean=0.1379\n",
      "Acceptor scores: Min=0.0000, Max=0.9999, Mean=0.0857\n",
      "Xong!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from metrics import compute_metrics # Hàm của bạn\n",
    "\n",
    "# --- CẤU HÌNH ĐƯỜNG DẪN ---\n",
    "MODEL_PATH = r'D:\\my_project\\Bio_paper\\Bio_sequence_Research_AITALAB\\benchmark\\task1_splicing_prediction\\MMSplice\\pretrained_model' # Thư mục chứa donor.h5 và acceptor.h5\n",
    "DATA_FOLDER = r'D:\\my_project\\Bio_paper\\Bio_sequence_Research_AITALAB\\train\\task1_splicing_prediction\\data_preparation\\train_val'\n",
    "RESULTS_FOLDER = 'results'\n",
    "TEST_FILES = ['test_1_1_1.csv', 'test_2_1_1.csv', 'test_4_1_1.csv', 'test_10_1_1.csv', 'test_data.csv']\n",
    "\n",
    "os.makedirs(RESULTS_FOLDER, exist_ok=True)\n",
    "\n",
    "# Tự định nghĩa lại lớp ConvDNA để xử lý các tham số lạ từ file .h5\n",
    "class ConvDNA(Conv1D):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        # Lấy seq_length ra nếu có, nếu không thì bỏ qua \n",
    "        # (pop giúp loại bỏ nó khỏi kwargs để không gây lỗi cho Conv1D)\n",
    "        self.seq_length = kwargs.pop('seq_length', None)\n",
    "        \n",
    "        # Nếu mô hình còn các tham số \"lạ\" khác, bạn có thể pop tương tự\n",
    "        # Hoặc dùng cách an toàn hơn bên dưới:\n",
    "        super(ConvDNA, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(ConvDNA, self).get_config()\n",
    "        config.update({'seq_length': self.seq_length})\n",
    "        return config\n",
    "\n",
    "# Bây giờ truyền nó vào custom_objects\n",
    "custom_objs = {'ConvDNA': ConvDNA}\n",
    "\n",
    "# --- LOAD MODELS TRỰC TIẾP ---\n",
    "print(\"Đang load models từ file .h5...\")\n",
    "donor_model = tf.keras.models.load_model(\n",
    "        os.path.join(MODEL_PATH, 'donor.h5'), \n",
    "        compile=False, \n",
    "        custom_objects=custom_objs\n",
    "    )\n",
    "print(\"Load donor thành công!\")\n",
    "\n",
    "acceptor_model = tf.keras.models.load_model(\n",
    "    os.path.join(MODEL_PATH, 'acceptor.h5'), \n",
    "    compile=False, \n",
    "    custom_objects=custom_objs\n",
    ")\n",
    "print(\"Load acceptor thành công!\")\n",
    "\n",
    "# --- CÁC HÀM XỬ LÝ CHUỖI ---\n",
    "def reverse_complement(seq):\n",
    "    complement = {'A': 'T', 'C': 'G', 'G': 'C', 'T': 'A', 'N': 'N'}\n",
    "    return \"\".join(complement.get(base, base) for base in reversed(seq.upper()))\n",
    "\n",
    "def one_hot_dna(seq):\n",
    "    mapping = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n",
    "    arr = np.zeros((len(seq), 4), dtype=np.float32)\n",
    "    for i, base in enumerate(seq.upper()):\n",
    "        if base in mapping:\n",
    "            arr[i, mapping[base]] = 1.0\n",
    "    return arr\n",
    "\n",
    "# --- PIPELINE INFERENCE ---\n",
    "def run_pipeline(file_name):\n",
    "    df = pd.read_csv(os.path.join(DATA_FOLDER, file_name))\n",
    "    y_true = df['Splicing_types'].values\n",
    "    \n",
    "    d_inputs, a_inputs = [], []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        seq = row['sequence']\n",
    "        mid = len(seq) // 2\n",
    "        # Donor (9bp): 3bp Exon | 6bp Intron\n",
    "        d_inputs.append(one_hot_dna(seq[mid-5 : mid+13]))\n",
    "        # Acceptor (50bp): 40bp Intron | 10bp Exon\n",
    "        a_inputs.append(one_hot_dna(seq[mid-49 : mid+4]))\n",
    "\n",
    "    # Predict Batch\n",
    "    d_scores = donor_model.predict(np.stack(d_inputs), batch_size=512, verbose=0).flatten()\n",
    "    a_scores = acceptor_model.predict(np.stack(a_inputs), batch_size=512, verbose=0).flatten()\n",
    "\n",
    "    print(f\"Donor scores: Min={d_scores.min():.4f}, Max={d_scores.max():.4f}, Mean={d_scores.mean():.4f}\")\n",
    "    print(f\"Acceptor scores: Min={a_scores.min():.4f}, Max={a_scores.max():.4f}, Mean={a_scores.mean():.4f}\")\n",
    "    \n",
    "    # 1. Tạo ma trận xác suất (Sử dụng Normalization thay vì Softmax)\n",
    "    y_probs = np.zeros((len(d_scores), 3))\n",
    "    y_probs[:, 1] = d_scores\n",
    "    y_probs[:, 2] = a_scores\n",
    "    y_probs[:, 0] = 1 - np.maximum(d_scores, a_scores)\n",
    "    \n",
    "    # Chuẩn hóa để tổng mỗi hàng = 1 cho AUC metrics\n",
    "    row_sums = y_probs.sum(axis=1, keepdims=True)\n",
    "    y_probs = y_probs / np.where(row_sums == 0, 1e-10, row_sums)\n",
    "    \n",
    "    # 2. Tạo nhãn dự đoán (y_pred) \n",
    "    # Nếu bạn muốn dùng Threshold để ưu tiên lớp hiếm (Donor/Acceptor)\n",
    "    THRESHOLD = 0.48\n",
    "    y_pred = []\n",
    "    for d, a in zip(d_scores, a_scores):\n",
    "        if d > THRESHOLD and d > a: \n",
    "            y_pred.append(1)\n",
    "        elif a > THRESHOLD and a > d: \n",
    "            y_pred.append(2)\n",
    "        else: \n",
    "            y_pred.append(0)\n",
    "            \n",
    "    return y_true, np.array(y_pred), y_probs\n",
    "\n",
    "# --- CHẠY VÀ LƯU KẾT QUẢ ---\n",
    "for f in TEST_FILES:\n",
    "    print(f\"Processing {f}...\")\n",
    "    y_true, y_pred, y_probs = run_pipeline(f)\n",
    "    \n",
    "    res = {\n",
    "        \"metrics\": compute_metrics(y_true, y_pred, y_probs),\n",
    "        \"confusion_matrix\": confusion_matrix(y_true, y_pred, labels=[0, 1, 2]).tolist()\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(RESULTS_FOLDER, f.replace('.csv', '_results.json')), 'w') as out:\n",
    "        json.dump(res, out, indent=4)\n",
    "\n",
    "print(\"Xong!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d03ca320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Kiểm tra Motif Donor (Cần GT ở vị trí cắt) ---\n",
      "Sequence: ...AG | GT... -> Motif: GT\n",
      "Sequence: ...AG | GT... -> Motif: GT\n",
      "Sequence: ...AG | GT... -> Motif: GT\n",
      "Sequence: ...AG | GT... -> Motif: GT\n",
      "Sequence: ...AG | GT... -> Motif: GT\n",
      "Sequence: ...GG | GC... -> Motif: GC\n",
      "Sequence: ...AG | GT... -> Motif: GT\n",
      "Sequence: ...GT | GT... -> Motif: GT\n",
      "Sequence: ...AG | GT... -> Motif: GT\n",
      "Sequence: ...AG | GT... -> Motif: GT\n"
     ]
    }
   ],
   "source": [
    "def check_motifs(df, num_samples=10):\n",
    "    mid = len(df.iloc[0]['sequence']) // 2\n",
    "    print(\"--- Kiểm tra Motif Donor (Cần GT ở vị trí cắt) ---\")\n",
    "    donors = df[df['Splicing_types'] == 1].sample(num_samples)\n",
    "    for _, row in donors.iterrows():\n",
    "        # Giả sử mid là vị trí bắt đầu Intron\n",
    "        seq = row['sequence']\n",
    "        # In ra 2 base tại vị trí cắt\n",
    "        print(f\"Sequence: ...{seq[mid-2:mid]} | {seq[mid:mid+2]}... -> Motif: {seq[mid:mid+2]}\")\n",
    "\n",
    "df = pd.read_csv(r'D:\\my_project\\Bio_paper\\Bio_sequence_Research_AITALAB\\train\\task1_splicing_prediction\\data_preparation\\train_val\\test_1_1_1.csv')\n",
    "check_motifs(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "652e8e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Đang tìm vị trí vàng cho Donor ---\n",
      "Offset -5 (Mid=295): Avg Score = 0.0676\n",
      "Offset -4 (Mid=296): Avg Score = 0.0594\n",
      "Offset -3 (Mid=297): Avg Score = 0.2209\n",
      "Offset -2 (Mid=298): Avg Score = 0.8679\n",
      "Offset -1 (Mid=299): Avg Score = 0.0237\n",
      "Offset 0 (Mid=300): Avg Score = 0.0281\n",
      "Offset 1 (Mid=301): Avg Score = 0.0352\n",
      "Offset 2 (Mid=302): Avg Score = 0.0754\n",
      "Offset 3 (Mid=303): Avg Score = 0.0607\n",
      "Offset 4 (Mid=304): Avg Score = 0.0436\n",
      "Offset 5 (Mid=305): Avg Score = 0.0554\n",
      "==> Donor nên cắt tại mid = 300 + (-2)\n"
     ]
    }
   ],
   "source": [
    "def find_best_offset(df, model, label_type):\n",
    "    results = []\n",
    "    # Chỉ lấy các mẫu chuẩn (True Label) để test\n",
    "    test_df = df[df['Splicing_types'] == label_type]\n",
    "    \n",
    "    for offset in range(-5, 6): # Thử từ 295 đến 305\n",
    "        mid = 300 + offset\n",
    "        inputs = []\n",
    "        for seq in test_df['sequence']:\n",
    "            if label_type == 1: # Donor\n",
    "                inputs.append(one_hot_dna(seq[mid-3 : mid+15]))\n",
    "            else: # Acceptor\n",
    "                inputs.append(one_hot_dna(seq[mid-50 : mid+3]))\n",
    "        \n",
    "        preds = model.predict(np.array(inputs), verbose=0)\n",
    "        avg_score = np.mean(preds)\n",
    "        results.append((offset, avg_score))\n",
    "        print(f\"Offset {offset} (Mid={mid}): Avg Score = {avg_score:.4f}\")\n",
    "    \n",
    "    best_offset = max(results, key=lambda x: x[1])\n",
    "    return best_offset\n",
    "\n",
    "# Chạy thử cho Donor\n",
    "print(\"--- Đang tìm vị trí vàng cho Donor ---\")\n",
    "best_d = find_best_offset(df, donor_model, 1)\n",
    "print(f\"==> Donor nên cắt tại mid = 300 + ({best_d[0]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1dd6a56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Đang tìm vị trí vàng cho Acceptor ---\n",
      "Offset -5 (Mid=295): Avg Score = 0.1180\n",
      "Offset -4 (Mid=296): Avg Score = 0.1109\n",
      "Offset -3 (Mid=297): Avg Score = 0.1268\n",
      "Offset -2 (Mid=298): Avg Score = 0.1745\n",
      "Offset -1 (Mid=299): Avg Score = 0.1912\n",
      "Offset 0 (Mid=300): Avg Score = 0.2024\n",
      "Offset 1 (Mid=301): Avg Score = 0.8210\n",
      "Offset 2 (Mid=302): Avg Score = 0.0711\n",
      "Offset 3 (Mid=303): Avg Score = 0.0530\n",
      "Offset 4 (Mid=304): Avg Score = 0.1062\n",
      "Offset 5 (Mid=305): Avg Score = 0.0856\n",
      "==> Acceptor nên cắt tại mid = 300 + (1)\n"
     ]
    }
   ],
   "source": [
    "def find_best_offset(df, model, label_type):\n",
    "    results = []\n",
    "    # Chỉ lấy các mẫu chuẩn (True Label) để test\n",
    "    test_df = df[df['Splicing_types'] == label_type]\n",
    "    \n",
    "    for offset in range(-5, 6): # Thử từ 295 đến 305\n",
    "        mid = 300 + offset\n",
    "        inputs = []\n",
    "        for seq in test_df['sequence']:\n",
    "            if label_type == 1: # Donor\n",
    "                inputs.append(one_hot_dna(seq[mid-3 : mid+15]))\n",
    "            else: # Acceptor\n",
    "                inputs.append(one_hot_dna(seq[mid-50 : mid+3]))\n",
    "        \n",
    "        preds = model.predict(np.array(inputs), verbose=0)\n",
    "        avg_score = np.mean(preds)\n",
    "        results.append((offset, avg_score))\n",
    "        print(f\"Offset {offset} (Mid={mid}): Avg Score = {avg_score:.4f}\")\n",
    "    \n",
    "    best_offset = max(results, key=lambda x: x[1])\n",
    "    return best_offset\n",
    "\n",
    "# Chạy thử cho Acceptor\n",
    "print(\"--- Đang tìm vị trí vàng cho Acceptor ---\")\n",
    "best_d = find_best_offset(df, acceptor_model, 2)\n",
    "print(f\"==> Acceptor nên cắt tại mid = 300 + ({best_d[0]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67aacbb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cấu trúc Donor Model:\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ss (InputLayer)             [(None, 18, 4)]           0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 72)                0         \n",
      "                                                                 \n",
      " dense1 (Dense)              (None, 128)               9344      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense2 (Dense)              (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_2 (ReLU)              (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,433\n",
      "Trainable params: 18,049\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "\n",
      "Cấu trúc Acceptor Model:\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ss (InputLayer)             [(None, 53, 4)]           0         \n",
      "                                                                 \n",
      " convSpliceSite (ConvDNA)    (None, 53, 32)            1952      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 53, 32)           128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1by1 (Conv1D)           (None, 53, 32)            1056      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 53, 32)           128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1696)              0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1696)              0         \n",
      "                                                                 \n",
      " denseSS (Dense)             (None, 1)                 1697      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,961\n",
      "Trainable params: 4,833\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"Cấu trúc Donor Model:\")\n",
    "donor_model.summary()\n",
    "\n",
    "print(\"\\nCấu trúc Acceptor Model:\")\n",
    "acceptor_model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmsplice_official",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
