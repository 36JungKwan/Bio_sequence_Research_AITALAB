{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a56fc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch  # Chuy·ªÉn t·ª´ TF sang Torch\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from metrics import compute_metrics\n",
    "from data_preparation import prepare_csv_datasets\n",
    "\n",
    "# ƒê∆∞·ªùng d·∫´n t·ªõi file model SPLAM (th∆∞·ªùng l√† splam_script.pt)\n",
    "MODEL_PATH = r\"D:\\Bio_sequence_Research_AITALAB\\SPLAM\\models\\splam_script.pt\"\n",
    "PREPARED_FOLDER = \"prepared_data/\"\n",
    "RESULTS_DIR = \"results/\"\n",
    "BATCH_SIZE = 256  \n",
    "CONTEXT = 400     \n",
    "TARGET_LEN = 800\n",
    "test_files = ['test_1_1_1.csv', 'test_2_1_1.csv', 'test_4_1_1.csv', 'test_10_1_1.csv', 'test_data.csv']\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499b7a52",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f280a847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:57:43] Loading Genome with pyfaidx...\n",
      "Sorting test_1_1_1.csv for sequential disk access...\n",
      "üöÄ Processing: test_1_1_1.csv (26310 rows)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26310/26310 [00:01<00:00, 24702.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Type       | Window around center (-2 to +2) | Found?\n",
      "-----------------------------------------------------------------\n",
      "Donor      | AA[GG]TT                  | ‚ùå (Target: GT)\n",
      "Donor      | CA[GG]TA                  | ‚ùå (Target: GT)\n",
      "Donor      | CA[AG]TA                  | ‚ùå (Target: GT)\n",
      "Donor      | AA[GG]TA                  | ‚ùå (Target: GT)\n",
      "Donor      | AT[GG]TG                  | ‚ùå (Target: GT)\n",
      "Acceptor   | AT[AG]GT                  | ‚úÖ (Target: AG)\n",
      "Acceptor   | CC[AG]AG                  | ‚úÖ (Target: AG)\n",
      "Acceptor   | GA[AG]GT                  | ‚úÖ (Target: AG)\n",
      "Acceptor   | GC[AG]GT                  | ‚úÖ (Target: AG)\n",
      "Acceptor   | AG[AG]CC                  | ‚úÖ (Target: AG)\n",
      "‚úÖ Saved to prepared_data/test_1_1_1.csv | Speed: 8493.61 seq/s\n",
      "\n",
      "Sorting test_2_1_1.csv for sequential disk access...\n",
      "üöÄ Processing: test_2_1_1.csv (35132 rows)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 35132/35132 [00:01<00:00, 24192.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Type       | Window around center (-2 to +2) | Found?\n",
      "-----------------------------------------------------------------\n",
      "Donor      | GG[TA]AT                  | ‚ùå (Target: GT)\n",
      "Donor      | GA[GG]TG                  | ‚ùå (Target: GT)\n",
      "Donor      | GG[TA]AA                  | ‚ùå (Target: GT)\n",
      "Donor      | AA[GG]TG                  | ‚ùå (Target: GT)\n",
      "Donor      | GG[TA]AG                  | ‚ùå (Target: GT)\n",
      "Acceptor   | CC[AG]TG                  | ‚úÖ (Target: AG)\n",
      "Acceptor   | GC[AG]CC                  | ‚úÖ (Target: AG)\n",
      "Acceptor   | TC[AG]AA                  | ‚úÖ (Target: AG)\n",
      "Acceptor   | TC[AG]GC                  | ‚úÖ (Target: AG)\n",
      "Acceptor   | TT[AG]GA                  | ‚úÖ (Target: AG)\n",
      "‚úÖ Saved to prepared_data/test_2_1_1.csv | Speed: 8355.16 seq/s\n",
      "\n",
      "Sorting test_4_1_1.csv for sequential disk access...\n",
      "üöÄ Processing: test_4_1_1.csv (52776 rows)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 52776/52776 [00:02<00:00, 23726.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Type       | Window around center (-2 to +2) | Found?\n",
      "-----------------------------------------------------------------\n",
      "Donor      | GG[TA]AG                  | ‚ùå (Target: GT)\n",
      "Donor      | CC[GG]TG                  | ‚ùå (Target: GT)\n",
      "Donor      | GG[TC]AG                  | ‚ùå (Target: GT)\n",
      "Donor      | GG[TG]AG                  | ‚ùå (Target: GT)\n",
      "Donor      | GA[GG]TA                  | ‚ùå (Target: GT)\n",
      "Acceptor   | TC[AG]GT                  | ‚úÖ (Target: AG)\n",
      "Acceptor   | AG[AG]AA                  | ‚úÖ (Target: AG)\n",
      "Acceptor   | AC[AG]TT                  | ‚úÖ (Target: AG)\n",
      "Acceptor   | GC[AG]GA                  | ‚úÖ (Target: AG)\n",
      "Acceptor   | AG[GT]GG                  | ‚ùå (Target: AG)\n",
      "‚úÖ Saved to prepared_data/test_4_1_1.csv | Speed: 8139.52 seq/s\n",
      "\n",
      "Sorting test_10_1_1.csv for sequential disk access...\n",
      "üöÄ Processing: test_10_1_1.csv (105708 rows)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105708/105708 [00:04<00:00, 24718.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Type       | Window around center (-2 to +2) | Found?\n",
      "-----------------------------------------------------------------\n",
      "Donor      | GG[TT]AG                  | ‚ùå (Target: GT)\n",
      "Donor      | CA[GG]TA                  | ‚ùå (Target: GT)\n",
      "Donor      | AC[GG]TG                  | ‚ùå (Target: GT)\n",
      "Donor      | GG[TC]AG                  | ‚ùå (Target: GT)\n",
      "Donor      | AA[GG]TA                  | ‚ùå (Target: GT)\n",
      "Acceptor   | AG[CT]GC                  | ‚ùå (Target: AG)\n",
      "Acceptor   | GC[AG]TA                  | ‚úÖ (Target: AG)\n",
      "Acceptor   | AG[GT]GG                  | ‚ùå (Target: AG)\n",
      "Acceptor   | AG[AG]GG                  | ‚úÖ (Target: AG)\n",
      "Acceptor   | CC[AG]CA                  | ‚úÖ (Target: AG)\n",
      "‚úÖ Saved to prepared_data/test_10_1_1.csv | Speed: 8423.27 seq/s\n",
      "\n",
      "Sorting test_data.csv for sequential disk access...\n",
      "üöÄ Processing: test_data.csv (938297 rows)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 938297/938297 [00:37<00:00, 25041.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Type       | Window around center (-2 to +2) | Found?\n",
      "-----------------------------------------------------------------\n",
      "Donor      | GG[TG]AG                  | ‚ùå (Target: GT)\n",
      "Donor      | GG[TG]AG                  | ‚ùå (Target: GT)\n",
      "Donor      | GG[TA]AG                  | ‚ùå (Target: GT)\n",
      "Donor      | GA[GG]TG                  | ‚ùå (Target: GT)\n",
      "Donor      | AA[GG]TG                  | ‚ùå (Target: GT)\n",
      "Acceptor   | AG[CT]GT                  | ‚ùå (Target: AG)\n",
      "Acceptor   | CT[AG]GC                  | ‚úÖ (Target: AG)\n",
      "Acceptor   | CT[AG]TG                  | ‚úÖ (Target: AG)\n",
      "Acceptor   | AG[GG]CG                  | ‚ùå (Target: AG)\n",
      "Acceptor   | CC[AG]GG                  | ‚úÖ (Target: AG)\n",
      "‚úÖ Saved to prepared_data/test_data.csv | Speed: 8451.58 seq/s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(PREPARED_FOLDER, exist_ok=True)\n",
    "prepare_csv_datasets(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6a75a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(r'D:\\Bio_sequence_Research_AITALAB\\benchmark\\task1_splicing_prediction\\SpliceAI\\prepared_data\\test_1_1_1.csv')\n",
    "# # Ki·ªÉm tra 5 m·∫´u Donor ƒë·∫ßu ti√™n\n",
    "# donor_samples = df[df['Splicing_types'] == 1]['sequence'].values[:5]\n",
    "# for i, seq in enumerate(donor_samples):\n",
    "#     # L·∫•y v√πng trung t√¢m (index 5000 l√† nucleotide t·∫°i v·ªã tr√≠ pos)\n",
    "#     center = seq[5000:5002] \n",
    "#     print(f\"Donor {i}: V·ªã tr√≠ trung t√¢m l√† '{center}' (K·ª≥ v·ªçng th∆∞·ªùng l√† GT)\")\n",
    "\n",
    "# # Ki·ªÉm tra 5 m·∫´u Acceptor ƒë·∫ßu ti√™n\n",
    "# acceptor_samples = df[df['Splicing_types'] == 2]['sequence'].values[:5]\n",
    "# for i, seq in enumerate(acceptor_samples):\n",
    "#     center = seq[5000:5002]\n",
    "#     print(f\"Acceptor {i}: V·ªã tr√≠ trung t√¢m l√† '{center}' (K·ª≥ v·ªçng th∆∞·ªùng l√† AG)\")\n",
    "\n",
    "# def diagnose_splice_sites(df, sample_size=5):\n",
    "#     print(f\"{'Type':<10} | {'Window (-5 to +5 around center)':<20} | {'Found?'}\")\n",
    "#     print(\"-\" * 50)\n",
    "    \n",
    "#     for label, name in [(1, 'Donor'), (2, 'Acceptor')]:\n",
    "#         samples = df[df['Splicing_types'] == label].sample(min(sample_size, len(df)))\n",
    "#         for _, row in samples.iterrows():\n",
    "#             seq = row['sequence']\n",
    "#             # L·∫•y 11 nucleotide (v·ªã tr√≠ 5000 l√† trung t√¢m)\n",
    "#             window = seq[4995:5006]\n",
    "            \n",
    "#             target = \"GT\" if label == 1 else \"AG\"\n",
    "#             found = \"‚úÖ\" if target in window else \"‚ùå\"\n",
    "            \n",
    "#             # Highlight v·ªã tr√≠ trung t√¢m b·∫±ng d·∫•u ngo·∫∑c []\n",
    "#             display_win = window[:5] + \"[\" + window[5:7] + \"]\" + window[7:]\n",
    "#             print(f\"{name:<10} | {display_win:<20} | {found} (Target: {target})\")\n",
    "\n",
    "# # Ch·∫°y sau khi load df t·ª´ prepared_data\n",
    "# diagnose_splice_sites(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03407f29",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64f1a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model SPLAM (TorchScript)\n",
    "print(f\"Loading SPLAM Model on {device}...\")\n",
    "model = torch.jit.load(MODEL_PATH)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print(\"Successfully loaded SPLAM model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0de321",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Progress:   0%|          | 0/5 [00:00<?, ?file/s, file=test_1_1_1.csv]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ƒêANG KI·ªÇM TRA ONE-HOT ENCODING ---\n",
      "‚úÖ H√ÄNG 14218: Kh·ªõp ho√†n to√†n (ƒê·ªô d√†i: 10001)\n",
      "‚úÖ H√ÄNG 18004: Kh·ªõp ho√†n to√†n (ƒê·ªô d√†i: 10001)\n",
      "‚úÖ H√ÄNG 15326: Kh·ªõp ho√†n to√†n (ƒê·ªô d√†i: 10001)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206/206 [==============================] - 65s 306ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206/206 [==============================] - 62s 302ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206/206 [==============================] - 62s 301ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206/206 [==============================] - 62s 301ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206/206 [==============================] - 62s 301ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Ki·ªÉm tra ph√¢n ph·ªëi x√°c su·∫•t cho test_1_1_1.csv ---"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Progress:  20%|‚ñà‚ñà        | 1/5 [05:15<21:01, 315.36s/file, file=test_2_1_1.csv]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   Nh√£n 1: Avg = 0.382683, Max = 0.999861\n",
      "   Nh√£n 2: Avg = 0.322296, Max = 0.999870\n",
      "‚úÖ test_1_1_1.csv | Enc: 65.13s | Total: 313.84s\n",
      "--- ƒêANG KI·ªÇM TRA ONE-HOT ENCODING ---\n",
      "‚úÖ H√ÄNG 20332: Kh·ªõp ho√†n to√†n (ƒê·ªô d√†i: 10001)\n",
      "‚úÖ H√ÄNG 29545: Kh·ªõp ho√†n to√†n (ƒê·ªô d√†i: 10001)\n",
      "‚úÖ H√ÄNG 15602: Kh·ªõp ho√†n to√†n (ƒê·ªô d√†i: 10001)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 79s 289ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 76s 279ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 76s 278ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 82s 298ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 82s 300ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Progress:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [11:53<18:12, 364.00s/file, file=test_4_1_1.csv]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Ki·ªÉm tra ph√¢n ph·ªëi x√°c su·∫•t cho test_2_1_1.csv ---\n",
      "   Nh√£n 1: Avg = 0.382683, Max = 0.999861\n",
      "   Nh√£n 2: Avg = 0.322296, Max = 0.999870\n",
      "‚úÖ test_2_1_1.csv | Enc: 79.22s | Total: 395.89s\n",
      "--- ƒêANG KI·ªÇM TRA ONE-HOT ENCODING ---\n",
      "‚úÖ H√ÄNG 38910: Kh·ªõp ho√†n to√†n (ƒê·ªô d√†i: 10001)\n",
      "‚úÖ H√ÄNG 36961: Kh·ªõp ho√†n to√†n (ƒê·ªô d√†i: 10001)\n",
      "‚úÖ H√ÄNG 6545: Kh·ªõp ho√†n to√†n (ƒê·ªô d√†i: 10001)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413/413 [==============================] - 121s 293ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413/413 [==============================] - 115s 280ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413/413 [==============================] - 123s 298ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413/413 [==============================] - 124s 301ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413/413 [==============================] - 124s 301ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Ki·ªÉm tra ph√¢n ph·ªëi x√°c su·∫•t cho test_4_1_1.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Progress:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [22:04<15:53, 476.67s/file, file=test_10_1_1.csv]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Nh√£n 1: Avg = 0.382683, Max = 0.999861\n",
      "   Nh√£n 2: Avg = 0.322296, Max = 0.999870\n",
      "‚úÖ test_4_1_1.csv | Enc: 120.95s | Total: 607.55s\n",
      "--- ƒêANG KI·ªÇM TRA ONE-HOT ENCODING ---\n",
      "‚úÖ H√ÄNG 11114: Kh·ªõp ho√†n to√†n (ƒê·ªô d√†i: 10001)\n",
      "‚úÖ H√ÄNG 22244: Kh·ªõp ho√†n to√†n (ƒê·ªô d√†i: 10001)\n",
      "‚úÖ H√ÄNG 2553: Kh·ªõp ho√†n to√†n (ƒê·ªô d√†i: 10001)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "826/826 [==============================] - 232s 281ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "826/826 [==============================] - 240s 290ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "826/826 [==============================] - 247s 299ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "826/826 [==============================] - 234s 283ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "826/826 [==============================] - 230s 279ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Ki·ªÉm tra ph√¢n ph·ªëi x√°c su·∫•t cho test_10_1_1.csv ---"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Progress:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [41:55<12:38, 758.62s/file, file=test_data.csv]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   Nh√£n 1: Avg = 0.382683, Max = 0.999861\n",
      "   Nh√£n 2: Avg = 0.322296, Max = 0.999870\n",
      "‚úÖ test_10_1_1.csv | Enc: 232.37s | Total: 1183.38s\n",
      "--- ƒêANG KI·ªÇM TRA ONE-HOT ENCODING ---\n",
      "‚úÖ H√ÄNG 458967: Kh·ªõp ho√†n to√†n (ƒê·ªô d√†i: 10001)\n",
      "‚úÖ H√ÄNG 34906: Kh·ªõp ho√†n to√†n (ƒê·ªô d√†i: 10001)\n",
      "‚úÖ H√ÄNG 287788: Kh·ªõp ho√†n to√†n (ƒê·ªô d√†i: 10001)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7331/7331 [==============================] - 2114s 288ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7331/7331 [==============================] - 2187s 298ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7331/7331 [==============================] - 2187s 298ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7331/7331 [==============================] - 2187s 298ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7331/7331 [==============================] - 2061s 281ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Ki·ªÉm tra ph√¢n ph·ªëi x√°c su·∫•t cho test_data.csv ---\n",
      "   Nh√£n 1: Avg = 0.382683, Max = 0.999861\n",
      "   Nh√£n 2: Avg = 0.322296, Max = 0.999870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Progress: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [3:41:42<00:00, 2660.57s/file, file=test_data.csv]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ test_data.csv | Enc: 2115.72s | Total: 10740.92s\n",
      "\n",
      "‚ú® ALL DATASETS PROCESSED SUCCESSFULLY!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "def one_hot_encode_splam(seq):\n",
    "    \"\"\"\n",
    "    Encoding cho SPLAM: Shape (4, 800)\n",
    "    Th·ª© t·ª± base: A, C, G, T\n",
    "    \"\"\"\n",
    "    seq_code = np.zeros((4, len(seq)), dtype=np.float32)\n",
    "    seq = seq.upper()\n",
    "    sn = np.frombuffer(seq.encode('ascii'), dtype=np.int8)\n",
    "    \n",
    "    seq_code[0, sn == ord('A')] = 1.0\n",
    "    seq_code[1, sn == ord('C')] = 1.0\n",
    "    seq_code[2, sn == ord('G')] = 1.0\n",
    "    seq_code[3, sn == ord('T')] = 1.0\n",
    "    return seq_code\n",
    "\n",
    "def get_batches(sequences, batch_size):\n",
    "    for i in range(0, len(sequences), batch_size):\n",
    "        batch_seqs = sequences[i:i + batch_size]\n",
    "        # Encode v√† stack th√†nh tensor (Batch, 4, 800)\n",
    "        batch_data = np.array([one_hot_encode_splam(s) for s in batch_seqs])\n",
    "        yield torch.tensor(batch_data, dtype=torch.float32).to(device)\n",
    "\n",
    "# --- CH∆Ø∆†NG TR√åNH CH√çNH ---\n",
    "test_files = ['test_data.csv'] # C·∫≠p nh·∫≠t danh s√°ch file c·ªßa b·∫°n\n",
    "\n",
    "pbar_files = tqdm(test_files, desc=\"Overall Progress\")\n",
    "\n",
    "for csv_file in pbar_files:\n",
    "    path = os.path.join(PREPARED_FOLDER, csv_file)\n",
    "    if not os.path.exists(path): continue\n",
    "    \n",
    "    df = pd.read_csv(path)\n",
    "    y_true = df['Splicing_types'].values\n",
    "    sequences = df['sequence'].values\n",
    "    \n",
    "    all_probs = []\n",
    "    inference_start = time.time()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_tensor in tqdm(get_batches(sequences, BATCH_SIZE), \n",
    "                                total=int(np.ceil(len(sequences)/BATCH_SIZE)), \n",
    "                                desc=\" ‚Ü™ Inferencing\", leave=False):\n",
    "            \n",
    "            # SPLAM Forward Pass\n",
    "            # Output shape th∆∞·ªùng l√† (Batch, 3, 800) ho·∫∑c (Batch, 3) t√πy version\n",
    "            outputs = model(batch_tensor)\n",
    "            \n",
    "            # SPLAM th∆∞·ªùng d·ª± ƒëo√°n cho m·ªçi v·ªã tr√≠ ho·∫∑c v·ªã tr√≠ trung t√¢m\n",
    "            # N·∫øu output l√† (Batch, 3, 800), ta l·∫•y t·∫°i index 400 (v·ªã tr√≠ junction)\n",
    "            if outputs.dim() == 3:\n",
    "                # L·∫•y x√°c su·∫•t t·∫°i ƒëi·ªÉm gi·ªØa\n",
    "                # SPLAM mapping: 0: None, 1: Acceptor, 2: Donor\n",
    "                probs = outputs[:, :, 400].cpu().numpy()\n",
    "            else:\n",
    "                probs = outputs.cpu().numpy()\n",
    "                \n",
    "            all_probs.append(probs)\n",
    "\n",
    "    avg_probs = np.vstack(all_probs)\n",
    "    total_duration = time.time() - inference_start\n",
    "    \n",
    "    # --- MAPPING NH√ÉN THEO Y√äU C·∫¶U ---\n",
    "    # SPLAM G·ªëc: 0=Null, 1=Acceptor, 2=Donor\n",
    "    # Y√™u c·∫ßu c·ªßa b·∫°n: 0=Null, 1=Donor, 2=Acceptor\n",
    "    \n",
    "    p_null = avg_probs[:, 0]\n",
    "    p_acceptor_raw = avg_probs[:, 1] \n",
    "    p_donor_raw = avg_probs[:, 2]\n",
    "    \n",
    "    # T·∫°o m·∫£ng x√°c su·∫•t ƒë√£ map: [p_null, p_donor, p_acceptor]\n",
    "    probs_mapped = np.stack([p_null, p_donor_raw, p_acceptor_raw], axis=1)\n",
    "    \n",
    "    # Quy·∫øt ƒë·ªãnh nh√£n (Argmax ho·∫∑c Threshold)\n",
    "    preds_mapped = np.argmax(probs_mapped, axis=1)\n",
    "    \n",
    "    # (T√πy ch·ªçn) √Åp d·ª•ng Threshold n·∫øu c·∫ßn ƒë·ªô nh·∫°y cao\n",
    "    # THRESHOLD = 0.1\n",
    "    # for i in range(len(preds_mapped)):\n",
    "    #     if p_donor_raw[i] > THRESHOLD or p_acceptor_raw[i] > THRESHOLD:\n",
    "    #         preds_mapped[i] = 1 if p_donor_raw[i] > p_acceptor_raw[i] else 2\n",
    "    #     else: preds_mapped[i] = 0\n",
    "\n",
    "    # --- L∆ØU K·∫æT QU·∫¢ ---\n",
    "    try:\n",
    "        # Gi·∫£ s·ª≠ h√†m compute_metrics c·ªßa b·∫°n nh·∫≠n (y_true, y_pred, probs)\n",
    "        # k·∫øt qu·∫£ tr·∫£ v·ªÅ m·ªôt dict\n",
    "        from metrics import compute_metrics \n",
    "        results = compute_metrics(y_true, preds_mapped, probs=probs_mapped)\n",
    "        \n",
    "        results['benchmarking'] = {\n",
    "            'total_inference_time_sec': round(total_duration, 4),\n",
    "            'samples_per_second': round(len(df) / total_duration, 2)\n",
    "        }\n",
    "        \n",
    "        cm = confusion_matrix(y_true, preds_mapped)\n",
    "        output = {\"metrics\": results, \"confusion_matrix\": cm.tolist()}\n",
    "        \n",
    "        json_path = os.path.join(RESULTS_DIR, csv_file.replace('.csv', '_results.json'))\n",
    "        with open(json_path, 'w') as f:\n",
    "            json.dump(output, f, indent=4)\n",
    "            \n",
    "        print(f\"‚úÖ {csv_file} processed. Speed: {results['benchmarking']['samples_per_second']} seq/s\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error with {csv_file}: {e}\")\n",
    "\n",
    "print(\"\\n‚ú® SPLAM INFERENCE COMPLETED!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67aacbb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SpliceAI_official",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
