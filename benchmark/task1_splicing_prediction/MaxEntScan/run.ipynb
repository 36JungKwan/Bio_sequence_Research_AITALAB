{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa3086c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Äang cháº¡y cháº¿ Ä‘á»™ BIAS Cá»°C ÄOAN cho Ratio: 1-1-1\n",
      "âœ… ÄÃ£ hoÃ n táº¥t xá»­ lÃ½. Káº¿t quáº£ lÆ°u táº¡i: D:\\Study\\5-FA25\\AiTa_Lab_Research\\Code\\Inference_Model\\MaxEntScan\\results\\results_1-1-1.json\n",
      "\n",
      "ğŸš€ Äang cháº¡y cháº¿ Ä‘á»™ BIAS Cá»°C ÄOAN cho Ratio: 2-1-1\n",
      "âœ… ÄÃ£ hoÃ n táº¥t xá»­ lÃ½. Káº¿t quáº£ lÆ°u táº¡i: D:\\Study\\5-FA25\\AiTa_Lab_Research\\Code\\Inference_Model\\MaxEntScan\\results\\results_2-1-1.json\n",
      "\n",
      "ğŸš€ Äang cháº¡y cháº¿ Ä‘á»™ BIAS Cá»°C ÄOAN cho Ratio: 4-1-1\n",
      "âœ… ÄÃ£ hoÃ n táº¥t xá»­ lÃ½. Káº¿t quáº£ lÆ°u táº¡i: D:\\Study\\5-FA25\\AiTa_Lab_Research\\Code\\Inference_Model\\MaxEntScan\\results\\results_4-1-1.json\n",
      "\n",
      "ğŸš€ Äang cháº¡y cháº¿ Ä‘á»™ BIAS Cá»°C ÄOAN cho Ratio: 10-1-1\n",
      "âœ… ÄÃ£ hoÃ n táº¥t xá»­ lÃ½. Káº¿t quáº£ lÆ°u táº¡i: D:\\Study\\5-FA25\\AiTa_Lab_Research\\Code\\Inference_Model\\MaxEntScan\\results\\results_10-1-1.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from a import MaxEntScorer\n",
    "from metrics import compute_metrics, get_confusion_matrix\n",
    "\n",
    "# --- Cáº¤U HÃŒNH ---\n",
    "DATA_DIR = r\"D:\\Study\\5-FA25\\AiTa_Lab_Research\\Code\\Inference_Model\\MaxEntScan\\data\"\n",
    "OUTPUT_DIR = r\"D:\\Study\\5-FA25\\AiTa_Lab_Research\\Code\\Inference_Model\\MaxEntScan\\results\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "scorer = MaxEntScorer()\n",
    "\n",
    "def softmax(x):\n",
    "    # TrÃ¡nh trÃ n sá»‘ (numerical stability)\n",
    "    e_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return e_x / e_x.sum(axis=1, keepdims=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    RATIOS = [\"1-1-1\", \"2-1-1\", \"4-1-1\", \"10-1-1\", \"100-1-1\"]\n",
    "    \n",
    "    # CHIáº¾N THUáº¬T BIAS (Cá»™ng thÃªm vÃ o logit Ä‘á»ƒ Ã©p nhÃ£n)\n",
    "    # VÃ¬ Score cá»§a MaxEntScan báº£n cháº¥t gáº§n giá»‘ng log-likelihood\n",
    "    # Ta cá»™ng thÃªm giÃ¡ trá»‹ dÆ°Æ¡ng Ä‘á»ƒ Æ°u tiÃªn lá»›p Ä‘Ã³\n",
    "    CLASS_BIAS = np.array([5.0, 1.0, 4.0]) # Ã‰p máº¡nh vÃ o lá»›p 2 (Acceptor)\n",
    "\n",
    "    for ratio in RATIOS:\n",
    "        input_file = os.path.join(DATA_DIR, f\"maxent_input_{ratio}.csv\")\n",
    "        if not os.path.exists(input_file):\n",
    "            print(f\"âŒ KhÃ´ng tÃ¬m tháº¥y file: {input_file}\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\nğŸš€ Äang cháº¡y cháº¿ Ä‘á»™ BIAS Cá»°C ÄOAN cho Ratio: {ratio}\")\n",
    "        df = pd.read_csv(input_file)\n",
    "        \n",
    "        # 1. TÃ­nh Scores thÃ´\n",
    "        s5_scores = df['seq_5'].apply(scorer.score5).values\n",
    "        s3_scores = df['seq_3'].apply(scorer.score3).values\n",
    "        \n",
    "        # 2. Táº¡o ma tráº­n Ä‘iá»ƒm [L0, L1, L2]\n",
    "        # Lá»›p 0 (Baseline) chÃºng ta Ä‘áº·t lÃ  Ä‘iá»ƒm trung bÃ¬nh tháº¥p (vÃ­ dá»¥ -5.0) \n",
    "        # thay vÃ¬ 0.0 Ä‘á»ƒ trÃ¡nh nÃ³ láº¥n Ã¡t cÃ¡c site yáº¿u.\n",
    "        combined_scores = np.stack([np.zeros(len(s5_scores)), s5_scores, s3_scores], axis=1)\n",
    "        \n",
    "        # 3. Ãp dá»¥ng Bias (Cá»™ng thay vÃ¬ NhÃ¢n Ä‘á»ƒ trÃ¡nh lá»—i sá»‘ Ã¢m)\n",
    "        weighted_logits = combined_scores + CLASS_BIAS\n",
    "        \n",
    "        # 4. Dá»± Ä‘oÃ¡n\n",
    "        all_probs = softmax(weighted_logits)\n",
    "        all_preds = np.argmax(weighted_logits, axis=1)\n",
    "        \n",
    "        # 5. TÃ­nh Metrics\n",
    "        y_true = df['label'].values\n",
    "        # Äáº£m báº£o hÃ m compute_metrics cá»§a báº¡n nháº­n diá»‡n Ä‘Ãºng thá»© tá»± nhÃ£n\n",
    "        metrics_res = compute_metrics(y_true, all_preds, probs=all_probs, k=2)\n",
    "        metrics_res['confusion_matrix'] = get_confusion_matrix(y_true, all_preds).tolist()\n",
    "        \n",
    "        # ThÃªm thÃ´ng tin vá» thiáº¿t láº­p cá»±c Ä‘oan vÃ o káº¿t quáº£\n",
    "        metrics_res['meta'] = {\"bias_applied\": CLASS_BIAS.tolist(), \"ratio\": ratio}\n",
    "\n",
    "        output_json = os.path.join(OUTPUT_DIR, f\"results_{ratio}.json\")\n",
    "        with open(output_json, \"w\") as f:\n",
    "            json.dump(metrics_res, f, indent=4)\n",
    "            \n",
    "        print(f\"âœ… ÄÃ£ hoÃ n táº¥t xá»­ lÃ½. Káº¿t quáº£ lÆ°u táº¡i: {output_json}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
