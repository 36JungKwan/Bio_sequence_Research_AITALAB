{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be1f1ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Ratio: 1-1-1 | Bias: [4.5 1.2 4.5] | Thresholds: [0.0, 0.7, 0.6]\n",
      "‚úÖ K·∫øt qu·∫£ l∆∞u t·∫°i: D:\\Study\\5-FA25\\AiTa_Lab_Research\\Code\\Inference_Model\\MaxEntScan\\results\\results_1-1-1.json\n",
      "\n",
      "üöÄ Ratio: 2-1-1 | Bias: [4.5 1.2 4.5] | Thresholds: [0.0, 0.7, 0.6]\n",
      "‚úÖ K·∫øt qu·∫£ l∆∞u t·∫°i: D:\\Study\\5-FA25\\AiTa_Lab_Research\\Code\\Inference_Model\\MaxEntScan\\results\\results_2-1-1.json\n",
      "\n",
      "üöÄ Ratio: 4-1-1 | Bias: [4.5 1.2 4.5] | Thresholds: [0.0, 0.7, 0.6]\n",
      "‚úÖ K·∫øt qu·∫£ l∆∞u t·∫°i: D:\\Study\\5-FA25\\AiTa_Lab_Research\\Code\\Inference_Model\\MaxEntScan\\results\\results_4-1-1.json\n",
      "\n",
      "üöÄ Ratio: 10-1-1 | Bias: [4.5 1.2 4.5] | Thresholds: [0.0, 0.7, 0.6]\n",
      "‚úÖ K·∫øt qu·∫£ l∆∞u t·∫°i: D:\\Study\\5-FA25\\AiTa_Lab_Research\\Code\\Inference_Model\\MaxEntScan\\results\\results_10-1-1.json\n",
      "\n",
      "üöÄ Ratio: 100-1-1 | Bias: [4.5 1.2 4.5] | Thresholds: [0.0, 0.7, 0.6]\n",
      "‚úÖ K·∫øt qu·∫£ l∆∞u t·∫°i: D:\\Study\\5-FA25\\AiTa_Lab_Research\\Code\\Inference_Model\\MaxEntScan\\results\\results_100-1-1.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from a import MaxEntScorer\n",
    "from metrics import compute_metrics, get_confusion_matrix\n",
    "\n",
    "# --- C·∫§U H√åNH ---\n",
    "DATA_DIR = r\"D:\\Study\\5-FA25\\AiTa_Lab_Research\\Code\\Inference_Model\\MaxEntScan\\data\"\n",
    "OUTPUT_DIR = r\"D:\\Study\\5-FA25\\AiTa_Lab_Research\\Code\\Inference_Model\\MaxEntScan\\results\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "scorer = MaxEntScorer()\n",
    "\n",
    "def softmax(x):\n",
    "    # Tr√°nh tr√†n s·ªë (numerical stability)\n",
    "    e_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return e_x / e_x.sum(axis=1, keepdims=True)\n",
    "\n",
    "# H√†m √°p d·ª•ng ng∆∞·ª°ng th·ªß c√¥ng\n",
    "def apply_threshold_prediction(probs, thresholds):\n",
    "    \"\"\"\n",
    "    probs: Ma tr·∫≠n x√°c su·∫•t (N_samples, N_classes)\n",
    "    thresholds: List ng∆∞·ª°ng cho t·ª´ng class [th_class0, th_class1, th_class2]\n",
    "    \"\"\"\n",
    "    # 1. L·∫•y l·ªõp c√≥ x√°c su·∫•t cao nh·∫•t ban ƒë·∫ßu\n",
    "    initial_preds = np.argmax(probs, axis=1)\n",
    "    \n",
    "    # 2. L·∫•y gi√° tr·ªã x√°c su·∫•t t∆∞∆°ng ·ª©ng c·ªßa l·ªõp ƒë√≥\n",
    "    # np.arange(len(probs)) t·∫°o index h√†ng, initial_preds l√† index c·ªôt\n",
    "    max_confidences = probs[np.arange(len(probs)), initial_preds]\n",
    "    \n",
    "    # 3. L·∫•y ng∆∞·ª°ng t∆∞∆°ng ·ª©ng v·ªõi l·ªõp ƒë∆∞·ª£c d·ª± ƒëo√°n\n",
    "    # V√≠ d·ª•: n·∫øu m√°y ƒëo√°n l·ªõp 1, n√≥ s·∫Ω l·∫•y thresholds[1]\n",
    "    selected_thresholds = np.array([thresholds[p] for p in initial_preds])\n",
    "    \n",
    "    # 4. So s√°nh: N·∫øu x√°c su·∫•t < ng∆∞·ª°ng -> G√°n v·ªÅ class 0 (Non-site)\n",
    "    # Ng∆∞·ª£c l·∫°i gi·ªØ nguy√™n d·ª± ƒëo√°n ban ƒë·∫ßu\n",
    "    final_preds = np.where(max_confidences >= selected_thresholds, initial_preds, 0)\n",
    "    \n",
    "    return final_preds\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    RATIOS = [\"1-1-1\", \"2-1-1\", \"4-1-1\", \"10-1-1\", \"100-1-1\"]\n",
    "    \n",
    "    # CHI·∫æN THU·∫¨T BIAS\n",
    "    CLASS_BIAS = np.array([4.5, 1.2, 4.5])\n",
    "\n",
    "    # --- C·∫§U H√åNH NG∆Ø·ª†NG (B·∫†N CH·ªàNH ·ªû ƒê√ÇY) ---\n",
    "    # Index 0: Non-site (th∆∞·ªùng ƒë·ªÉ 0.0 v√¨ n√≥ l√† fallback)\n",
    "    # Index 1: Donor (GT)\n",
    "    # Index 2: Acceptor (AG)\n",
    "    # V√≠ d·ª•: [0.0, 0.7, 0.6] nghƒ©a l√†:\n",
    "    # - N·∫øu ƒëo√°n l√† Donor, x√°c su·∫•t ph·∫£i > 70% m·ªõi ch·ªët, kh√¥ng th√¨ v·ªÅ Non-site\n",
    "    # - N·∫øu ƒëo√°n l√† Acceptor, x√°c su·∫•t ph·∫£i > 60% m·ªõi ch·ªët.\n",
    "    CONFIDENCE_THRESHOLDS = [0.0, 0.7, 0.6] \n",
    "\n",
    "    for ratio in RATIOS:\n",
    "        input_file = os.path.join(DATA_DIR, f\"maxent_input_{ratio}.csv\")\n",
    "        if not os.path.exists(input_file):\n",
    "            print(f\"‚ùå Kh√¥ng t√¨m th·∫•y file: {input_file}\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\nüöÄ Ratio: {ratio} | Bias: {CLASS_BIAS} | Thresholds: {CONFIDENCE_THRESHOLDS}\")\n",
    "        df = pd.read_csv(input_file)\n",
    "        \n",
    "        # 1. T√≠nh Scores th√¥\n",
    "        s5_scores = df['seq_5'].apply(scorer.score5).values\n",
    "        s3_scores = df['seq_3'].apply(scorer.score3).values\n",
    "        \n",
    "        # 2. T·∫°o ma tr·∫≠n ƒëi·ªÉm\n",
    "        combined_scores = np.stack([np.zeros(len(s5_scores)), s5_scores, s3_scores], axis=1)\n",
    "        \n",
    "        # 3. √Åp d·ª•ng Bias\n",
    "        weighted_logits = combined_scores + CLASS_BIAS\n",
    "        \n",
    "        # 4. D·ª± ƒëo√°n (C√ì S·ª¨ D·ª§NG NG∆Ø·ª†NG)\n",
    "        all_probs = softmax(weighted_logits)\n",
    "        \n",
    "        # --- THAY ƒê·ªîI ·ªû ƒê√ÇY: D√πng h√†m apply_threshold_prediction thay v√¨ np.argmax ---\n",
    "        # all_preds = np.argmax(weighted_logits, axis=1) # (Code c≈©)\n",
    "        all_preds = apply_threshold_prediction(all_probs, CONFIDENCE_THRESHOLDS)\n",
    "        \n",
    "        # 5. T√≠nh Metrics\n",
    "        y_true = df['label'].values\n",
    "        metrics_res = compute_metrics(y_true, all_preds, probs=all_probs, k=2)\n",
    "        metrics_res['confusion_matrix'] = get_confusion_matrix(y_true, all_preds).tolist()\n",
    "        \n",
    "        # L∆∞u th√™m th√¥ng tin thresholds v√†o k·∫øt qu·∫£ ƒë·ªÉ ti·ªán theo d√µi\n",
    "        metrics_res['meta'] = {\n",
    "            \"bias_applied\": CLASS_BIAS.tolist(), \n",
    "            \"thresholds\": CONFIDENCE_THRESHOLDS,\n",
    "            \"ratio\": ratio\n",
    "        }\n",
    "\n",
    "        output_json = os.path.join(OUTPUT_DIR, f\"results_{ratio}.json\")\n",
    "        with open(output_json, \"w\") as f:\n",
    "            json.dump(metrics_res, f, indent=4)\n",
    "            \n",
    "        print(f\"‚úÖ K·∫øt qu·∫£ l∆∞u t·∫°i: {output_json}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
