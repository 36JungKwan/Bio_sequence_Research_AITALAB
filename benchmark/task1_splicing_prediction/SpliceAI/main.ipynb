{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a56fc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import json\n",
    "\n",
    "# --- CẤU HÌNH BENCHMARK ---\n",
    "MODEL_FOLDER = \"path/to/models/\"\n",
    "PREPARED_FOLDER = \"prepared_data/\"\n",
    "RESULTS_DIR = \"results/\"\n",
    "BATCH_SIZE = 32\n",
    "CONTEXT = 5000 # Phải khớp với context lúc prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499b7a52",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f280a847",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preparation import prepare_csv_datasets\n",
    "os.makedirs(PREPARED_FOLDER, exist_ok=True)\n",
    "test_files = ['test_1_1_1.csv', 'test_2_1_1.csv', 'test_4_1_1.csv', 'test_10_1_1.csv', 'test_data.csv']\n",
    "prepare_csv_datasets(test_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03407f29",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094e6f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tất cả models 1 lần duy nhất bên ngoài vòng lặp file\n",
    "print(\"Loading Ensemble Models...\")\n",
    "models = []\n",
    "for i in range(1, 6):\n",
    "    model_path = os.path.join(MODEL_FOLDER, f\"spliceai{i}.h5\")\n",
    "    models.append(tf.keras.models.load_model(model_path, compile=False))\n",
    "print(f\"Successfully loaded {len(models)} models.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0de321",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import compute_metrics\n",
    "\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "def one_hot_encode(seq):\n",
    "    # Vấn đề 4: Xử lý 'N' thành vector 0 (hoặc 0.25 tùy model, ở đây dùng 0)\n",
    "    map_dict = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n",
    "    seq_code = np.zeros((len(seq), 4), dtype=np.float32)\n",
    "    for i, nt in enumerate(seq):\n",
    "        if nt in map_dict:\n",
    "            seq_code[i, map_dict[nt]] = 1.0\n",
    "    return seq_code\n",
    "\n",
    "def create_dataset(sequences, batch_size):\n",
    "    # Vấn đề 1: Sử dụng Generator để không phải load toàn bộ mảng X vào RAM\n",
    "    def gen():\n",
    "        for s in sequences:\n",
    "            yield one_hot_encode(s)\n",
    "            \n",
    "    return tf.data.Dataset.from_generator(\n",
    "        gen,\n",
    "        output_signature=tf.TensorSpec(shape=(2*CONTEXT+1, 4), dtype=tf.float32)\n",
    "    ).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "for csv_file in test_files:\n",
    "    path = os.path.join(PREPARED_FOLDER, csv_file)\n",
    "    if not os.path.exists(path): continue\n",
    "    \n",
    "    df = pd.read_csv(path)\n",
    "    y_true = df['Splicing_types'].values\n",
    "    ds = create_dataset(df['sequence'], BATCH_SIZE)\n",
    "\n",
    "    # Ensemble Inference\n",
    "    all_preds = []\n",
    "    for i, model in enumerate(models):\n",
    "        print(f\"Predicting with model {i+1} for {csv_file}...\")\n",
    "        preds = model.predict(ds, verbose=1)\n",
    "        # Lấy nucleotide trung tâm (điểm splice)\n",
    "        all_preds.append(preds[:, CONTEXT, :])\n",
    "\n",
    "    # Trung bình cộng xác suất\n",
    "    avg_probs = np.mean(all_preds, axis=0)\n",
    "    \n",
    "    # Mapping nhãn theo đúng thứ tự SpliceAI (None:0, Don:1, Acc:2)\n",
    "    # Lưu ý: SpliceAI nguyên bản trả về [None, Acceptor, Donor]\n",
    "    # Nếu y_true của bạn là 1:Donor, 2:Acceptor -> Thứ tự: [None, Donor, Acceptor]\n",
    "    probs_mapped = np.stack([avg_probs[:, 0], avg_probs[:, 2], avg_probs[:, 1]], axis=1)\n",
    "    preds_mapped = np.argmax(probs_mapped, axis=1)\n",
    "\n",
    "    # Tính metrics\n",
    "    results = compute_metrics(y_true, preds_mapped, probs=probs_mapped, k=2)\n",
    "    cm = confusion_matrix(y_true, preds_mapped)\n",
    "\n",
    "    # Xuất JSON đúng định dạng yêu cầu\n",
    "    output = {\"metrics\": results, \"confusion_matrix\": cm.tolist()}\n",
    "    json_path = os.path.join(RESULTS_DIR, csv_file.replace('.csv', '_results.json'))\n",
    "    \n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(output, f, indent=4)\n",
    "    print(f\"Results saved to {json_path}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
