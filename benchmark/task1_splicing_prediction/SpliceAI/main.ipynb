{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9a913ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pandas numpy==1.23.5 tensorflow-gpu==2.10.1 scikit-learn biopython tqdm pyfaidx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30f5d98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install -c conda-forge cudatoolkit=11.2 cudnn=8.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a56fc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import json\n",
    "from metrics import compute_metrics\n",
    "from data_preparation import prepare_csv_datasets\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# --- C·∫§U H√åNH BENCHMARK ---\n",
    "MODEL_FOLDER = r\"D:\\Bio_sequence_Research_AITALAB\\benchmark\\task1_splicing_prediction\\SpliceAI\\pretrained_model\"\n",
    "PREPARED_FOLDER = \"prepared_data/\"\n",
    "RESULTS_DIR = \"results/\"\n",
    "BATCH_SIZE = 128\n",
    "CONTEXT = 5000 # Ph·∫£i kh·ªõp v·ªõi context l√∫c prepare data\n",
    "test_files = ['test_1_1_1.csv', 'test_2_1_1.csv', 'test_4_1_1.csv', 'test_10_1_1.csv', 'test_data.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "100d7028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phi√™n b·∫£n TF: 2.10.1\n",
      "Danh s√°ch thi·∫øt b·ªã: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "S·ªë l∆∞·ª£ng GPU: 1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Phi√™n b·∫£n TF:\", tf.__version__)\n",
    "print(\"Danh s√°ch thi·∫øt b·ªã:\", tf.config.list_physical_devices())\n",
    "print(\"S·ªë l∆∞·ª£ng GPU:\", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499b7a52",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f280a847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:57:43] Loading Genome with pyfaidx...\n",
      "Sorting test_1_1_1.csv for sequential disk access...\n",
      "üöÄ Processing: test_1_1_1.csv (26310 rows)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26310/26310 [00:01<00:00, 24702.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Type       | Window around center (-2 to +2) | Found?\n",
      "-----------------------------------------------------------------\n",
      "Donor      | AA[GG]TT                  | ‚ùå (Target: GT)\n",
      "Donor      | CA[GG]TA                  | ‚ùå (Target: GT)\n",
      "Donor      | CA[AG]TA                  | ‚ùå (Target: GT)\n",
      "Donor      | AA[GG]TA                  | ‚ùå (Target: GT)\n",
      "Donor      | AT[GG]TG                  | ‚ùå (Target: GT)\n",
      "Acceptor   | AT[AG]GT                  | ‚úÖ (Target: AG)\n",
      "Acceptor   | CC[AG]AG                  | ‚úÖ (Target: AG)\n",
      "Acceptor   | GA[AG]GT                  | ‚úÖ (Target: AG)\n",
      "Acceptor   | GC[AG]GT                  | ‚úÖ (Target: AG)\n",
      "Acceptor   | AG[AG]CC                  | ‚úÖ (Target: AG)\n",
      "‚úÖ Saved to prepared_data/test_1_1_1.csv | Speed: 8493.61 seq/s\n",
      "\n",
      "Sorting test_2_1_1.csv for sequential disk access...\n",
      "üöÄ Processing: test_2_1_1.csv (35132 rows)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 35132/35132 [00:01<00:00, 24192.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Type       | Window around center (-2 to +2) | Found?\n",
      "-----------------------------------------------------------------\n",
      "Donor      | GG[TA]AT                  | ‚ùå (Target: GT)\n",
      "Donor      | GA[GG]TG                  | ‚ùå (Target: GT)\n",
      "Donor      | GG[TA]AA                  | ‚ùå (Target: GT)\n",
      "Donor      | AA[GG]TG                  | ‚ùå (Target: GT)\n",
      "Donor      | GG[TA]AG                  | ‚ùå (Target: GT)\n",
      "Acceptor   | CC[AG]TG                  | ‚úÖ (Target: AG)\n",
      "Acceptor   | GC[AG]CC                  | ‚úÖ (Target: AG)\n",
      "Acceptor   | TC[AG]AA                  | ‚úÖ (Target: AG)\n",
      "Acceptor   | TC[AG]GC                  | ‚úÖ (Target: AG)\n",
      "Acceptor   | TT[AG]GA                  | ‚úÖ (Target: AG)\n",
      "‚úÖ Saved to prepared_data/test_2_1_1.csv | Speed: 8355.16 seq/s\n",
      "\n",
      "Sorting test_4_1_1.csv for sequential disk access...\n",
      "üöÄ Processing: test_4_1_1.csv (52776 rows)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 52776/52776 [00:02<00:00, 23726.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Type       | Window around center (-2 to +2) | Found?\n",
      "-----------------------------------------------------------------\n",
      "Donor      | GG[TA]AG                  | ‚ùå (Target: GT)\n",
      "Donor      | CC[GG]TG                  | ‚ùå (Target: GT)\n",
      "Donor      | GG[TC]AG                  | ‚ùå (Target: GT)\n",
      "Donor      | GG[TG]AG                  | ‚ùå (Target: GT)\n",
      "Donor      | GA[GG]TA                  | ‚ùå (Target: GT)\n",
      "Acceptor   | TC[AG]GT                  | ‚úÖ (Target: AG)\n",
      "Acceptor   | AG[AG]AA                  | ‚úÖ (Target: AG)\n",
      "Acceptor   | AC[AG]TT                  | ‚úÖ (Target: AG)\n",
      "Acceptor   | GC[AG]GA                  | ‚úÖ (Target: AG)\n",
      "Acceptor   | AG[GT]GG                  | ‚ùå (Target: AG)\n",
      "‚úÖ Saved to prepared_data/test_4_1_1.csv | Speed: 8139.52 seq/s\n",
      "\n",
      "Sorting test_10_1_1.csv for sequential disk access...\n",
      "üöÄ Processing: test_10_1_1.csv (105708 rows)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 105708/105708 [00:04<00:00, 24718.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Type       | Window around center (-2 to +2) | Found?\n",
      "-----------------------------------------------------------------\n",
      "Donor      | GG[TT]AG                  | ‚ùå (Target: GT)\n",
      "Donor      | CA[GG]TA                  | ‚ùå (Target: GT)\n",
      "Donor      | AC[GG]TG                  | ‚ùå (Target: GT)\n",
      "Donor      | GG[TC]AG                  | ‚ùå (Target: GT)\n",
      "Donor      | AA[GG]TA                  | ‚ùå (Target: GT)\n",
      "Acceptor   | AG[CT]GC                  | ‚ùå (Target: AG)\n",
      "Acceptor   | GC[AG]TA                  | ‚úÖ (Target: AG)\n",
      "Acceptor   | AG[GT]GG                  | ‚ùå (Target: AG)\n",
      "Acceptor   | AG[AG]GG                  | ‚úÖ (Target: AG)\n",
      "Acceptor   | CC[AG]CA                  | ‚úÖ (Target: AG)\n",
      "‚úÖ Saved to prepared_data/test_10_1_1.csv | Speed: 8423.27 seq/s\n",
      "\n",
      "Sorting test_data.csv for sequential disk access...\n",
      "üöÄ Processing: test_data.csv (938297 rows)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 938297/938297 [00:37<00:00, 25041.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Type       | Window around center (-2 to +2) | Found?\n",
      "-----------------------------------------------------------------\n",
      "Donor      | GG[TG]AG                  | ‚ùå (Target: GT)\n",
      "Donor      | GG[TG]AG                  | ‚ùå (Target: GT)\n",
      "Donor      | GG[TA]AG                  | ‚ùå (Target: GT)\n",
      "Donor      | GA[GG]TG                  | ‚ùå (Target: GT)\n",
      "Donor      | AA[GG]TG                  | ‚ùå (Target: GT)\n",
      "Acceptor   | AG[CT]GT                  | ‚ùå (Target: AG)\n",
      "Acceptor   | CT[AG]GC                  | ‚úÖ (Target: AG)\n",
      "Acceptor   | CT[AG]TG                  | ‚úÖ (Target: AG)\n",
      "Acceptor   | AG[GG]CG                  | ‚ùå (Target: AG)\n",
      "Acceptor   | CC[AG]GG                  | ‚úÖ (Target: AG)\n",
      "‚úÖ Saved to prepared_data/test_data.csv | Speed: 8451.58 seq/s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(PREPARED_FOLDER, exist_ok=True)\n",
    "prepare_csv_datasets(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6a75a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(r'D:\\Bio_sequence_Research_AITALAB\\benchmark\\task1_splicing_prediction\\SpliceAI\\prepared_data\\test_1_1_1.csv')\n",
    "# # Ki·ªÉm tra 5 m·∫´u Donor ƒë·∫ßu ti√™n\n",
    "# donor_samples = df[df['Splicing_types'] == 1]['sequence'].values[:5]\n",
    "# for i, seq in enumerate(donor_samples):\n",
    "#     # L·∫•y v√πng trung t√¢m (index 5000 l√† nucleotide t·∫°i v·ªã tr√≠ pos)\n",
    "#     center = seq[5000:5002] \n",
    "#     print(f\"Donor {i}: V·ªã tr√≠ trung t√¢m l√† '{center}' (K·ª≥ v·ªçng th∆∞·ªùng l√† GT)\")\n",
    "\n",
    "# # Ki·ªÉm tra 5 m·∫´u Acceptor ƒë·∫ßu ti√™n\n",
    "# acceptor_samples = df[df['Splicing_types'] == 2]['sequence'].values[:5]\n",
    "# for i, seq in enumerate(acceptor_samples):\n",
    "#     center = seq[5000:5002]\n",
    "#     print(f\"Acceptor {i}: V·ªã tr√≠ trung t√¢m l√† '{center}' (K·ª≥ v·ªçng th∆∞·ªùng l√† AG)\")\n",
    "\n",
    "# def diagnose_splice_sites(df, sample_size=5):\n",
    "#     print(f\"{'Type':<10} | {'Window (-5 to +5 around center)':<20} | {'Found?'}\")\n",
    "#     print(\"-\" * 50)\n",
    "    \n",
    "#     for label, name in [(1, 'Donor'), (2, 'Acceptor')]:\n",
    "#         samples = df[df['Splicing_types'] == label].sample(min(sample_size, len(df)))\n",
    "#         for _, row in samples.iterrows():\n",
    "#             seq = row['sequence']\n",
    "#             # L·∫•y 11 nucleotide (v·ªã tr√≠ 5000 l√† trung t√¢m)\n",
    "#             window = seq[4995:5006]\n",
    "            \n",
    "#             target = \"GT\" if label == 1 else \"AG\"\n",
    "#             found = \"‚úÖ\" if target in window else \"‚ùå\"\n",
    "            \n",
    "#             # Highlight v·ªã tr√≠ trung t√¢m b·∫±ng d·∫•u ngo·∫∑c []\n",
    "#             display_win = window[:5] + \"[\" + window[5:7] + \"]\" + window[7:]\n",
    "#             print(f\"{name:<10} | {display_win:<20} | {found} (Target: {target})\")\n",
    "\n",
    "# # Ch·∫°y sau khi load df t·ª´ prepared_data\n",
    "# diagnose_splice_sites(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03407f29",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "094e6f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Ensemble Models...\n",
      "Successfully loaded 5 models.\n"
     ]
    }
   ],
   "source": [
    "# Load t·∫•t c·∫£ models 1 l·∫ßn duy nh·∫•t b√™n ngo√†i v√≤ng l·∫∑p file\n",
    "print(\"Loading Ensemble Models...\")\n",
    "models = []\n",
    "for i in range(1, 6):\n",
    "    model_path = os.path.join(MODEL_FOLDER, f\"spliceai{i}.h5\")\n",
    "    models.append(tf.keras.models.load_model(model_path, compile=False))\n",
    "print(f\"Successfully loaded {len(models)} models.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e0de321",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Progress:   0%|          | 0/5 [00:00<?, ?file/s, file=test_1_1_1.csv]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ƒêANG KI·ªÇM TRA ONE-HOT ENCODING ---\n",
      "‚úÖ H√ÄNG 10342: Kh·ªõp ho√†n to√†n (ƒê·ªô d√†i: 10001)\n",
      "‚úÖ H√ÄNG 3732: Kh·ªõp ho√†n to√†n (ƒê·ªô d√†i: 10001)\n",
      "‚úÖ H√ÄNG 4845: Kh·ªõp ho√†n to√†n (ƒê·ªô d√†i: 10001)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206/206 [==============================] - 63s 306ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206/206 [==============================] - 62s 302ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206/206 [==============================] - 62s 301ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206/206 [==============================] - 62s 301ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206/206 [==============================] - 62s 302ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Progress:  20%|‚ñà‚ñà        | 1/5 [05:11<20:47, 311.87s/file, file=test_2_1_1.csv]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Ki·ªÉm tra ph√¢n ph·ªëi x√°c su·∫•t cho test_1_1_1.csv ---\n",
      "   Nh√£n 1: Avg = 0.382683, Max = 0.999861, Top 10 Min = [0.0000000002, 0.0000000006, 0.0000000006, 0.0000000007, 0.0000000010, 0.0000000013, 0.0000000017, 0.0000000017, 0.0000000017, 0.0000000018]\n",
      "   Nh√£n 2: Avg = 0.322296, Max = 0.999870, Top 10 Min = [0.0000000009, 0.0000000009, 0.0000000015, 0.0000000019, 0.0000000020, 0.0000000023, 0.0000000028, 0.0000000029, 0.0000000033, 0.0000000038]\n",
      "‚úÖ test_1_1_1.csv | Enc: 62.75s | Total: 310.26s\n",
      "--- ƒêANG KI·ªÇM TRA ONE-HOT ENCODING ---\n",
      "‚úÖ H√ÄNG 28724: Kh·ªõp ho√†n to√†n (ƒê·ªô d√†i: 10001)\n",
      "‚úÖ H√ÄNG 8594: Kh·ªõp ho√†n to√†n (ƒê·ªô d√†i: 10001)\n",
      "‚úÖ H√ÄNG 7474: Kh·ªõp ho√†n to√†n (ƒê·ªô d√†i: 10001)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 83s 302ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 82s 301ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 83s 302ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 82s 301ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 82s 300ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Progress:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [12:06<18:37, 372.38s/file, file=test_4_1_1.csv]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Ki·ªÉm tra ph√¢n ph·ªëi x√°c su·∫•t cho test_2_1_1.csv ---\n",
      "   Nh√£n 1: Avg = 0.382683, Max = 0.999861, Top 10 Min = [0.0000000002, 0.0000000006, 0.0000000006, 0.0000000007, 0.0000000010, 0.0000000013, 0.0000000017, 0.0000000017, 0.0000000017, 0.0000000018]\n",
      "   Nh√£n 2: Avg = 0.322296, Max = 0.999870, Top 10 Min = [0.0000000009, 0.0000000009, 0.0000000015, 0.0000000019, 0.0000000020, 0.0000000023, 0.0000000028, 0.0000000029, 0.0000000033, 0.0000000038]\n",
      "‚úÖ test_2_1_1.csv | Enc: 82.76s | Total: 412.56s\n",
      "--- ƒêANG KI·ªÇM TRA ONE-HOT ENCODING ---\n",
      "‚úÖ H√ÄNG 36801: Kh·ªõp ho√†n to√†n (ƒê·ªô d√†i: 10001)\n",
      "‚úÖ H√ÄNG 49949: Kh·ªõp ho√†n to√†n (ƒê·ªô d√†i: 10001)\n",
      "‚úÖ H√ÄNG 38578: Kh·ªõp ho√†n to√†n (ƒê·ªô d√†i: 10001)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413/413 [==============================] - 124s 301ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413/413 [==============================] - 124s 301ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413/413 [==============================] - 124s 301ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413/413 [==============================] - 124s 301ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413/413 [==============================] - 123s 300ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Ki·ªÉm tra ph√¢n ph·ªëi x√°c su·∫•t cho test_4_1_1.csv ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Progress:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [22:29<16:13, 486.77s/file, file=test_10_1_1.csv]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Nh√£n 1: Avg = 0.382683, Max = 0.999861, Top 10 Min = [0.0000000002, 0.0000000006, 0.0000000006, 0.0000000007, 0.0000000010, 0.0000000013, 0.0000000017, 0.0000000017, 0.0000000017, 0.0000000018]\n",
      "   Nh√£n 2: Avg = 0.322296, Max = 0.999870, Top 10 Min = [0.0000000009, 0.0000000009, 0.0000000015, 0.0000000019, 0.0000000020, 0.0000000023, 0.0000000028, 0.0000000029, 0.0000000033, 0.0000000038]\n",
      "‚úÖ test_4_1_1.csv | Enc: 124.14s | Total: 619.71s\n",
      "--- ƒêANG KI·ªÇM TRA ONE-HOT ENCODING ---\n",
      "‚úÖ H√ÄNG 1809: Kh·ªõp ho√†n to√†n (ƒê·ªô d√†i: 10001)\n",
      "‚úÖ H√ÄNG 978: Kh·ªõp ho√†n to√†n (ƒê·ªô d√†i: 10001)\n",
      "‚úÖ H√ÄNG 2269: Kh·ªõp ho√†n to√†n (ƒê·ªô d√†i: 10001)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "826/826 [==============================] - 248s 301ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    753/Unknown - 226s 300ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Progress:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [30:29<20:19, 609.89s/file, file=test_10_1_1.csv]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 101\u001b[0m\n\u001b[0;32m     99\u001b[0m     encoding_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m enc_start\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 101\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m# --- S·ª¨A L·ªñI TRUY C·∫¨P CH·ªà S·ªê (IndexError Fix) ---\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m preds\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Dung\\anaconda3\\envs\\SpliceAI_official\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Dung\\anaconda3\\envs\\SpliceAI_official\\lib\\site-packages\\keras\\engine\\training.py:2253\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   2251\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[0;32m   2252\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_predict_batch_begin(step)\n\u001b[1;32m-> 2253\u001b[0m     tmp_batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2254\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   2255\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\Dung\\anaconda3\\envs\\SpliceAI_official\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Dung\\anaconda3\\envs\\SpliceAI_official\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Dung\\anaconda3\\envs\\SpliceAI_official\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    952\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    953\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 954\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m    956\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    957\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Dung\\anaconda3\\envs\\SpliceAI_official\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dung\\anaconda3\\envs\\SpliceAI_official\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Dung\\anaconda3\\envs\\SpliceAI_official\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\Dung\\anaconda3\\envs\\SpliceAI_official\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "def one_hot_encode(seq):\n",
    "    # Vectorized Encoding (CPU-side)\n",
    "    seq_code = np.zeros((len(seq), 4), dtype=np.float32)\n",
    "    seq = seq.upper()\n",
    "    sn = np.frombuffer(seq.encode('ascii'), dtype=np.int8)\n",
    "    seq_code[sn == ord('A'), 0] = 1.0\n",
    "    seq_code[sn == ord('C'), 1] = 1.0\n",
    "    seq_code[sn == ord('G'), 2] = 1.0\n",
    "    seq_code[sn == ord('T'), 3] = 1.0\n",
    "    return seq_code\n",
    "\n",
    "def create_optimized_dataset(sequences, batch_size):\n",
    "    def gen():\n",
    "        for s in sequences:\n",
    "            yield one_hot_encode(s)\n",
    "            \n",
    "    ds = tf.data.Dataset.from_generator(\n",
    "        gen,\n",
    "        output_signature=tf.TensorSpec(shape=(2*CONTEXT+1, 4), dtype=tf.float32)\n",
    "    )\n",
    "    # Ch·ªâ cache n·∫øu s·ªë l∆∞·ª£ng m·∫´u nh·ªè (v√≠ d·ª• < 50,000)\n",
    "    if len(sequences) < 50000:\n",
    "        return ds.batch(batch_size).cache().prefetch(tf.data.AUTOTUNE)\n",
    "    return ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "def debug_one_hot_encoding(sequences, sample_size=1):\n",
    "    \"\"\"\n",
    "    Ki·ªÉm tra xem One-hot encoding c√≥ kh·ªõp v·ªõi chu·ªói g·ªëc hay kh√¥ng.\n",
    "    \"\"\"\n",
    "    # L·∫•y m·ªôt v√†i m·∫´u ng·∫´u nhi√™n\n",
    "    indices = np.random.choice(len(sequences), sample_size)\n",
    "    map_dict = {0: 'A', 1: 'C', 2: 'G', 3: 'T'}\n",
    "    \n",
    "    print(\"--- ƒêANG KI·ªÇM TRA ONE-HOT ENCODING ---\")\n",
    "    \n",
    "    for idx in indices:\n",
    "        original_seq = sequences[idx]\n",
    "        encoded_seq = one_hot_encode(original_seq)\n",
    "        \n",
    "        # 1. Ki·ªÉm tra Shape\n",
    "        expected_shape = (2 * CONTEXT + 1, 4)\n",
    "        if encoded_seq.shape != expected_shape:\n",
    "            print(f\"‚ùå L·ªñI SHAPE: K·ª≥ v·ªçng {expected_shape}, nh·∫≠n ƒë∆∞·ª£c {encoded_seq.shape}\")\n",
    "            return\n",
    "            \n",
    "        # 2. Gi·∫£i m√£ ng∆∞·ª£c (Decode)\n",
    "        # T√¨m v·ªã tr√≠ index c√≥ gi√° tr·ªã 1.0, n·∫øu to√†n 0 th√¨ tr·∫£ v·ªÅ -1 (ƒë·∫°i di·ªán cho 'N')\n",
    "        decoded_indices = np.where(encoded_seq == 1.0)[1]\n",
    "        # X·ª≠ l√Ω tr∆∞·ªùng h·ª£p h√†ng to√†n 0 (k√Ω t·ª± 'N' ho·∫∑c l·ªói)\n",
    "        decoded_seq_list = []\n",
    "        for row in encoded_seq:\n",
    "            if np.sum(row) == 0:\n",
    "                decoded_seq_list.append('N')\n",
    "            else:\n",
    "                decoded_seq_list.append(map_dict[np.argmax(row)])\n",
    "        \n",
    "        decoded_seq = \"\".join(decoded_seq_list)\n",
    "        \n",
    "        # 3. So s√°nh chu·ªói g·ªëc v√† chu·ªói gi·∫£i m√£ (ch·ªâ ki·ªÉm tra c√°c k√Ω t·ª± ACGT)\n",
    "        # L∆∞u √Ω: Biopython/pyfaidx c√≥ th·ªÉ tr·∫£ v·ªÅ chu·ªói h·ªón h·ª£p, ta n√™n .upper()\n",
    "        if original_seq.upper() == decoded_seq:\n",
    "            print(f\"‚úÖ H√ÄNG {idx}: Kh·ªõp ho√†n to√†n (ƒê·ªô d√†i: {len(decoded_seq)})\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è H√ÄNG {idx}: C√ì S·ª∞ KH√ÅC BI·ªÜT!\")\n",
    "            # In ra 10 k√Ω t·ª± ƒë·∫ßu ti√™n ƒë·ªÉ so s√°nh\n",
    "            print(f\"   G·ªëc: {original_seq[:10]}...\")\n",
    "            print(f\"   M√£ : {decoded_seq[:10]}...\")\n",
    "\n",
    "        # 4. Ki·ªÉm tra xem c√≥ vector n√†o b·ªã l·ªói (v√≠ d·ª• c√≥ 2 s·ªë 1 trong 1 h√†ng)\n",
    "        invalid_rows = np.where(np.sum(encoded_seq, axis=1) > 1)[0]\n",
    "        if len(invalid_rows) > 0:\n",
    "            print(f\"‚ùå L·ªñI LOGIC: C√≥ {len(invalid_rows)} h√†ng ch·ª©a nhi·ªÅu h∆°n m·ªôt gi√° tr·ªã 1.0\")\n",
    "\n",
    "\n",
    "pbar_files = tqdm(test_files, desc=\"Overall Progress\", unit=\"file\")\n",
    "\n",
    "for csv_file in pbar_files:\n",
    "    path = os.path.join(PREPARED_FOLDER, csv_file)\n",
    "    if not os.path.exists(path): continue\n",
    "    \n",
    "    pbar_files.set_postfix({\"file\": csv_file})\n",
    "    \n",
    "    df = pd.read_csv(path)\n",
    "    debug_one_hot_encoding(df['sequence'].values, sample_size=3)\n",
    "    y_true = df['Splicing_types'].values\n",
    "    ds = create_optimized_dataset(df['sequence'], BATCH_SIZE)\n",
    "\n",
    "    total_probs = None \n",
    "    encoding_time = 0\n",
    "    inference_start = time.time()\n",
    "\n",
    "    for i, model in enumerate(tqdm(models, desc=f\" ‚Ü™ Models Ensemble\", leave=False)):\n",
    "        # ƒêo th·ªùi gian encoding ·ªü model ƒë·∫ßu ti√™n (l√∫c generator th·ª±c s·ª± ch·∫°y)\n",
    "        if i == 0:\n",
    "            enc_start = time.time()\n",
    "            preds = model.predict(ds, verbose=1)\n",
    "            encoding_time = time.time() - enc_start\n",
    "        else:\n",
    "            preds = model.predict(ds, verbose=1)\n",
    "        \n",
    "        # --- S·ª¨A L·ªñI TRUY C·∫¨P CH·ªà S·ªê (IndexError Fix) ---\n",
    "        if preds.ndim == 3:\n",
    "            if preds.shape[1] > CONTEXT:\n",
    "                # Tr∆∞·ªùng h·ª£p model tr·∫£ v·ªÅ c·∫£ chu·ªói (vd: 10001)\n",
    "                center_probs = preds[:, CONTEXT, :]\n",
    "            else:\n",
    "                # Tr∆∞·ªùng h·ª£p model tr·∫£ v·ªÅ singleton dimension (vd: shape (batch, 1, 3))\n",
    "                center_probs = preds[:, 0, :]\n",
    "        else:\n",
    "            # Tr∆∞·ªùng h·ª£p model tr·∫£ v·ªÅ 2D (batch, classes)\n",
    "            center_probs = preds\n",
    "        \n",
    "        if total_probs is None:\n",
    "            total_probs = center_probs\n",
    "        else:\n",
    "            total_probs += center_probs\n",
    "            \n",
    "    avg_probs = total_probs / len(models)\n",
    "    total_duration = time.time() - inference_start\n",
    "    \n",
    "    # Mapping nh√£n theo ƒë√∫ng th·ª© t·ª± (None, Donor, Acceptor)\n",
    "    probs_mapped = np.stack([avg_probs[:, 0], avg_probs[:, 2], avg_probs[:, 1]], axis=1)\n",
    "    # preds_mapped = np.argmax(probs_mapped, axis=1)\n",
    "\n",
    "    THRESHOLD = 0.0000025 # Ng∆∞·ª°ng nh·∫°y b√©n cho Donor/Acceptor\n",
    "\n",
    "    # L·∫•y x√°c su·∫•t Donor v√† Acceptor\n",
    "    p_donor = probs_mapped[:, 1]\n",
    "    p_acceptor = probs_mapped[:, 2]\n",
    "\n",
    "    # T·∫°o nh√£n d·ª± ƒëo√°n: ∆Øu ti√™n Donor/Acceptor n·∫øu v∆∞·ª£t ng∆∞·ª°ng\n",
    "    preds_mapped = np.zeros(len(probs_mapped), dtype=int)\n",
    "    for i in range(len(probs_mapped)):\n",
    "        if p_donor[i] > THRESHOLD or p_acceptor[i] > THRESHOLD:\n",
    "            preds_mapped[i] = 1 if p_donor[i] > p_acceptor[i] else 2\n",
    "        else:\n",
    "            preds_mapped[i] = 0\n",
    "    \n",
    "    print(f\"\\n--- Ki·ªÉm tra ph√¢n ph·ªëi x√°c su·∫•t cho {csv_file} ---\")\n",
    "    for i in [1, 2]:\n",
    "        mask = (y_true == i)\n",
    "        if np.any(mask):\n",
    "            probs_label = probs_mapped[mask, i]\n",
    "            mean_p = np.mean(probs_label)\n",
    "            max_p = np.max(probs_label)\n",
    "            \n",
    "            # L·∫•y Top 10 gi√° tr·ªã th·∫•p nh·∫•t (ƒë·ªÉ xem model t·ª± tin th·∫•p ƒë·∫øn m·ª©c n√†o)\n",
    "            num_elements = len(probs_label)\n",
    "            k = min(10, num_elements) \n",
    "            \n",
    "            # np.partition ƒë∆∞a k ph·∫ßn t·ª≠ nh·ªè nh·∫•t l√™n ƒë·∫ßu\n",
    "            top_k_min = np.sort(np.partition(probs_label, k-1)[:k])\n",
    "            \n",
    "            top_str = \", \".join([f\"{val:.10f}\" for val in top_k_min])\n",
    "            print(f\"   Nh√£n {i}: Avg = {mean_p:.6f}, Max = {max_p:.6f}, Top {k} Min = [{top_str}]\")\n",
    "        else:\n",
    "            print(f\"   Nh√£n {i}: Kh√¥ng c√≥ d·ªØ li·ªáu trong y_true\")\n",
    "\n",
    "    try:\n",
    "        results = compute_metrics(y_true, preds_mapped, probs=probs_mapped, k=2)\n",
    "        \n",
    "        # L∆∞u th√¥ng tin benchmarking\n",
    "        results['benchmarking'] = {\n",
    "            'encoding_time_sec': round(encoding_time, 4),\n",
    "            'total_inference_time_sec': round(total_duration, 4),\n",
    "            'samples_per_second': round(len(df) * len(models) / total_duration, 2)\n",
    "        }\n",
    "        \n",
    "        cm = confusion_matrix(y_true, preds_mapped)\n",
    "        output = {\"metrics\": results, \"confusion_matrix\": cm.tolist()}\n",
    "        \n",
    "        json_path = os.path.join(RESULTS_DIR, csv_file.replace('.csv', '_results.json'))\n",
    "        with open(json_path, 'w') as f:\n",
    "            json.dump(output, f, indent=4)\n",
    "            \n",
    "        tqdm.write(f\"‚úÖ {csv_file} | Enc: {encoding_time:.2f}s | Total: {total_duration:.2f}s\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error with {csv_file}: {e}\")\n",
    "\n",
    "print(\"\\n‚ú® ALL DATASETS PROCESSED SUCCESSFULLY!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67aacbb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SpliceAI_official",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
