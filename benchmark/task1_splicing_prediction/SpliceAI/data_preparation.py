import pandas as pd
from pyfaidx import Fasta
from Bio.Seq import Seq
import os
import time
from concurrent.futures import ThreadPoolExecutor
from tqdm import tqdm

# --- Cáº¤U HÃŒNH ---
GENOME_PATH = r"D:\Homo_sapiens.GRCh38.dna.primary_assembly.fa"
DATA_FOLDER = r"D:\Bio_sequence_Research_AITALAB\train\task1_splicing_prediction\data_preparation\train_val"
PREPARED_FOLDER = "prepared_data/"
CONTEXT = 5000 

def get_sequence_worker(row, fasta_obj, target_len):
    try:
        parts = row['id'].split('_')
        chrom, pos, strand = parts[1], int(parts[2]), parts[3]
        
        start = (pos - 1) - CONTEXT
        end = (pos - 1) + CONTEXT + 1
        
        # pyfaidx láº¥y sequence cá»±c nhanh vÃ  há»— trá»£ xá»­ lÃ½ biÃªn tá»± Ä‘á»™ng
        # LÆ°u Ã½: pyfaidx dÃ¹ng 1-based indexing nhÆ°ng slice giá»‘ng python
        seq_str = str(fasta_obj[chrom][max(0, start):end]).upper()
        
        # BÃ¹ 'N' náº¿u start Ã¢m
        if start < 0:
            seq_str = ("N" * abs(start)) + seq_str
        
        # BÃ¹ 'N' náº¿u thiáº¿u Ä‘á»™ dÃ i
        if len(seq_str) < target_len:
            seq_str = seq_str + ("N" * (target_len - len(seq_str)))
            
        if strand == '-':
            seq_str = str(Seq(seq_str).reverse_complement())
            
        return seq_str
    except Exception:
        return "N" * target_len

def prepare_csv_datasets(file_list):
    # 1. Load Genome báº±ng pyfaidx (táº¡o file .fai Ä‘á»ƒ truy xuáº¥t cá»±c nhanh)
    print(f"[{time.strftime('%H:%M:%S')}] Loading Genome with pyfaidx...")
    genome = Fasta(GENOME_PATH, sequence_always_upper=True)
    
    target_len = 2 * CONTEXT + 1
    os.makedirs(PREPARED_FOLDER, exist_ok=True)
    
    for file_name in file_list:
        file_start = time.time()
        input_path = os.path.join(DATA_FOLDER, file_name)
        output_path = os.path.join(PREPARED_FOLDER, file_name)
        
        df = pd.read_csv(input_path)
        
        # --- BÃ KÃP TÄ‚NG Tá»C: SORTING ---
        # TÃ¡ch chrom vÃ  pos táº¡m thá»i Ä‘á»ƒ sort, giÃºp á»• cá»©ng Ä‘á»c tuáº§n tá»±
        print(f"Sorting {file_name} for sequential disk access...")
        df[['_tmp_chr', '_tmp_pos']] = df['id'].str.split('_', expand=True)[[1, 2]]
        df['_tmp_pos'] = df['_tmp_pos'].astype(int)
        df = df.sort_values(['_tmp_chr', '_tmp_pos']).reset_index(drop=True)
        # -------------------------------

        print(f"ðŸš€ Processing: {file_name} ({len(df)} rows)")
        
        # DÃ¹ng map hoáº·c list comprehension vá»›i pyfaidx thÆ°á»ng nhanh hÆ¡n thread 
        # vÃ¬ pyfaidx Ä‘Ã£ tá»‘i Æ°u viá»‡c buffer file.
        results = []
        for _, row in tqdm(df.iterrows(), total=len(df), desc="Extracting"):
            results.append(get_sequence_worker(row, genome, target_len))
            
        df['sequence'] = results
        
        # XÃ³a cÃ¡c cá»™t táº¡m vÃ  lÆ°u
        df = df.drop(columns=['_tmp_chr', '_tmp_pos'])
        df.to_csv(output_path, index=False)
        
        duration = time.time() - file_start
        print(f"âœ… Done {file_name} | Speed: {len(df)/duration:.2f} seq/s")