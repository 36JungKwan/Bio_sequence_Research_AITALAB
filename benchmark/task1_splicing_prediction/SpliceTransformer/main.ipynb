{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10cc9900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¦ Loading model & metrics...\n",
      "âœ… Model loaded\n",
      "ðŸ§ª Test files: ['test_1_1_1.csv', 'test_2_1_1.csv', 'test_4_1_1.csv', 'test_10_1_1.csv', 'test_100_1_1.csv']\n",
      "\n",
      "ðŸš€ Inference for ratio 1_1_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference 1_1_1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 412/412 [06:29<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Prediction distribution: Counter({0: 18417, 1: 4166, 2: 3727})\n",
      "ðŸ’¾ Saved â†’ D:\\Bio_sequence_Research_AITALAB\\benchmark\\task1_splicing_prediction\\SpliceTransformer\\result\\metrics_1_1_1.json\n",
      "\n",
      "ðŸš€ Inference for ratio 2_1_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference 2_1_1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 549/549 [08:33<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Prediction distribution: Counter({0: 24592, 1: 5470, 2: 5070})\n",
      "ðŸ’¾ Saved â†’ D:\\Bio_sequence_Research_AITALAB\\benchmark\\task1_splicing_prediction\\SpliceTransformer\\result\\metrics_2_1_1.json\n",
      "\n",
      "ðŸš€ Inference for ratio 4_1_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference 4_1_1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 825/825 [12:30<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Prediction distribution: Counter({0: 36943, 2: 7921, 1: 7912})\n",
      "ðŸ’¾ Saved â†’ D:\\Bio_sequence_Research_AITALAB\\benchmark\\task1_splicing_prediction\\SpliceTransformer\\result\\metrics_4_1_1.json\n",
      "\n",
      "ðŸš€ Inference for ratio 10_1_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference 10_1_1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1652/1652 [24:13<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Prediction distribution: Counter({0: 73995, 2: 16948, 1: 14765})\n",
      "ðŸ’¾ Saved â†’ D:\\Bio_sequence_Research_AITALAB\\benchmark\\task1_splicing_prediction\\SpliceTransformer\\result\\metrics_10_1_1.json\n",
      "\n",
      "ðŸš€ Inference for ratio 100_1_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference 100_1_1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13502/13502 [3:22:27<00:00,  1.11it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Prediction distribution: Counter({0: 604862, 2: 144236, 1: 114991})\n",
      "ðŸ’¾ Saved â†’ D:\\Bio_sequence_Research_AITALAB\\benchmark\\task1_splicing_prediction\\SpliceTransformer\\result\\metrics_100_1_1.json\n",
      "\n",
      "ðŸŽ‰ FINAL INFERENCE FINISHED (ALL TRICKS APPLIED)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# SpliceTransformer FINAL INFERENCE (ALL-IN BEST PRACTICE)\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import importlib.util\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "# ================= CONFIG =================\n",
    "MODEL_MAX_LEN = 8192\n",
    "SEQ_LEN = 601\n",
    "BATCH_SIZE = 64\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ---- INFERENCE HYPERPARAMS ----\n",
    "WINDOW_RADIUS = 25          # pooling Â±25\n",
    "TEMPERATURE = 0.7           # soften / sharpen probs\n",
    "TOP_SPLICE_RATIO = 0.30     # percentile-based decision (0.2â€“0.4)\n",
    "\n",
    "# ================= PATHS =================\n",
    "DATA_DIR = r\"D:\\Bio_sequence_Research_AITALAB\\benchmark\\task1_splicing_prediction\\SpliceTransformer\\data\"\n",
    "RESULT_DIR = r\"D:\\Bio_sequence_Research_AITALAB\\benchmark\\task1_splicing_prediction\\SpliceTransformer\\result\"\n",
    "CKPT_PATH = r\"D:\\Bio_sequence_Research_AITALAB\\benchmark\\task1_splicing_prediction\\SpliceTransformer\\SpTransformer_pytorch.ckpt\"\n",
    "MODEL_CODE = r\"D:\\Bio_sequence_Research_AITALAB\\benchmark\\task1_splicing_prediction\\SpliceTransformer\\SpliceTransformer-main\\model\\model.py\"\n",
    "METRICS_FILE = r\"D:\\Bio_sequence_Research_AITALAB\\benchmark\\task1_splicing_prediction\\SpliceTransformer\\metrics.py\"\n",
    "\n",
    "os.makedirs(RESULT_DIR, exist_ok=True)\n",
    "\n",
    "# ================= UTILS =================\n",
    "def load_module(path, name):\n",
    "    spec = importlib.util.spec_from_file_location(name, path)\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(module)\n",
    "    return module\n",
    "\n",
    "# ================= DATASET =================\n",
    "class SpliceInferenceDataset(Dataset):\n",
    "    def __init__(self, csv_path):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.map = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n",
    "        self.pad_left = (MODEL_MAX_LEN - SEQ_LEN) // 2\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def encode_onehot(self, seq):\n",
    "        onehot = np.zeros((4, len(seq)), dtype=np.float32)\n",
    "        for i, c in enumerate(seq):\n",
    "            if c in self.map:\n",
    "                onehot[self.map[c], i] = 1.0\n",
    "        return onehot\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.df.iloc[idx][\"sequence\"].upper().strip()\n",
    "        label = int(self.df.iloc[idx][\"Splicing_types\"])\n",
    "\n",
    "        # ---- CASE 1: already full length ----\n",
    "        if len(seq) == MODEL_MAX_LEN:\n",
    "            x = self.encode_onehot(seq)\n",
    "\n",
    "        # ---- CASE 2: short â†’ center pad ----\n",
    "        elif len(seq) == SEQ_LEN:\n",
    "            # ðŸ”¥ non-zero pad to avoid background bias\n",
    "            x = np.full((4, MODEL_MAX_LEN), 0.25, dtype=np.float32)\n",
    "            onehot = self.encode_onehot(seq)\n",
    "            x[:, self.pad_left:self.pad_left + SEQ_LEN] = onehot\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected sequence length {len(seq)}\")\n",
    "\n",
    "        return torch.tensor(x), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "# ================= LOAD MODEL & METRICS =================\n",
    "print(\"ðŸ“¦ Loading model & metrics...\")\n",
    "metrics_mod = load_module(METRICS_FILE, \"metrics\")\n",
    "model_mod = load_module(MODEL_CODE, \"model\")\n",
    "\n",
    "model = model_mod.SpTransformer(\n",
    "    dim=128,\n",
    "    tissue_num=15,\n",
    "    attn_depth=6,\n",
    "    max_seq_len=MODEL_MAX_LEN\n",
    ").to(DEVICE)\n",
    "\n",
    "ckpt = torch.load(CKPT_PATH, map_location=DEVICE)\n",
    "state_dict = ckpt.get(\"state_dict\", ckpt)\n",
    "state_dict = {k.replace(\"model.\", \"\"): v for k, v in state_dict.items()}\n",
    "model.load_state_dict(state_dict, strict=False)\n",
    "model.eval()\n",
    "\n",
    "print(\"âœ… Model loaded\")\n",
    "\n",
    "# ================= SORT TEST FILES =================\n",
    "def parse_ratio(fname):\n",
    "    return int(fname.split(\"_\")[1])\n",
    "\n",
    "test_files = sorted(\n",
    "    [f for f in os.listdir(DATA_DIR) if f.startswith(\"test_\")],\n",
    "    key=parse_ratio\n",
    ")\n",
    "\n",
    "print(\"ðŸ§ª Test files:\", test_files)\n",
    "\n",
    "# ================= INFERENCE =================\n",
    "for fname in test_files:\n",
    "    ratio = fname.replace(\"test_\", \"\").replace(\".csv\", \"\")\n",
    "    print(f\"\\nðŸš€ Inference for ratio {ratio}\")\n",
    "\n",
    "    dataset = SpliceInferenceDataset(os.path.join(DATA_DIR, fname))\n",
    "    loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    all_labels, all_probs = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(loader, desc=f\"Inference {ratio}\"):\n",
    "            inputs = inputs.to(DEVICE)\n",
    "\n",
    "            outputs = model(inputs)             # (B, C, L)\n",
    "            splice_logits = outputs[:, :3, :]   # bg, acc, donor\n",
    "\n",
    "            # ---- CENTER WINDOW POOLING ----\n",
    "            center = splice_logits.shape[-1] // 2\n",
    "            window = splice_logits[:, :, center-WINDOW_RADIUS:center+WINDOW_RADIUS+1]\n",
    "            pooled_logits = torch.max(window, dim=2)[0]\n",
    "\n",
    "            # ---- TEMPERATURE SCALING ----\n",
    "            probs = torch.softmax(pooled_logits / TEMPERATURE, dim=1)\n",
    "\n",
    "            all_labels.extend(labels.numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_probs = np.array(all_probs)\n",
    "\n",
    "    # =====================================================\n",
    "    # ðŸ”¥ RANK-BASED + SPLICE-CONFIDENCE DECISION (CORE)\n",
    "    # =====================================================\n",
    "    splice_scores = np.max(all_probs[:, 1:], axis=1)\n",
    "\n",
    "    threshold = np.percentile(\n",
    "        splice_scores,\n",
    "        100 * (1 - TOP_SPLICE_RATIO)\n",
    "    )\n",
    "\n",
    "    all_preds = []\n",
    "    for p, s in zip(all_probs, splice_scores):\n",
    "        if s < threshold:\n",
    "            all_preds.append(0)\n",
    "        else:\n",
    "            all_preds.append(1 if p[1] > p[2] else 2)\n",
    "\n",
    "    all_preds = np.array(all_preds)\n",
    "\n",
    "    print(\"ðŸ“Š Prediction distribution:\", Counter(all_preds))\n",
    "\n",
    "    # ================= METRICS =================\n",
    "    metrics = metrics_mod.compute_metrics(\n",
    "        labels=all_labels,\n",
    "        preds=all_preds,\n",
    "        probs=all_probs,\n",
    "        k=2\n",
    "    )\n",
    "\n",
    "    # ================= SAVE =================\n",
    "    output = {\n",
    "        \"test_file\": fname,\n",
    "        \"ratio\": ratio,\n",
    "        \"window_radius\": WINDOW_RADIUS,\n",
    "        \"temperature\": TEMPERATURE,\n",
    "        \"top_splice_ratio\": TOP_SPLICE_RATIO,\n",
    "        \"num_samples\": len(all_labels),\n",
    "        \"metrics\": metrics\n",
    "    }\n",
    "\n",
    "    out_path = os.path.join(RESULT_DIR, f\"metrics_{ratio}.json\")\n",
    "    with open(out_path, \"w\") as f:\n",
    "        json.dump(output, f, indent=4)\n",
    "\n",
    "    print(f\"ðŸ’¾ Saved â†’ {out_path}\")\n",
    "\n",
    "print(\"\\nðŸŽ‰ FINAL INFERENCE FINISHED (ALL TRICKS APPLIED)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "splice_transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
