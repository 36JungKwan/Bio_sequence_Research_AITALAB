{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10cc9900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Loading model & metrics...\n",
      "‚úÖ Model loaded\n",
      "üß™ Test files: ['test_1_1_1.csv', 'test_2_1_1.csv', 'test_4_1_1.csv', 'test_10_1_1.csv', 'test_100_1_1.csv']\n",
      "\n",
      "üöÄ Inference for ratio 1_1_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference 1_1_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 412/412 [06:29<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Prediction distribution: Counter({0: 18417, 1: 4166, 2: 3727})\n",
      "üíæ Saved ‚Üí D:\\Bio_sequence_Research_AITALAB\\benchmark\\task1_splicing_prediction\\SpliceTransformer\\result\\metrics_1_1_1.json\n",
      "\n",
      "üöÄ Inference for ratio 2_1_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference 2_1_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 549/549 [08:33<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Prediction distribution: Counter({0: 24592, 1: 5470, 2: 5070})\n",
      "üíæ Saved ‚Üí D:\\Bio_sequence_Research_AITALAB\\benchmark\\task1_splicing_prediction\\SpliceTransformer\\result\\metrics_2_1_1.json\n",
      "\n",
      "üöÄ Inference for ratio 4_1_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference 4_1_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 825/825 [12:30<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Prediction distribution: Counter({0: 36943, 2: 7921, 1: 7912})\n",
      "üíæ Saved ‚Üí D:\\Bio_sequence_Research_AITALAB\\benchmark\\task1_splicing_prediction\\SpliceTransformer\\result\\metrics_4_1_1.json\n",
      "\n",
      "üöÄ Inference for ratio 10_1_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference 10_1_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1652/1652 [24:13<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Prediction distribution: Counter({0: 73995, 2: 16948, 1: 14765})\n",
      "üíæ Saved ‚Üí D:\\Bio_sequence_Research_AITALAB\\benchmark\\task1_splicing_prediction\\SpliceTransformer\\result\\metrics_10_1_1.json\n",
      "\n",
      "üöÄ Inference for ratio 100_1_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference 100_1_1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13502/13502 [3:22:27<00:00,  1.11it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Prediction distribution: Counter({0: 604862, 2: 144236, 1: 114991})\n",
      "üíæ Saved ‚Üí D:\\Bio_sequence_Research_AITALAB\\benchmark\\task1_splicing_prediction\\SpliceTransformer\\result\\metrics_100_1_1.json\n",
      "\n",
      "üéâ FINAL INFERENCE FINISHED (ALL TRICKS APPLIED)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# SpliceTransformer FINAL INFERENCE (ALL-IN BEST PRACTICE)\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import importlib.util\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "# ================= CONFIG =================\n",
    "MODEL_MAX_LEN = 8192\n",
    "SEQ_LEN = 601\n",
    "BATCH_SIZE = 64\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ---- INFERENCE HYPERPARAMS ----\n",
    "WINDOW_RADIUS = 25          # pooling ¬±25\n",
    "TEMPERATURE = 0.7           # soften / sharpen probs\n",
    "TOP_SPLICE_RATIO = 0.30     # percentile-based decision (0.2‚Äì0.4)\n",
    "\n",
    "# ================= PATHS =================\n",
    "DATA_DIR = r\"D:\\Bio_sequence_Research_AITALAB\\benchmark\\task1_splicing_prediction\\SpliceTransformer\\data\"\n",
    "RESULT_DIR = r\"D:\\Bio_sequence_Research_AITALAB\\benchmark\\task1_splicing_prediction\\SpliceTransformer\\result\"\n",
    "CKPT_PATH = r\"D:\\Bio_sequence_Research_AITALAB\\benchmark\\task1_splicing_prediction\\SpliceTransformer\\SpTransformer_pytorch.ckpt\"\n",
    "MODEL_CODE = r\"D:\\Bio_sequence_Research_AITALAB\\benchmark\\task1_splicing_prediction\\SpliceTransformer\\SpliceTransformer-main\\model\\model.py\"\n",
    "METRICS_FILE = r\"D:\\Bio_sequence_Research_AITALAB\\benchmark\\task1_splicing_prediction\\SpliceTransformer\\metrics.py\"\n",
    "\n",
    "os.makedirs(RESULT_DIR, exist_ok=True)\n",
    "\n",
    "# ================= UTILS =================\n",
    "def load_module(path, name):\n",
    "    spec = importlib.util.spec_from_file_location(name, path)\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(module)\n",
    "    return module\n",
    "\n",
    "# ================= DATASET =================\n",
    "class SpliceInferenceDataset(Dataset):\n",
    "    def __init__(self, csv_path):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.map = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n",
    "        self.pad_left = (MODEL_MAX_LEN - SEQ_LEN) // 2\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def encode_onehot(self, seq):\n",
    "        onehot = np.zeros((4, len(seq)), dtype=np.float32)\n",
    "        for i, c in enumerate(seq):\n",
    "            if c in self.map:\n",
    "                onehot[self.map[c], i] = 1.0\n",
    "        return onehot\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.df.iloc[idx][\"sequence\"].upper().strip()\n",
    "        label = int(self.df.iloc[idx][\"Splicing_types\"])\n",
    "\n",
    "        # ---- CASE 1: already full length ----\n",
    "        if len(seq) == MODEL_MAX_LEN:\n",
    "            x = self.encode_onehot(seq)\n",
    "\n",
    "        # ---- CASE 2: short ‚Üí center pad ----\n",
    "        elif len(seq) == SEQ_LEN:\n",
    "            # üî• non-zero pad to avoid background bias\n",
    "            x = np.full((4, MODEL_MAX_LEN), 0.25, dtype=np.float32)\n",
    "            onehot = self.encode_onehot(seq)\n",
    "            x[:, self.pad_left:self.pad_left + SEQ_LEN] = onehot\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected sequence length {len(seq)}\")\n",
    "\n",
    "        return torch.tensor(x), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "# ================= LOAD MODEL & METRICS =================\n",
    "print(\"üì¶ Loading model & metrics...\")\n",
    "metrics_mod = load_module(METRICS_FILE, \"metrics\")\n",
    "model_mod = load_module(MODEL_CODE, \"model\")\n",
    "\n",
    "model = model_mod.SpTransformer(\n",
    "    dim=128,\n",
    "    tissue_num=15,\n",
    "    attn_depth=6,\n",
    "    max_seq_len=MODEL_MAX_LEN\n",
    ").to(DEVICE)\n",
    "\n",
    "ckpt = torch.load(CKPT_PATH, map_location=DEVICE)\n",
    "state_dict = ckpt.get(\"state_dict\", ckpt)\n",
    "state_dict = {k.replace(\"model.\", \"\"): v for k, v in state_dict.items()}\n",
    "model.load_state_dict(state_dict, strict=False)\n",
    "model.eval()\n",
    "\n",
    "print(\"‚úÖ Model loaded\")\n",
    "\n",
    "# ================= SORT TEST FILES =================\n",
    "def parse_ratio(fname):\n",
    "    return int(fname.split(\"_\")[1])\n",
    "\n",
    "test_files = sorted(\n",
    "    [f for f in os.listdir(DATA_DIR) if f.startswith(\"test_\")],\n",
    "    key=parse_ratio\n",
    ")\n",
    "\n",
    "print(\"üß™ Test files:\", test_files)\n",
    "\n",
    "# ================= INFERENCE =================\n",
    "for fname in test_files:\n",
    "    ratio = fname.replace(\"test_\", \"\").replace(\".csv\", \"\")\n",
    "    print(f\"\\nüöÄ Inference for ratio {ratio}\")\n",
    "\n",
    "    dataset = SpliceInferenceDataset(os.path.join(DATA_DIR, fname))\n",
    "    loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    all_labels, all_probs = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(loader, desc=f\"Inference {ratio}\"):\n",
    "            inputs = inputs.to(DEVICE)\n",
    "\n",
    "            outputs = model(inputs)             # (B, C, L)\n",
    "            splice_logits = outputs[:, :3, :]   # bg, acc, donor\n",
    "\n",
    "            # ---- CENTER WINDOW POOLING ----\n",
    "            center = splice_logits.shape[-1] // 2\n",
    "            window = splice_logits[:, :, center-WINDOW_RADIUS:center+WINDOW_RADIUS+1]\n",
    "            pooled_logits = torch.max(window, dim=2)[0]\n",
    "\n",
    "            # ---- TEMPERATURE SCALING ----\n",
    "            probs = torch.softmax(pooled_logits / TEMPERATURE, dim=1)\n",
    "\n",
    "            all_labels.extend(labels.numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_probs = np.array(all_probs)\n",
    "\n",
    "    # =====================================================\n",
    "    # üî• RANK-BASED + SPLICE-CONFIDENCE DECISION (CORE)\n",
    "    # =====================================================\n",
    "    splice_scores = np.max(all_probs[:, 1:], axis=1)\n",
    "\n",
    "    threshold = np.percentile(\n",
    "        splice_scores,\n",
    "        100 * (1 - TOP_SPLICE_RATIO)\n",
    "    )\n",
    "\n",
    "    all_preds = []\n",
    "    for p, s in zip(all_probs, splice_scores):\n",
    "        if s < threshold:\n",
    "            all_preds.append(0)\n",
    "        else:\n",
    "            all_preds.append(1 if p[1] > p[2] else 2)\n",
    "\n",
    "    all_preds = np.array(all_preds)\n",
    "\n",
    "    print(\"üìä Prediction distribution:\", Counter(all_preds))\n",
    "\n",
    "    # ================= METRICS =================\n",
    "    metrics = metrics_mod.compute_metrics(\n",
    "        labels=all_labels,\n",
    "        preds=all_preds,\n",
    "        probs=all_probs,\n",
    "        k=2\n",
    "    )\n",
    "\n",
    "    # ================= SAVE =================\n",
    "    output = {\n",
    "        \"test_file\": fname,\n",
    "        \"ratio\": ratio,\n",
    "        \"window_radius\": WINDOW_RADIUS,\n",
    "        \"temperature\": TEMPERATURE,\n",
    "        \"top_splice_ratio\": TOP_SPLICE_RATIO,\n",
    "        \"num_samples\": len(all_labels),\n",
    "        \"metrics\": metrics\n",
    "    }\n",
    "\n",
    "    out_path = os.path.join(RESULT_DIR, f\"metrics_{ratio}.json\")\n",
    "    with open(out_path, \"w\") as f:\n",
    "        json.dump(output, f, indent=4)\n",
    "\n",
    "    print(f\"üíæ Saved ‚Üí {out_path}\")\n",
    "\n",
    "print(\"\\nüéâ FINAL INFERENCE FINISHED (ALL TRICKS APPLIED)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9b10e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Loading model & metrics...\n",
      "‚úÖ Model loaded\n",
      "\n",
      "üöÄ Inference for ratio 1_1_1 | Threshold: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Model: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 412/412 [06:31<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Swapping Probability Columns (1 <-> 2) to match Labels...\n",
      "üìä Prediction Stats: Counter({0: 9465, 1: 8520, 2: 8325})\n",
      "\n",
      "Confusion Matrix:\n",
      " [[7815  577  430]\n",
      " [ 892 7858   72]\n",
      " [ 758   85 7823]]\n",
      "üíæ Saved ‚Üí D:\\Bio_sequence_Research_AITALAB\\benchmark\\task1_splicing_prediction\\SpliceTransformer\\result\\metrics_1_1_1.json\n",
      "\n",
      "üöÄ Inference for ratio 2_1_1 | Threshold: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Model: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 549/549 [08:38<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Swapping Probability Columns (1 <-> 2) to match Labels...\n",
      "üìä Prediction Stats: Counter({0: 17315, 1: 9089, 2: 8728})\n",
      "\n",
      "Confusion Matrix:\n",
      " [[15666  1146   832]\n",
      " [  892  7858    72]\n",
      " [  757    85  7824]]\n",
      "üíæ Saved ‚Üí D:\\Bio_sequence_Research_AITALAB\\benchmark\\task1_splicing_prediction\\SpliceTransformer\\result\\metrics_2_1_1.json\n",
      "\n",
      "üöÄ Inference for ratio 4_1_1 | Threshold: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Model: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 825/825 [12:56<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Swapping Probability Columns (1 <-> 2) to match Labels...\n",
      "üìä Prediction Stats: Counter({0: 32929, 1: 10275, 2: 9572})\n",
      "\n",
      "Confusion Matrix:\n",
      " [[31279  2332  1677]\n",
      " [  892  7858    72]\n",
      " [  758    85  7823]]\n",
      "üíæ Saved ‚Üí D:\\Bio_sequence_Research_AITALAB\\benchmark\\task1_splicing_prediction\\SpliceTransformer\\result\\metrics_4_1_1.json\n",
      "\n",
      "üöÄ Inference for ratio 10_1_1 | Threshold: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Model: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1652/1652 [25:58<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Swapping Probability Columns (1 <-> 2) to match Labels...\n",
      "üìä Prediction Stats: Counter({0: 80042, 1: 13602, 2: 12064})\n",
      "\n",
      "Confusion Matrix:\n",
      " [[78393  5659  4168]\n",
      " [  892  7858    72]\n",
      " [  757    85  7824]]\n",
      "üíæ Saved ‚Üí D:\\Bio_sequence_Research_AITALAB\\benchmark\\task1_splicing_prediction\\SpliceTransformer\\result\\metrics_10_1_1.json\n",
      "\n",
      "üöÄ Inference for ratio 100_1_1 | Threshold: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Model: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13502/13502 [3:28:52<00:00,  1.08it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Swapping Probability Columns (1 <-> 2) to match Labels...\n",
      "üìä Prediction Stats: Counter({0: 756328, 1: 61099, 2: 46662})\n",
      "\n",
      "Confusion Matrix:\n",
      " [[754817  53744  39364]\n",
      " [   819   7279     63]\n",
      " [   692     76   7235]]\n",
      "üíæ Saved ‚Üí D:\\Bio_sequence_Research_AITALAB\\benchmark\\task1_splicing_prediction\\SpliceTransformer\\result\\metrics_100_1_1.json\n",
      "\n",
      "üéâ DONE.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# SpliceTransformer FINAL INFERENCE (MANUAL THRESHOLD)\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import importlib.util\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# ================= CONFIG (T√ôY CH·ªàNH T·∫†I ƒê√ÇY) =================\n",
    "MODEL_MAX_LEN = 8192\n",
    "SEQ_LEN = 601\n",
    "BATCH_SIZE = 64\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ---- INFERENCE HYPERPARAMS ----\n",
    "WINDOW_RADIUS = 25          # pooling ¬±25\n",
    "TEMPERATURE = 0.7           # soften / sharpen probs\n",
    "\n",
    "# üî• C·∫§U H√åNH NG∆Ø·ª†NG (QUAN TR·ªåNG)\n",
    "# N·∫øu True: S·ª≠ d·ª•ng ng∆∞·ª°ng c·ªë ƒë·ªãnh do b·∫°n ƒë·∫∑t (SPLICE_THRESHOLD).\n",
    "# N·∫øu False: S·ª≠ d·ª•ng Top % nh∆∞ code c≈© (TOP_SPLICE_RATIO).\n",
    "USE_FIXED_THRESHOLD = True  \n",
    "\n",
    "# Ng∆∞·ª°ng x√°c su·∫•t ƒë·ªÉ ch·∫•p nh·∫≠n l√† Splice site (0.0 -> 1.0)\n",
    "# V√≠ d·ª•: 0.5 nghƒ©a l√† x√°c su·∫•t ph·∫£i > 50% m·ªõi ƒë∆∞·ª£c coi l√† 1 ho·∫∑c 2. N·∫øu th·∫•p h∆°n s·∫Ω v·ªÅ 0.\n",
    "# 0.00001\n",
    "SPLICE_THRESHOLD = 0.00001 \n",
    "\n",
    "# C·∫•u h√¨nh c≈© (ch·ªâ d√πng khi USE_FIXED_THRESHOLD = False)\n",
    "TOP_SPLICE_RATIO = 0.30     \n",
    "\n",
    "# üî• ƒê·∫£o ng∆∞·ª£c nh√£n (True: 1->2, 2->1)\n",
    "FIX_REVERSED_LABELS = True  \n",
    "\n",
    "# ================= PATHS =================\n",
    "DATA_DIR = r\"D:\\Bio_sequence_Research_AITALAB\\benchmark\\task1_splicing_prediction\\SpliceTransformer\\data\"\n",
    "RESULT_DIR = r\"D:\\Bio_sequence_Research_AITALAB\\benchmark\\task1_splicing_prediction\\SpliceTransformer\\result\"\n",
    "CKPT_PATH = r\"D:\\Bio_sequence_Research_AITALAB\\benchmark\\task1_splicing_prediction\\SpliceTransformer\\SpTransformer_pytorch.ckpt\"\n",
    "MODEL_CODE = r\"D:\\Bio_sequence_Research_AITALAB\\benchmark\\task1_splicing_prediction\\SpliceTransformer\\SpliceTransformer-main\\model\\model.py\"\n",
    "METRICS_FILE = r\"D:\\Bio_sequence_Research_AITALAB\\benchmark\\task1_splicing_prediction\\SpliceTransformer\\metrics.py\"\n",
    "\n",
    "os.makedirs(RESULT_DIR, exist_ok=True)\n",
    "\n",
    "# ================= UTILS & DATASET =================\n",
    "def load_module(path, name):\n",
    "    spec = importlib.util.spec_from_file_location(name, path)\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(module)\n",
    "    return module\n",
    "\n",
    "class SpliceInferenceDataset(Dataset):\n",
    "    def __init__(self, csv_path):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.map = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n",
    "        self.pad_left = (MODEL_MAX_LEN - SEQ_LEN) // 2\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def encode_onehot(self, seq):\n",
    "        onehot = np.zeros((4, len(seq)), dtype=np.float32)\n",
    "        for i, c in enumerate(seq):\n",
    "            if c in self.map:\n",
    "                onehot[self.map[c], i] = 1.0\n",
    "        return onehot\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.df.iloc[idx][\"sequence\"].upper().strip()\n",
    "        label = int(self.df.iloc[idx][\"Splicing_types\"])\n",
    "        if len(seq) == MODEL_MAX_LEN:\n",
    "            x = self.encode_onehot(seq)\n",
    "        elif len(seq) == SEQ_LEN:\n",
    "            x = np.full((4, MODEL_MAX_LEN), 0.25, dtype=np.float32)\n",
    "            onehot = self.encode_onehot(seq)\n",
    "            x[:, self.pad_left:self.pad_left + SEQ_LEN] = onehot\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected sequence length {len(seq)}\")\n",
    "        return torch.tensor(x), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "# ================= LOAD MODEL =================\n",
    "print(\"üì¶ Loading model & metrics...\")\n",
    "metrics_mod = load_module(METRICS_FILE, \"metrics\")\n",
    "model_mod = load_module(MODEL_CODE, \"model\")\n",
    "\n",
    "model = model_mod.SpTransformer(dim=128, tissue_num=15, attn_depth=6, max_seq_len=MODEL_MAX_LEN).to(DEVICE)\n",
    "ckpt = torch.load(CKPT_PATH, map_location=DEVICE)\n",
    "state_dict = ckpt.get(\"state_dict\", ckpt)\n",
    "state_dict = {k.replace(\"model.\", \"\"): v for k, v in state_dict.items()}\n",
    "model.load_state_dict(state_dict, strict=False)\n",
    "model.eval()\n",
    "print(\"‚úÖ Model loaded\")\n",
    "\n",
    "test_files = sorted([f for f in os.listdir(DATA_DIR) if f.startswith(\"test_\")], key=lambda x: int(x.split(\"_\")[1]))\n",
    "\n",
    "# ================= INFERENCE LOOP =================\n",
    "for fname in test_files:\n",
    "    ratio = fname.replace(\"test_\", \"\").replace(\".csv\", \"\")\n",
    "    print(f\"\\nüöÄ Inference for ratio {ratio} | Threshold: {SPLICE_THRESHOLD if USE_FIXED_THRESHOLD else 'Top %'}\")\n",
    "\n",
    "    dataset = SpliceInferenceDataset(os.path.join(DATA_DIR, fname))\n",
    "    loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    all_labels, all_probs = [], []\n",
    "\n",
    "    # 1. Ch·∫°y model l·∫•y x√°c su·∫•t\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(loader, desc=f\"Running Model\"):\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "            splice_logits = outputs[:, :3, :]\n",
    "            \n",
    "            # Pooling & Softmax\n",
    "            center = splice_logits.shape[-1] // 2\n",
    "            window = splice_logits[:, :, center-WINDOW_RADIUS:center+WINDOW_RADIUS+1]\n",
    "            pooled_logits = torch.max(window, dim=2)[0]\n",
    "            probs = torch.softmax(pooled_logits / TEMPERATURE, dim=1)\n",
    "\n",
    "            all_labels.extend(labels.numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_probs = np.array(all_probs)\n",
    "\n",
    "    # -------------------------------------------------------------\n",
    "    # üî• FIX QUAN TR·ªåNG: ƒê·∫£o c·ªôt x√°c su·∫•t NGAY T·ª™ ƒê·∫¶U\n",
    "    # L√∫c n√†y C·ªôt 1 = Acceptor Ch√≠nh X√°c, C·ªôt 2 = Donor Ch√≠nh X√°c\n",
    "    # -------------------------------------------------------------\n",
    "    if FIX_REVERSED_LABELS:\n",
    "        print(\"üîÑ Swapping Probability Columns (1 <-> 2) to match Labels...\")\n",
    "        all_probs[:, [1, 2]] = all_probs[:, [2, 1]]\n",
    "    \n",
    "    # 2. X·ª≠ l√Ω logic g√°n nh√£n (Thresholding)\n",
    "    all_preds = []\n",
    "    \n",
    "    # T√≠nh ng∆∞·ª°ng (n·∫øu d√πng ch·∫ø ƒë·ªô Percentile c≈©)\n",
    "    splice_scores = np.max(all_probs[:, 1:], axis=1) \n",
    "    \n",
    "    if USE_FIXED_THRESHOLD:\n",
    "        decision_threshold = SPLICE_THRESHOLD\n",
    "    else:\n",
    "        decision_threshold = np.percentile(splice_scores, 100 * (1 - TOP_SPLICE_RATIO))\n",
    "        print(f\"   ‚ÑπÔ∏è  Dynamic Threshold (Percentile {TOP_SPLICE_RATIO}): {decision_threshold:.4f}\")\n",
    "\n",
    "    # V√≤ng l·∫∑p quy·∫øt ƒë·ªãnh nh√£n t·ª´ng m·∫´u\n",
    "    for probs in all_probs:\n",
    "        p_bg, p_acc, p_don = probs[0], probs[1], probs[2] \n",
    "        max_splice_prob = max(p_acc, p_don)\n",
    "\n",
    "        # B∆Ø·ªöC 1: So s√°nh v·ªõi ng∆∞·ª°ng (Background vs Splice)\n",
    "        if max_splice_prob < decision_threshold:\n",
    "            pred = 0\n",
    "        else:\n",
    "            # B∆Ø·ªöC 2: So s√°nh gi·ªØa Acc v√† Don\n",
    "            # ‚ö†Ô∏è L∆ØU √ù: V√¨ all_probs ƒë√£ ƒë∆∞·ª£c ƒë·∫£o c·ªôt ·ªü tr√™n r·ªìi,\n",
    "            # n√™n ·ªü ƒë√¢y p_acc > p_don th√¨ ch·∫Øc ch·∫Øn l√† l·ªõp 1 (Acc).\n",
    "            # KH√îNG c·∫ßn ƒë·∫£o nh√£n ·ªü ƒë√¢y n·ªØa!\n",
    "            if p_acc > p_don:\n",
    "                pred = 1 \n",
    "            else:\n",
    "                pred = 2\n",
    "        \n",
    "        all_preds.append(pred)\n",
    "\n",
    "    all_preds = np.array(all_preds)\n",
    "\n",
    "    print(f\"üìä Prediction Stats: {Counter(all_preds)}\")\n",
    "\n",
    "    # ================= METRICS & CONFUSION MATRIX =================\n",
    "    # T√≠nh Confusion Matrix 3x3\n",
    "    cm = confusion_matrix(all_labels, all_preds, labels=[0, 1, 2])\n",
    "    print(\"\\nConfusion Matrix:\\n\", cm)\n",
    "\n",
    "    metrics = metrics_mod.compute_metrics(\n",
    "        labels=all_labels,\n",
    "        preds=all_preds,\n",
    "        probs=all_probs,\n",
    "        k=2\n",
    "    )\n",
    "\n",
    "    # ================= SAVE =================\n",
    "    output = {\n",
    "        \"test_file\": fname,\n",
    "        \"ratio\": ratio,\n",
    "        \"config\": {\n",
    "            \"window_radius\": WINDOW_RADIUS,\n",
    "            \"temperature\": TEMPERATURE,\n",
    "            \"use_fixed_threshold\": USE_FIXED_THRESHOLD,\n",
    "            \"threshold_value\": SPLICE_THRESHOLD if USE_FIXED_THRESHOLD else decision_threshold,\n",
    "            \"fix_reversed_labels\": FIX_REVERSED_LABELS\n",
    "        },\n",
    "        \"confusion_matrix\": cm.tolist(),\n",
    "        \"metrics\": metrics\n",
    "    }\n",
    "\n",
    "    out_path = os.path.join(RESULT_DIR, f\"metrics_{ratio}.json\")\n",
    "    with open(out_path, \"w\") as f:\n",
    "        json.dump(output, f, indent=4)\n",
    "\n",
    "    print(f\"üíæ Saved ‚Üí {out_path}\")\n",
    "\n",
    "print(\"\\nüéâ DONE.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "splice_transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
