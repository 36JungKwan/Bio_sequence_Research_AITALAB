{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c40d41a7",
   "metadata": {},
   "source": [
    "### Config file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "41d5287e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Data paths\n",
    "TRAIN_PARQUET = r\"D:\\Bio_sequence_Research_AITALAB\\train\\task3_variant_prediction\\data\\train.parquet\"\n",
    "VAL_PARQUET = r\"D:\\Bio_sequence_Research_AITALAB\\train\\task3_variant_prediction\\data\\val.parquet\"\n",
    "TEST_PARQUET = r\"D:\\Bio_sequence_Research_AITALAB\\train\\task3_variant_prediction\\data\\test.parquet\"\n",
    "\n",
    "# Embeddings directory\n",
    "EMB_DIR = r\"D:\\Bio_sequence_Research_AITALAB\\benchmark\\task3_variant_prediction\\HyenaDNA\\experiments_hyenadna\"\n",
    "TRAIN_EMB = os.path.join(EMB_DIR, \"train_embeddings.pt\")\n",
    "VAL_EMB = os.path.join(EMB_DIR, \"val_embeddings.pt\")\n",
    "TEST_EMB = os.path.join(EMB_DIR, \"test_embeddings.pt\")\n",
    "\n",
    "# HyenaDNA model\n",
    "HYENADNA_MODEL = \"LongSafari/hyenadna-large-1m-seqlen-hf\"  # Hoặc medium-450k-seqlen\n",
    "DNA_SEQ_LEN = 601  # Max length cho DNA sequences\n",
    "\n",
    "# Embedding batch sizes\n",
    "DNA_BATCH = 128\n",
    "\n",
    "# Model hyperparameters\n",
    "PROJ_DIM = 512\n",
    "FUSION_HIDDEN = [512, 256]\n",
    "DROPOUT = 0.3\n",
    "\n",
    "# Training hyperparameters\n",
    "LR = 1e-4\n",
    "EPOCHS = 60\n",
    "PATIENCE = 5\n",
    "BATCH_SIZE = 512\n",
    "WEIGHT_DECAY = 1e-4\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6855f31",
   "metadata": {},
   "source": [
    "### Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "333fbe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class HyenaDNADataset(Dataset):\n",
    "    \"\"\"Dataset cho HyenaDNA embeddings\"\"\"\n",
    "    def __init__(self, pt_file):\n",
    "        data = torch.load(pt_file)\n",
    "        self.dna_ref = data[\"dna_ref\"]\n",
    "        self.dna_alt = data[\"dna_alt\"]\n",
    "        self.labels = data[\"label\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            self.dna_ref[idx],\n",
    "            self.dna_alt[idx],\n",
    "            self.labels[idx],\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f73e43",
   "metadata": {},
   "source": [
    "### Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f176cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class ModalityProjector(nn.Module):\n",
    "    \"\"\"Projector cho DNA embeddings: [ref, alt, diff] -> proj_dim\"\"\"\n",
    "    def __init__(self, emb_dim, proj_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(emb_dim * 3, proj_dim),\n",
    "            nn.LayerNorm(proj_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, ref, alt):\n",
    "        diff = alt - ref\n",
    "        x = torch.cat([ref, alt, diff], dim=-1)\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class DNAClassifier(nn.Module):\n",
    "    \"\"\"MLP Classifier chỉ dùng DNA embeddings từ HyenaDNA\"\"\"\n",
    "    def __init__(self, dna_dim, proj_dim, hidden_dims, dropout):\n",
    "        super().__init__()\n",
    "        self.dna_proj = ModalityProjector(dna_dim, proj_dim, dropout)\n",
    "        \n",
    "        # Classifier layers\n",
    "        layers = []\n",
    "        in_dim = proj_dim\n",
    "        for h in hidden_dims:\n",
    "            layers.extend([nn.Linear(in_dim, h), nn.ReLU(), nn.Dropout(dropout)])\n",
    "            in_dim = h\n",
    "        \n",
    "        layers.append(nn.Linear(in_dim, 1))\n",
    "        self.classifier = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, dna_ref, dna_alt):\n",
    "        dna_z = self.dna_proj(dna_ref, dna_alt)\n",
    "        return self.classifier(dna_z).squeeze(dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bf6e64",
   "metadata": {},
   "source": [
    "### Precompute Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6e5de95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Loading HyenaDNA model: LongSafari/hyenadna-large-1m-seqlen-hf\n",
      "\n",
      "Processing D:\\Bio_sequence_Research_AITALAB\\train\\task3_variant_prediction\\data\\train.parquet (114568 rows)\n",
      "Embedding ref sequences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding DNA: 100%|██████████| 896/896 [01:36<00:00,  9.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding alt sequences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding DNA: 100%|██████████| 896/896 [01:35<00:00,  9.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to D:\\Bio_sequence_Research_AITALAB\\benchmark\\task3_variant_prediction\\HyenaDNA\\experiments_hyenadna\\train_embeddings.pt\n",
      "  DNA embedding dim: 256\n",
      "  Number of samples: 114568\n",
      "\n",
      "Processing D:\\Bio_sequence_Research_AITALAB\\train\\task3_variant_prediction\\data\\val.parquet (20219 rows)\n",
      "Embedding ref sequences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding DNA: 100%|██████████| 158/158 [00:16<00:00,  9.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding alt sequences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding DNA: 100%|██████████| 158/158 [00:16<00:00,  9.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to D:\\Bio_sequence_Research_AITALAB\\benchmark\\task3_variant_prediction\\HyenaDNA\\experiments_hyenadna\\val_embeddings.pt\n",
      "  DNA embedding dim: 256\n",
      "  Number of samples: 20219\n",
      "\n",
      "Processing D:\\Bio_sequence_Research_AITALAB\\train\\task3_variant_prediction\\data\\test.parquet (4562 rows)\n",
      "Embedding ref sequences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding DNA: 100%|██████████| 36/36 [00:03<00:00,  9.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding alt sequences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding DNA: 100%|██████████| 36/36 [00:03<00:00,  9.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to D:\\Bio_sequence_Research_AITALAB\\benchmark\\task3_variant_prediction\\HyenaDNA\\experiments_hyenadna\\test_embeddings.pt\n",
      "  DNA embedding dim: 256\n",
      "  Number of samples: 4562\n",
      "\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "def embed_dna_hyenadna(seqs, tokenizer, model, batch_size, max_length=601):\n",
    "    \"\"\"Embed DNA sequences using HyenaDNA - lấy center token\"\"\"\n",
    "    all_embs = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, len(seqs), batch_size), desc=\"Embedding DNA\"):\n",
    "            batch = seqs[i : i + batch_size]\n",
    "            inputs = tokenizer(\n",
    "                batch,\n",
    "                return_tensors=\"pt\",\n",
    "                max_length=max_length,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "            )\n",
    "            input_ids = inputs[\"input_ids\"].to(DEVICE)\n",
    "            \n",
    "            outputs = model(input_ids, output_hidden_states=True)\n",
    "            # Lấy hidden state lớp cuối cùng, token ở giữa\n",
    "            last_hidden = outputs.hidden_states[-1]  # [B, L, H]\n",
    "            seq_len = last_hidden.size(1)\n",
    "            center_idx = seq_len // 2\n",
    "            batch_embs = last_hidden[:, center_idx, :].float().cpu()\n",
    "            all_embs.append(batch_embs)\n",
    "    \n",
    "    return torch.cat(all_embs, dim=0)\n",
    "\n",
    "\n",
    "def process_split(parquet_path, out_path, tokenizer, model, batch_size):\n",
    "    \"\"\"Process một split (train/val/test)\"\"\"\n",
    "    df = pd.read_parquet(parquet_path)\n",
    "    print(f\"\\nProcessing {parquet_path} ({len(df)} rows)\")\n",
    "    \n",
    "    # Kiểm tra columns\n",
    "    if \"ref_seq\" not in df.columns or \"alt_seq\" not in df.columns:\n",
    "        raise ValueError(f\"Missing required columns in {parquet_path}\")\n",
    "    \n",
    "    dna_ref = df[\"ref_seq\"].astype(str).tolist()\n",
    "    dna_alt = df[\"alt_seq\"].astype(str).tolist()\n",
    "    \n",
    "    # Kiểm tra label column\n",
    "    if \"label\" in df.columns:\n",
    "        labels = torch.tensor(df[\"label\"].values, dtype=torch.long)\n",
    "    elif \"ClinicalSignificance\" in df.columns:\n",
    "        keep = [\"Pathogenic\", \"Benign\"]\n",
    "        df = df[df[\"ClinicalSignificance\"].isin(keep)].copy()\n",
    "        label_map = {\"Pathogenic\": 1, \"Benign\": 0}\n",
    "        df[\"label\"] = df[\"ClinicalSignificance\"].map(label_map)\n",
    "        labels = torch.tensor(df[\"label\"].values, dtype=torch.long)\n",
    "    else:\n",
    "        raise ValueError(f\"No label column found in {parquet_path}\")\n",
    "    \n",
    "    # Embed DNA sequences\n",
    "    print(\"Embedding ref sequences...\")\n",
    "    dna_ref_emb = embed_dna_hyenadna(dna_ref, tokenizer, model, batch_size, DNA_SEQ_LEN)\n",
    "    \n",
    "    print(\"Embedding alt sequences...\")\n",
    "    dna_alt_emb = embed_dna_hyenadna(dna_alt, tokenizer, model, batch_size, DNA_SEQ_LEN)\n",
    "    \n",
    "    # Lưu embeddings\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    torch.save(\n",
    "        {\n",
    "            \"dna_ref\": dna_ref_emb,\n",
    "            \"dna_alt\": dna_alt_emb,\n",
    "            \"label\": labels,\n",
    "        },\n",
    "        out_path,\n",
    "    )\n",
    "    \n",
    "    print(f\"Saved to {out_path}\")\n",
    "    print(f\"  DNA embedding dim: {dna_ref_emb.shape[1]}\")\n",
    "    print(f\"  Number of samples: {len(labels)}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--split\", type=str, choices=[\"train\", \"val\", \"test\", \"all\"], default=\"all\",\n",
    "                       help=\"Which split to process\")\n",
    "    parser.add_argument(\"--dna_batch\", type=int, default=DNA_BATCH,\n",
    "                       help=\"Batch size for DNA embedding\")\n",
    "    args = parser.parse_args([])\n",
    "    \n",
    "    print(f\"Device: {DEVICE}\")\n",
    "    print(f\"Loading HyenaDNA model: {HYENADNA_MODEL}\")\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(HYENADNA_MODEL, trust_remote_code=True)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        HYENADNA_MODEL,\n",
    "        torch_dtype=torch.bfloat16 if DEVICE == \"cuda\" else torch.bfloat16,\n",
    "        trust_remote_code=True\n",
    "    ).to(DEVICE)\n",
    "    \n",
    "    splits_to_process = []\n",
    "    if args.split == \"all\":\n",
    "        splits_to_process = [\n",
    "            (TRAIN_PARQUET, TRAIN_EMB),\n",
    "            (VAL_PARQUET, VAL_EMB),\n",
    "            (TEST_PARQUET, TEST_EMB),\n",
    "        ]\n",
    "    elif args.split == \"train\":\n",
    "        splits_to_process = [(TRAIN_PARQUET, TRAIN_EMB)]\n",
    "    elif args.split == \"val\":\n",
    "        splits_to_process = [(VAL_PARQUET, VAL_EMB)]\n",
    "    elif args.split == \"test\":\n",
    "        splits_to_process = [(TEST_PARQUET, TEST_EMB)]\n",
    "    \n",
    "    for parquet_path, emb_path in splits_to_process:\n",
    "        if not os.path.exists(parquet_path):\n",
    "            print(f\"Warning: {parquet_path} not found, skipping...\")\n",
    "            continue\n",
    "        process_split(parquet_path, emb_path, tokenizer, model, args.dna_batch)\n",
    "    \n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"\\nDone!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc407d20",
   "metadata": {},
   "source": [
    "### Training Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df4a9e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TRAINING CONFIGURATION:\n",
      "======================================================================\n",
      "  Experiment Name: experiment_1\n",
      "  Device: cuda\n",
      "  Learning Rate: 0.0001\n",
      "  Epochs: 60\n",
      "  Batch Size: 512\n",
      "  Patience: 5\n",
      "  Dropout: 0.3\n",
      "  Seed: 42\n",
      "  Proj Dim: 512\n",
      "  Fusion Hidden: [512, 256]\n",
      "======================================================================\n",
      "\n",
      "============================== MODEL SUMMARY ==============================\n",
      "=====================================================================================================================================================================\n",
      "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #                   Kernel Shape              Mult-Adds\n",
      "=====================================================================================================================================================================\n",
      "DNAClassifier                            [512, 256]                [512]                     --                        --                        --\n",
      "├─ModalityProjector: 1-1                 [512, 256]                [512, 512]                --                        --                        --\n",
      "│    └─Sequential: 2-1                   [512, 768]                [512, 512]                --                        --                        --\n",
      "│    │    └─Linear: 3-1                  [512, 768]                [512, 512]                393,728                   --                        201,588,736\n",
      "│    │    └─LayerNorm: 3-2               [512, 512]                [512, 512]                1,024                     --                        524,288\n",
      "│    │    └─GELU: 3-3                    [512, 512]                [512, 512]                --                        --                        --\n",
      "│    │    └─Dropout: 3-4                 [512, 512]                [512, 512]                --                        --                        --\n",
      "├─Sequential: 1-2                        [512, 512]                [512, 1]                  --                        --                        --\n",
      "│    └─Linear: 2-2                       [512, 512]                [512, 512]                262,656                   --                        134,479,872\n",
      "│    └─ReLU: 2-3                         [512, 512]                [512, 512]                --                        --                        --\n",
      "│    └─Dropout: 2-4                      [512, 512]                [512, 512]                --                        --                        --\n",
      "│    └─Linear: 2-5                       [512, 512]                [512, 256]                131,328                   --                        67,239,936\n",
      "│    └─ReLU: 2-6                         [512, 256]                [512, 256]                --                        --                        --\n",
      "│    └─Dropout: 2-7                      [512, 256]                [512, 256]                --                        --                        --\n",
      "│    └─Linear: 2-8                       [512, 256]                [512, 1]                  257                       --                        131,584\n",
      "=====================================================================================================================================================================\n",
      "Total params: 788,993\n",
      "Trainable params: 788,993\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.MEGABYTES): 403.96\n",
      "=====================================================================================================================================================================\n",
      "Input size (MB): 1.05\n",
      "Forward/backward pass size (MB): 7.34\n",
      "Params size (MB): 3.16\n",
      "Estimated Total Size (MB): 11.55\n",
      "=====================================================================================================================================================================\n",
      "--> Model summary saved to experiments_hyenadna\\experiment_1\\model_summary.txt\n",
      "===========================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Train Loss: 0.6202 | Val Loss: 0.5819 | Train Acc: 0.6539 | Val Acc: 0.6949\n",
      "--> Saved best model checkpoint to experiments_hyenadna\\experiment_1\\best_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2] Train Loss: 0.5844 | Val Loss: 0.5715 | Train Acc: 0.6918 | Val Acc: 0.7027\n",
      "--> Saved best model checkpoint to experiments_hyenadna\\experiment_1\\best_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] Train Loss: 0.5759 | Val Loss: 0.5665 | Train Acc: 0.6991 | Val Acc: 0.7069\n",
      "--> Saved best model checkpoint to experiments_hyenadna\\experiment_1\\best_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] Train Loss: 0.5698 | Val Loss: 0.5707 | Train Acc: 0.7050 | Val Acc: 0.7016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5] Train Loss: 0.5659 | Val Loss: 0.5645 | Train Acc: 0.7068 | Val Acc: 0.7046\n",
      "--> Saved best model checkpoint to experiments_hyenadna\\experiment_1\\best_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6] Train Loss: 0.5620 | Val Loss: 0.5614 | Train Acc: 0.7103 | Val Acc: 0.7075\n",
      "--> Saved best model checkpoint to experiments_hyenadna\\experiment_1\\best_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7] Train Loss: 0.5594 | Val Loss: 0.5556 | Train Acc: 0.7116 | Val Acc: 0.7146\n",
      "--> Saved best model checkpoint to experiments_hyenadna\\experiment_1\\best_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8] Train Loss: 0.5556 | Val Loss: 0.5556 | Train Acc: 0.7150 | Val Acc: 0.7144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9] Train Loss: 0.5538 | Val Loss: 0.5530 | Train Acc: 0.7158 | Val Acc: 0.7144\n",
      "--> Saved best model checkpoint to experiments_hyenadna\\experiment_1\\best_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10] Train Loss: 0.5494 | Val Loss: 0.5523 | Train Acc: 0.7184 | Val Acc: 0.7188\n",
      "--> Saved best model checkpoint to experiments_hyenadna\\experiment_1\\best_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11] Train Loss: 0.5471 | Val Loss: 0.5477 | Train Acc: 0.7207 | Val Acc: 0.7228\n",
      "--> Saved best model checkpoint to experiments_hyenadna\\experiment_1\\best_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12] Train Loss: 0.5435 | Val Loss: 0.5475 | Train Acc: 0.7240 | Val Acc: 0.7192\n",
      "--> Saved best model checkpoint to experiments_hyenadna\\experiment_1\\best_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13] Train Loss: 0.5419 | Val Loss: 0.5467 | Train Acc: 0.7237 | Val Acc: 0.7192\n",
      "--> Saved best model checkpoint to experiments_hyenadna\\experiment_1\\best_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14] Train Loss: 0.5395 | Val Loss: 0.5432 | Train Acc: 0.7271 | Val Acc: 0.7252\n",
      "--> Saved best model checkpoint to experiments_hyenadna\\experiment_1\\best_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15] Train Loss: 0.5371 | Val Loss: 0.5437 | Train Acc: 0.7278 | Val Acc: 0.7257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16] Train Loss: 0.5354 | Val Loss: 0.5427 | Train Acc: 0.7284 | Val Acc: 0.7236\n",
      "--> Saved best model checkpoint to experiments_hyenadna\\experiment_1\\best_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17] Train Loss: 0.5319 | Val Loss: 0.5420 | Train Acc: 0.7306 | Val Acc: 0.7235\n",
      "--> Saved best model checkpoint to experiments_hyenadna\\experiment_1\\best_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18] Train Loss: 0.5318 | Val Loss: 0.5404 | Train Acc: 0.7296 | Val Acc: 0.7260\n",
      "--> Saved best model checkpoint to experiments_hyenadna\\experiment_1\\best_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19] Train Loss: 0.5293 | Val Loss: 0.5412 | Train Acc: 0.7329 | Val Acc: 0.7237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20] Train Loss: 0.5273 | Val Loss: 0.5412 | Train Acc: 0.7333 | Val Acc: 0.7233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21] Train Loss: 0.5241 | Val Loss: 0.5419 | Train Acc: 0.7364 | Val Acc: 0.7247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22] Train Loss: 0.5239 | Val Loss: 0.5413 | Train Acc: 0.7367 | Val Acc: 0.7226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23] Train Loss: 0.5164 | Val Loss: 0.5380 | Train Acc: 0.7407 | Val Acc: 0.7291\n",
      "--> Saved best model checkpoint to experiments_hyenadna\\experiment_1\\best_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24] Train Loss: 0.5124 | Val Loss: 0.5366 | Train Acc: 0.7439 | Val Acc: 0.7275\n",
      "--> Saved best model checkpoint to experiments_hyenadna\\experiment_1\\best_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25] Train Loss: 0.5122 | Val Loss: 0.5390 | Train Acc: 0.7442 | Val Acc: 0.7271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26] Train Loss: 0.5104 | Val Loss: 0.5367 | Train Acc: 0.7456 | Val Acc: 0.7276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27] Train Loss: 0.5088 | Val Loss: 0.5398 | Train Acc: 0.7458 | Val Acc: 0.7260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28] Train Loss: 0.5082 | Val Loss: 0.5381 | Train Acc: 0.7456 | Val Acc: 0.7285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29] Train Loss: 0.5023 | Val Loss: 0.5368 | Train Acc: 0.7495 | Val Acc: 0.7290\n",
      "Early stopping triggered.\n",
      "\n",
      "--- Testing with Best Model ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] Loss: 0.5617 | AUC: 0.6949 | MCC: 0.3951 | Acc: 0.7058 | Spec: 0.7739\n",
      "[TEST] Balanced Acc: 0.6949 | F1_macro: 0.6965 | Precision: 0.6735 | Recall: 0.6160\n",
      "\n",
      "✓ Experiment saved to: experiments_hyenadna\\experiment_1\n",
      "  - Config: experiments_hyenadna\\experiment_1\\config.json\n",
      "  - Results: experiments_hyenadna\\experiment_1\\results.json\n",
      "  - Model: experiments_hyenadna\\experiment_1\\best_model.pt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "from torchinfo import summary\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "import torchmetrics\n",
    "from torchmetrics.classification import (\n",
    "    BinaryAUROC, BinaryAccuracy, BinaryMatthewsCorrCoef, MulticlassF1Score, MulticlassAccuracy,\n",
    "    BinaryConfusionMatrix, BinaryPrecision, BinaryRecall, BinarySpecificity\n",
    ")\n",
    "\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm_tensor, epoch, stage):\n",
    "    \"\"\"Plot confusion matrix\"\"\"\n",
    "    cm = cm_tensor.cpu().numpy()\n",
    "    fig, ax = plt.subplots(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', ax=ax,\n",
    "                xticklabels=['Benign', 'Pathogenic'], \n",
    "                yticklabels=['Benign', 'Pathogenic'])\n",
    "    ax.set_xlabel('Predicted labels')\n",
    "    ax.set_ylabel('True labels')\n",
    "    ax.set_title(f'Confusion Matrix - {stage} - Epoch {epoch}')\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def run_epoch(model, loader, criterion, device, metrics_collection, cm_metric, optimizer=None, writer=None, epoch=0, stage=\"train\"):\n",
    "    is_train = optimizer is not None\n",
    "    model.train() if is_train else model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    metrics_collection.reset()\n",
    "    cm_metric.reset()\n",
    "\n",
    "    pbar = tqdm(loader, desc=f\"{stage.capitalize()} Epoch {epoch}\", leave=False)\n",
    "\n",
    "    for dna_ref, dna_alt, label in pbar:\n",
    "        dna_ref = dna_ref.to(device)\n",
    "        dna_alt = dna_alt.to(device)\n",
    "        label = label.to(device).float()\n",
    "\n",
    "        with torch.set_grad_enabled(is_train):\n",
    "            logits = model(dna_ref, dna_alt)\n",
    "            loss = criterion(logits, label)\n",
    "            if is_train:\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * len(label)\n",
    "        preds = (torch.sigmoid(logits) > 0.5).int()\n",
    "        metrics_collection.update(preds, label.int())\n",
    "        cm_metric.update(preds, label.int())\n",
    "        pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "    avg_loss = total_loss / len(loader.dataset)\n",
    "    results = {k: v.item() for k, v in metrics_collection.compute().items()}\n",
    "    results['loss'] = avg_loss\n",
    "\n",
    "    if writer:\n",
    "        for name, value in results.items():\n",
    "            writer.add_scalar(f\"{stage}/{name}\", value, epoch)\n",
    "        \n",
    "        cm_tensor = cm_metric.compute()\n",
    "        fig = plot_confusion_matrix(cm_tensor, epoch, stage)\n",
    "        writer.add_figure(f\"ConfusionMatrix/{stage}\", fig, epoch)\n",
    "        plt.close(fig)\n",
    "            \n",
    "    return results\n",
    "\n",
    "\n",
    "def train(args):\n",
    "    seed_everything(args.seed)\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    # Tạo experiment directory\n",
    "    if args.exp_name is None:\n",
    "        args.exp_name = f\"exp_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    \n",
    "    if args.log_dir is None:\n",
    "        args.log_dir = os.path.join(\"runs_hyenadna\", args.exp_name)\n",
    "    \n",
    "    exp_dir = os.path.join(\"experiments_hyenadna\", args.exp_name)\n",
    "    os.makedirs(exp_dir, exist_ok=True)\n",
    "    \n",
    "    # In configuration\n",
    "    print(\"=\" * 70)\n",
    "    print(\"TRAINING CONFIGURATION:\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"  Experiment Name: {args.exp_name}\")\n",
    "    print(f\"  Device: {device}\")\n",
    "    print(f\"  Learning Rate: {args.lr}\")\n",
    "    print(f\"  Epochs: {args.epochs}\")\n",
    "    print(f\"  Batch Size: {args.batch_size}\")\n",
    "    print(f\"  Patience: {args.patience}\")\n",
    "    print(f\"  Dropout: {args.dropout}\")\n",
    "    print(f\"  Seed: {args.seed}\")\n",
    "    print(f\"  Proj Dim: {args.proj_dim}\")\n",
    "    print(f\"  Fusion Hidden: {args.fusion_hidden}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Lưu config\n",
    "    config_snapshot = {\n",
    "        \"exp_name\": args.exp_name,\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"lr\": args.lr,\n",
    "        \"epochs\": args.epochs,\n",
    "        \"batch_size\": args.batch_size,\n",
    "        \"patience\": args.patience,\n",
    "        \"dropout\": args.dropout,\n",
    "        \"seed\": args.seed,\n",
    "        \"proj_dim\": args.proj_dim,\n",
    "        \"fusion_hidden\": args.fusion_hidden,\n",
    "    }\n",
    "    with open(os.path.join(exp_dir, \"config.json\"), \"w\") as f:\n",
    "        json.dump(config_snapshot, f, indent=2)\n",
    "    \n",
    "    writer = SummaryWriter(log_dir=args.log_dir)\n",
    "\n",
    "    # Load datasets\n",
    "    train_ds = HyenaDNADataset(TRAIN_EMB)\n",
    "    val_ds = HyenaDNADataset(VAL_EMB)\n",
    "    test_ds = HyenaDNADataset(TEST_EMB)\n",
    "\n",
    "    loader_args = {'batch_size': args.batch_size, 'num_workers': 0, 'pin_memory': True}\n",
    "    train_loader = DataLoader(train_ds, shuffle=True, **loader_args)\n",
    "    val_loader = DataLoader(val_ds, shuffle=False, **loader_args)\n",
    "    test_loader = DataLoader(test_ds, shuffle=False, **loader_args)\n",
    "\n",
    "    # Tạo model\n",
    "    dna_dim = train_ds.dna_ref.shape[1]\n",
    "    model = DNAClassifier(\n",
    "        dna_dim=dna_dim,\n",
    "        proj_dim=args.proj_dim,\n",
    "        hidden_dims=args.fusion_hidden,\n",
    "        dropout=args.dropout\n",
    "    ).to(device)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*30 + \" MODEL SUMMARY \" + \"=\"*30)\n",
    "    input_data_shapes = [\n",
    "        (args.batch_size, dna_dim),  # dna_ref\n",
    "        (args.batch_size, dna_dim),  # dna_alt\n",
    "    ]\n",
    "\n",
    "    model_stats = summary(\n",
    "        model, \n",
    "        input_size=input_data_shapes,\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"kernel_size\", \"mult_adds\"],\n",
    "        device=device,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    print(model_stats)\n",
    "    \n",
    "    summary_path = os.path.join(exp_dir, \"model_summary.txt\")\n",
    "    with open(summary_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(str(model_stats))\n",
    "    print(f\"--> Model summary saved to {summary_path}\")\n",
    "    print(\"=\"*75 + \"\\n\")\n",
    "\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "\n",
    "    metrics = torchmetrics.MetricCollection({\n",
    "        'auc': BinaryAUROC(),\n",
    "        'acc': BinaryAccuracy(),\n",
    "        'mcc': BinaryMatthewsCorrCoef(),\n",
    "        'balanced_acc': MulticlassAccuracy(num_classes=2, average='macro'),\n",
    "        'f1_macro': MulticlassF1Score(num_classes=2, average='macro'),\n",
    "        'precision': BinaryPrecision(),\n",
    "        'recall': BinaryRecall(),\n",
    "        'specificity': BinarySpecificity()\n",
    "    }).to(device)\n",
    "\n",
    "    cm_metric = BinaryConfusionMatrix().to(device)\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    patience_counter = 0\n",
    "    save_path = os.path.join(exp_dir, \"best_model.pt\")\n",
    "\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        train_res = run_epoch(model, train_loader, criterion, device, metrics, cm_metric, optimizer, writer, epoch, \"train\")\n",
    "        val_res = run_epoch(model, val_loader, criterion, device, metrics, cm_metric, None, writer, epoch, \"val\")\n",
    "\n",
    "        print(f\"[{epoch}] Train Loss: {train_res['loss']:.4f} | Val Loss: {val_res['loss']:.4f} | Train Acc: {train_res['acc']:.4f} | Val Acc: {val_res['acc']:.4f}\")\n",
    "\n",
    "        scheduler.step(val_res['loss'])\n",
    "\n",
    "        if val_res['loss'] < best_val_loss:\n",
    "            best_val_loss = val_res['loss']\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"--> Saved best model checkpoint to {save_path}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= args.patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "    print(\"\\n--- Testing with Best Model ---\")\n",
    "    model.load_state_dict(torch.load(save_path))\n",
    "    test_res = run_epoch(model, test_loader, criterion, device, metrics, cm_metric, None, writer, args.epochs, \"test\")\n",
    "    print(f\"[TEST] Loss: {test_res['loss']:.4f} | AUC: {test_res['auc']:.4f} | MCC: {test_res['mcc']:.4f} | Acc: {test_res['acc']:.4f} | Spec: {test_res['specificity']:.4f}\")\n",
    "    print(f\"[TEST] Balanced Acc: {test_res['balanced_acc']:.4f} | F1_macro: {test_res['f1_macro']:.4f} | Precision: {test_res['precision']:.4f} | Recall: {test_res['recall']:.4f}\")\n",
    "    \n",
    "    # Lưu hparams vào TensorBoard\n",
    "    hparams = {\n",
    "        \"lr\": args.lr,\n",
    "        \"dropout\": args.dropout,\n",
    "        \"batch_size\": args.batch_size,\n",
    "        \"proj_dim\": args.proj_dim,\n",
    "        \"fusion_hidden\": str(args.fusion_hidden),\n",
    "        \"patience\": args.patience,\n",
    "    }\n",
    "    metrics_dict = {\n",
    "        \"test_auc\": test_res['auc'],\n",
    "        \"test_acc\": test_res['acc'],\n",
    "        \"test_mcc\": test_res['mcc'],\n",
    "        \"test_balanced_acc\": test_res['balanced_acc'],\n",
    "        \"test_f1_macro\": test_res['f1_macro'],\n",
    "        \"test_precision\": test_res['precision'],\n",
    "        \"test_recall\": test_res['recall'],\n",
    "        \"test_specificity\": test_res['specificity'],\n",
    "        \"test_loss\": test_res['loss'],\n",
    "        \"best_val_loss\": best_val_loss,\n",
    "    }\n",
    "    writer.add_hparams(hparams, metrics_dict)\n",
    "    \n",
    "    # Lưu kết quả\n",
    "    final_results = {\n",
    "        \"exp_name\": args.exp_name,\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"best_val_loss\": float(best_val_loss),\n",
    "        \"test_results\": {k: float(v) for k, v in test_res.items()},\n",
    "        \"epochs_trained\": epoch,\n",
    "        \"hparams\": hparams,\n",
    "    }\n",
    "    with open(os.path.join(exp_dir, \"results.json\"), \"w\") as f:\n",
    "        json.dump(final_results, f, indent=2)\n",
    "    \n",
    "    writer.close()\n",
    "    \n",
    "    print(f\"\\n✓ Experiment saved to: {exp_dir}\")\n",
    "    print(f\"  - Config: {os.path.join(exp_dir, 'config.json')}\")\n",
    "    print(f\"  - Results: {os.path.join(exp_dir, 'results.json')}\")\n",
    "    print(f\"  - Model: {save_path}\")\n",
    "    \n",
    "    return test_res\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--exp_name\", type=str, default=\"experiment_1\")\n",
    "    parser.add_argument(\"--lr\", type=float, default=LR)\n",
    "    parser.add_argument(\"--epochs\", type=int, default=EPOCHS)\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=BATCH_SIZE)\n",
    "    parser.add_argument(\"--patience\", type=int, default=PATIENCE)\n",
    "    parser.add_argument(\"--dropout\", type=float, default=DROPOUT)\n",
    "    parser.add_argument(\"--seed\", type=int, default=SEED)\n",
    "    parser.add_argument(\"--proj_dim\", type=int, default=PROJ_DIM)\n",
    "    parser.add_argument(\"--fusion_hidden\", type=int, nargs='+', default=FUSION_HIDDEN)\n",
    "    parser.add_argument(\"--weight_decay\", type=float, default=WEIGHT_DECAY)\n",
    "    parser.add_argument(\"--log_dir\", type=str, default=None)\n",
    "    args = parser.parse_args([])\n",
    "    \n",
    "    train(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stable",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
