{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NT + ESM-2 ZERO-SHOT Ver\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1) Split parquet into train/val/test (chr20/21 as test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved:\n",
            "  train: 114568 -> d:\\Biosequence\\Bio_sequence_Research_AITALAB-main\\train\\task3_variant_prediction\\data\\train.parquet\n",
            "  val  : 20219 -> d:\\Biosequence\\Bio_sequence_Research_AITALAB-main\\train\\task3_variant_prediction\\data\\val.parquet\n",
            "  test : 4562 -> d:\\Biosequence\\Bio_sequence_Research_AITALAB-main\\train\\task3_variant_prediction\\data\\test.parquet\n"
          ]
        }
      ],
      "source": [
        "from split_data import main as split_main\n",
        "from config import RAW_PARQUET\n",
        "split_main(RAW_PARQUET)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2) Precompute embeddings (NT + ESM-2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: TOKENIZERS_PARALLELISM=false\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Dung\\anaconda3\\envs\\stable\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n",
            "Loading NT...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of EsmModel were not initialized from the model checkpoint at InstaDeepAI/nucleotide-transformer-500m-human-ref and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading ESM-2...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Dung\\anaconda3\\envs\\stable\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Dung\\.cache\\huggingface\\hub\\models--facebook--esm2_t33_650M_UR50D. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n",
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t33_650M_UR50D and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding split d:\\Biosequence\\Bio_sequence_Research_AITALAB-main\\train\\task3_variant_prediction\\data\\train.parquet (114568 rows)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3581/3581 [09:24<00:00,  6.34it/s]\n",
            "100%|██████████| 3581/3581 [09:43<00:00,  6.13it/s]\n",
            "  0%|          | 0/28642 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "100%|██████████| 28642/28642 [16:44<00:00, 28.52it/s]\n",
            "100%|██████████| 28642/28642 [16:39<00:00, 28.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[saved] d:\\Biosequence\\Bio_sequence_Research_AITALAB-main\\train\\task3_variant_prediction\\embeddings\\train_embeddings.pt\n",
            "Embedding split d:\\Biosequence\\Bio_sequence_Research_AITALAB-main\\train\\task3_variant_prediction\\data\\val.parquet (20219 rows)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 632/632 [01:33<00:00,  6.73it/s]\n",
            "100%|██████████| 632/632 [01:36<00:00,  6.53it/s]\n",
            "100%|██████████| 5055/5055 [02:55<00:00, 28.74it/s]\n",
            "100%|██████████| 5055/5055 [02:56<00:00, 28.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[saved] d:\\Biosequence\\Bio_sequence_Research_AITALAB-main\\train\\task3_variant_prediction\\embeddings\\val_embeddings.pt\n",
            "Embedding split d:\\Biosequence\\Bio_sequence_Research_AITALAB-main\\train\\task3_variant_prediction\\data\\test.parquet (4562 rows)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 143/143 [00:21<00:00,  6.73it/s]\n",
            "100%|██████████| 143/143 [00:21<00:00,  6.52it/s]\n",
            "100%|██████████| 1141/1141 [00:39<00:00, 28.54it/s]\n",
            "100%|██████████| 1141/1141 [00:39<00:00, 28.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[saved] d:\\Biosequence\\Bio_sequence_Research_AITALAB-main\\train\\task3_variant_prediction\\embeddings\\test_embeddings.pt\n"
          ]
        }
      ],
      "source": [
        "%env TOKENIZERS_PARALLELISM=false\n",
        "from precompute_embeddings import main as emb_main\n",
        "emb_main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3) Train fusion classifier\n",
        "\n",
        "Để theo dõi tiến độ train trong tensorboard:\n",
        "\n",
        "- Mở terminal -> nhập: tensorboard --logdir train/task3_variant_prediction/runs -> truy cập vào link được in ra\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== CẤU TRÚC MODEL (PROJ_DIM=512) ===\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "============================================================================================================================================\n",
              "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #                   Mult-Adds\n",
              "============================================================================================================================================\n",
              "FusionClassifier                         [128, 768]                [128]                     --                        --\n",
              "├─ModalityProjector: 1-1                 [128, 768]                [128, 512]                --                        --\n",
              "│    └─Sequential: 2-1                   [128, 2304]               [128, 512]                --                        --\n",
              "│    │    └─Linear: 3-1                  [128, 2304]               [128, 512]                1,180,160                 151,060,480\n",
              "│    │    └─LayerNorm: 3-2               [128, 512]                [128, 512]                1,024                     131,072\n",
              "│    │    └─GELU: 3-3                    [128, 512]                [128, 512]                --                        --\n",
              "│    │    └─Dropout: 3-4                 [128, 512]                [128, 512]                --                        --\n",
              "├─ModalityProjector: 1-2                 [128, 1280]               [128, 512]                --                        --\n",
              "│    └─Sequential: 2-2                   [128, 3840]               [128, 512]                --                        --\n",
              "│    │    └─Linear: 3-5                  [128, 3840]               [128, 512]                1,966,592                 251,723,776\n",
              "│    │    └─LayerNorm: 3-6               [128, 512]                [128, 512]                1,024                     131,072\n",
              "│    │    └─GELU: 3-7                    [128, 512]                [128, 512]                --                        --\n",
              "│    │    └─Dropout: 3-8                 [128, 512]                [128, 512]                --                        --\n",
              "├─Sequential: 1-3                        [128, 1024]               [128, 1]                  --                        --\n",
              "│    └─Linear: 2-3                       [128, 1024]               [128, 512]                524,800                   67,174,400\n",
              "│    └─ReLU: 2-4                         [128, 512]                [128, 512]                --                        --\n",
              "│    └─Dropout: 2-5                      [128, 512]                [128, 512]                --                        --\n",
              "│    └─Linear: 2-6                       [128, 512]                [128, 256]                131,328                   16,809,984\n",
              "│    └─ReLU: 2-7                         [128, 256]                [128, 256]                --                        --\n",
              "│    └─Dropout: 2-8                      [128, 256]                [128, 256]                --                        --\n",
              "│    └─Linear: 2-9                       [128, 256]                [128, 1]                  257                       32,896\n",
              "============================================================================================================================================\n",
              "Total params: 3,805,185\n",
              "Trainable params: 3,805,185\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 487.06\n",
              "============================================================================================================================================\n",
              "Input size (MB): 2.10\n",
              "Forward/backward pass size (MB): 2.88\n",
              "Params size (MB): 15.22\n",
              "Estimated Total Size (MB): 20.20\n",
              "============================================================================================================================================"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from model import FusionClassifier\n",
        "from torchinfo import summary\n",
        "\n",
        "DNA_DIM = 768  \n",
        "PROT_DIM = 1280\n",
        "BATCHSIZE = 128 \n",
        "\n",
        "args_mock = {\n",
        "    'proj_dim': 512,\n",
        "    'fusion_hidden': [512, 256],\n",
        "    'dropout': 0.3\n",
        "}\n",
        "\n",
        "model = FusionClassifier(\n",
        "    dna_dim=DNA_DIM,\n",
        "    prot_dim=PROT_DIM,\n",
        "    proj_dim=args_mock['proj_dim'],\n",
        "    hidden_dims=args_mock['fusion_hidden'],\n",
        "    dropout=args_mock['dropout']\n",
        ")\n",
        "\n",
        "print(f\"=== CẤU TRÚC MODEL (PROJ_DIM={args_mock['proj_dim']}) ===\")\n",
        "summary(\n",
        "    model, \n",
        "    input_size=[(BATCHSIZE, DNA_DIM), (BATCHSIZE, DNA_DIM), (BATCHSIZE, PROT_DIM), (BATCHSIZE, PROT_DIM)],\n",
        "    col_names=[\"input_size\", \"output_size\", \"num_params\", \"mult_adds\"],\n",
        "    device=\"cpu\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "EXP_NAME = \"experiment_2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "TRAINING CONFIGURATION:\n",
            "======================================================================\n",
            "  Experiment Name: experiment_4\n",
            "  Device: cuda\n",
            "  Learning Rate: 0.0001\n",
            "  Epochs: 30\n",
            "  Batch Size: 128\n",
            "  Patience: 5\n",
            "  Dropout: 0.3\n",
            "  Seed: 42\n",
            "  Proj Dim: 256\n",
            "  Fusion Hidden: [256, 128]\n",
            "  Log Dir: runs\\experiment_4\n",
            "  Experiment Dir: d:\\Bio_sequence_Research_AITALAB\\train\\task3_variant_prediction\\embeddings\\experiments\\experiment_4\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1] Train Loss: 0.1887 | Val Loss: 0.1521 | Train Acc: 0.9287 | Val Acc: 0.9406\n",
            "--> Saved best model checkpoint to d:\\Bio_sequence_Research_AITALAB\\train\\task3_variant_prediction\\embeddings\\best_fusion_model.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2] Train Loss: 0.1423 | Val Loss: 0.1488 | Train Acc: 0.9458 | Val Acc: 0.9430\n",
            "--> Saved best model checkpoint to d:\\Bio_sequence_Research_AITALAB\\train\\task3_variant_prediction\\embeddings\\best_fusion_model.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[3] Train Loss: 0.1255 | Val Loss: 0.1586 | Train Acc: 0.9516 | Val Acc: 0.9416\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[4] Train Loss: 0.1106 | Val Loss: 0.1538 | Train Acc: 0.9580 | Val Acc: 0.9427\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5] Train Loss: 0.0937 | Val Loss: 0.1626 | Train Acc: 0.9650 | Val Acc: 0.9417\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[6] Train Loss: 0.0788 | Val Loss: 0.1888 | Train Acc: 0.9704 | Val Acc: 0.9419\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[7] Train Loss: 0.0530 | Val Loss: 0.2085 | Train Acc: 0.9803 | Val Acc: 0.9419\n",
            "Early stopping triggered.\n",
            "\n",
            "--- Testing with Best Model ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TEST] Loss: 0.1586 | AUC: 0.9323 | MCC: 0.8694 | Acc: 0.9360\n",
            "[TEST] Balanced Acc: 0.9323 | F1_macro: 0.9344 | Precision: 0.9438 | Recall: 0.9054\n",
            "\n",
            "✓ Experiment saved to: d:\\Bio_sequence_Research_AITALAB\\train\\task3_variant_prediction\\embeddings\\experiments\\experiment_4\n",
            "  - Config: d:\\Bio_sequence_Research_AITALAB\\train\\task3_variant_prediction\\embeddings\\experiments\\experiment_4\\config.json\n",
            "  - Args: d:\\Bio_sequence_Research_AITALAB\\train\\task3_variant_prediction\\embeddings\\experiments\\experiment_4\\args.json\n",
            "  - Results: d:\\Bio_sequence_Research_AITALAB\\train\\task3_variant_prediction\\embeddings\\experiments\\experiment_4\\results.json\n",
            "  - Model: d:\\Bio_sequence_Research_AITALAB\\train\\task3_variant_prediction\\embeddings\\experiments\\experiment_4\\best_model.pt\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'acc': 0.935992956161499,\n",
              " 'auc': 0.9322798252105713,\n",
              " 'balanced_acc': 0.9322798252105713,\n",
              " 'f1_macro': 0.9344041347503662,\n",
              " 'mcc': 0.869411051273346,\n",
              " 'precision': 0.9437963962554932,\n",
              " 'recall': 0.9053916335105896,\n",
              " 'loss': 0.15859096062054032}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from train import train\n",
        "from config import LR, EPOCHS, BATCH_SIZE, PATIENCE, DROPOUT, SEED, PROJ_DIM, FUSION_HIDDEN, WEIGHT_DECAY\n",
        "import argparse\n",
        "\n",
        "parser = argparse.ArgumentParser(description=\"Train fusion classifier with enhanced features.\")\n",
        "parser.add_argument(\"--proj_dim\", type=int, default=256)\n",
        "parser.add_argument(\"--fusion_hidden\", type=list, default=[256, 128])\n",
        "parser.add_argument(\"--lr\", type=float, default=1e-4, help=\"Learning rate\")\n",
        "parser.add_argument(\"--epochs\", type=int, default=EPOCHS)\n",
        "parser.add_argument(\"--batch_size\", type=int, default=BATCH_SIZE)\n",
        "parser.add_argument(\"--patience\", type=int, default=PATIENCE)\n",
        "parser.add_argument(\"--dropout\", type=float, default=0.3)\n",
        "parser.add_argument(\"--weight_decay\", type=float, default=WEIGHT_DECAY, help=\"L2 regularization lambda\")\n",
        "parser.add_argument(\"--seed\", type=int, default=SEED)\n",
        "parser.add_argument(\"--exp_name\", type=str, default=EXP_NAME, help=\"Experiment name (auto-generated if not provided)\")\n",
        "parser.add_argument(\"--log_dir\", type=str, default=None, help=\"TensorBoard log directory (auto: runs/exp_name)\")\n",
        "\n",
        "args = parser.parse_args([])\n",
        "\n",
        "result = train(args)\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4) Xem lại kết quả experiments\n",
        "\n",
        "Các experiments được lưu tự động trong `embeddings/experiments/<exp_name>/`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Danh sách experiments:\n",
            "    exp_name                  timestamp  test_auc  test_acc  test_mcc  test_balanced_acc  test_f1_macro  test_precision  test_recall  best_val_loss  epochs\n",
            "experiment_4 2025-12-26T22:15:42.118193  0.932280  0.935993  0.869411           0.932280       0.934404        0.943796     0.905392       0.148757       7\n",
            "experiment_3 2025-12-26T22:13:35.635218  0.934255  0.935993  0.869390           0.934255       0.934683        0.929231     0.921668       0.149948       7\n",
            "experiment_2 2025-12-26T22:01:18.202990  0.936344  0.937527  0.872634           0.936344       0.936317        0.927300     0.927772       0.149093       7\n"
          ]
        }
      ],
      "source": [
        "# Xem danh sách tất cả experiments\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "exp_base_dir = \"embeddings/experiments\"\n",
        "if os.path.exists(exp_base_dir):\n",
        "    experiments = []\n",
        "    for exp_name in os.listdir(exp_base_dir):\n",
        "        exp_dir = os.path.join(exp_base_dir, exp_name)\n",
        "        results_file = os.path.join(exp_dir, \"results.json\")\n",
        "        if os.path.exists(results_file):\n",
        "            with open(results_file, \"r\") as f:\n",
        "                data = json.load(f)\n",
        "                experiments.append({\n",
        "                    \"exp_name\": exp_name,\n",
        "                    \"timestamp\": data.get(\"timestamp\", \"\"),\n",
        "                    \"test_auc\": data[\"test_results\"].get(\"auc\", 0),\n",
        "                    \"test_acc\": data[\"test_results\"].get(\"acc\", 0),\n",
        "                    \"test_mcc\": data[\"test_results\"].get(\"mcc\", 0),\n",
        "                    \"test_balanced_acc\": data[\"test_results\"].get(\"balanced_acc\", 0),\n",
        "                    \"test_f1_macro\": data[\"test_results\"].get(\"f1_macro\", 0),\n",
        "                    \"test_precision\": data[\"test_results\"].get(\"precision\", 0),\n",
        "                    \"test_recall\": data[\"test_results\"].get(\"recall\", 0),\n",
        "                    \"best_val_loss\": data.get(\"best_val_loss\", 0),\n",
        "                    \"epochs\": data.get(\"epochs_trained\", 0),\n",
        "                })\n",
        "    \n",
        "    if experiments:\n",
        "        df = pd.DataFrame(experiments)\n",
        "        df = df.sort_values(\"timestamp\", ascending=False)\n",
        "        print(\"Danh sách experiments:\")\n",
        "        print(df.to_string(index=False))\n",
        "    else:\n",
        "        print(\"Chưa có experiments nào.\")\n",
        "else:\n",
        "    print(f\"Thư mục {exp_base_dir} chưa tồn tại.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Experiment: experiment_2 ===\n",
            "\n",
            "Config:\n",
            "  exp_name: experiment_2\n",
            "  timestamp: 2025-12-26T21:59:59.432663\n",
            "  lr: 0.0001\n",
            "  epochs: 30\n",
            "  batch_size: 128\n",
            "  patience: 5\n",
            "  dropout: 0.3\n",
            "  seed: 42\n",
            "  proj_dim: 512\n",
            "  fusion_hidden: [512, 256]\n",
            "  log_dir: runs\\experiment_2\n",
            "\n",
            "Results:\n",
            "  Best Val Loss: 0.1491\n",
            "  Test AUC: 0.9363\n",
            "  Test Acc: 0.9375\n",
            "  Test MCC: 0.8726\n",
            "  Test Balanced Acc: 0.9363\n",
            "  Test F1_macro: 0.9363\n",
            "  Test Precision: 0.9273\n",
            "  Test Recall: 0.9278\n",
            "  Epochs Trained: 7\n"
          ]
        }
      ],
      "source": [
        "# Xem chi tiết một experiment cụ thể\n",
        "exp_name = EXP_NAME  # Thay bằng exp_name muốn xem\n",
        "\n",
        "exp_dir = f\"embeddings/experiments/{exp_name}\"\n",
        "if os.path.exists(exp_dir):\n",
        "    print(f\"=== Experiment: {exp_name} ===\\n\")\n",
        "    \n",
        "    # Xem config\n",
        "    config_file = os.path.join(exp_dir, \"config.json\")\n",
        "    if os.path.exists(config_file):\n",
        "        with open(config_file, \"r\") as f:\n",
        "            config = json.load(f)\n",
        "        print(\"Config:\")\n",
        "        for k, v in config.items():\n",
        "            print(f\"  {k}: {v}\")\n",
        "        print()\n",
        "    \n",
        "    # Xem cấu trúc Model\n",
        "    summary_file = os.path.join(exp_dir, \"model_summary.txt\")\n",
        "    if os.path.exists(summary_file):\n",
        "        print(\"Model Architecture Summary:\")\n",
        "        with open(summary_file, \"r\", encoding=\"utf-8\") as f:\n",
        "            print(f.read())\n",
        "        print()\n",
        "\n",
        "    # Xem results\n",
        "    results_file = os.path.join(exp_dir, \"results.json\")\n",
        "    if os.path.exists(results_file):\n",
        "        with open(results_file, \"r\") as f:\n",
        "            results = json.load(f)\n",
        "        print(\"Results:\")\n",
        "        print(f\"  Best Val Loss: {results.get('best_val_loss', 0):.4f}\")\n",
        "        print(f\"  Test AUC: {results['test_results'].get('auc', 0):.4f}\")\n",
        "        print(f\"  Test Acc: {results['test_results'].get('acc', 0):.4f}\")\n",
        "        print(f\"  Test MCC: {results['test_results'].get('mcc', 0):.4f}\")\n",
        "        print(f\"  Test Balanced Acc: {results['test_results'].get('balanced_acc', 0):.4f}\")\n",
        "        print(f\"  Test F1_macro: {results['test_results'].get('f1_macro', 0):.4f}\")\n",
        "        print(f\"  Test Precision: {results['test_results'].get('precision', 0):.4f}\")\n",
        "        print(f\"  Test Recall: {results['test_results'].get('recall', 0):.4f}\")\n",
        "        print(f\"  Epochs Trained: {results.get('epochs_trained', 0)}\")\n",
        "else:\n",
        "    print(f\"Experiment '{exp_name}' không tồn tại.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NT + ESM-2 FINE-TUNED Ver\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
