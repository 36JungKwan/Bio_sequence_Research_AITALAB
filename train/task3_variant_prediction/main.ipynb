{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NT + ESM-2 ZERO-SHOT Ver\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1) Split parquet into train/val/test (chr20/21 as test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved:\n",
            "  train: 114568 -> d:\\Biosequence\\Bio_sequence_Research_AITALAB-main\\train\\task3_variant_prediction\\data\\train.parquet\n",
            "  val  : 20219 -> d:\\Biosequence\\Bio_sequence_Research_AITALAB-main\\train\\task3_variant_prediction\\data\\val.parquet\n",
            "  test : 4562 -> d:\\Biosequence\\Bio_sequence_Research_AITALAB-main\\train\\task3_variant_prediction\\data\\test.parquet\n"
          ]
        }
      ],
      "source": [
        "from split_data import main as split_main\n",
        "from config import RAW_PARQUET\n",
        "split_main(RAW_PARQUET)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2) Precompute embeddings (NT + ESM-2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: TOKENIZERS_PARALLELISM=false\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Dung\\anaconda3\\envs\\stable\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n",
            "Loading NT...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of EsmModel were not initialized from the model checkpoint at InstaDeepAI/nucleotide-transformer-500m-human-ref and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading ESM-2...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Dung\\anaconda3\\envs\\stable\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Dung\\.cache\\huggingface\\hub\\models--facebook--esm2_t33_650M_UR50D. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n",
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t33_650M_UR50D and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding split d:\\Biosequence\\Bio_sequence_Research_AITALAB-main\\train\\task3_variant_prediction\\data\\train.parquet (114568 rows)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3581/3581 [09:24<00:00,  6.34it/s]\n",
            "100%|██████████| 3581/3581 [09:43<00:00,  6.13it/s]\n",
            "  0%|          | 0/28642 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "100%|██████████| 28642/28642 [16:44<00:00, 28.52it/s]\n",
            "100%|██████████| 28642/28642 [16:39<00:00, 28.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[saved] d:\\Biosequence\\Bio_sequence_Research_AITALAB-main\\train\\task3_variant_prediction\\embeddings\\train_embeddings.pt\n",
            "Embedding split d:\\Biosequence\\Bio_sequence_Research_AITALAB-main\\train\\task3_variant_prediction\\data\\val.parquet (20219 rows)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 632/632 [01:33<00:00,  6.73it/s]\n",
            "100%|██████████| 632/632 [01:36<00:00,  6.53it/s]\n",
            "100%|██████████| 5055/5055 [02:55<00:00, 28.74it/s]\n",
            "100%|██████████| 5055/5055 [02:56<00:00, 28.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[saved] d:\\Biosequence\\Bio_sequence_Research_AITALAB-main\\train\\task3_variant_prediction\\embeddings\\val_embeddings.pt\n",
            "Embedding split d:\\Biosequence\\Bio_sequence_Research_AITALAB-main\\train\\task3_variant_prediction\\data\\test.parquet (4562 rows)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 143/143 [00:21<00:00,  6.73it/s]\n",
            "100%|██████████| 143/143 [00:21<00:00,  6.52it/s]\n",
            "100%|██████████| 1141/1141 [00:39<00:00, 28.54it/s]\n",
            "100%|██████████| 1141/1141 [00:39<00:00, 28.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[saved] d:\\Biosequence\\Bio_sequence_Research_AITALAB-main\\train\\task3_variant_prediction\\embeddings\\test_embeddings.pt\n"
          ]
        }
      ],
      "source": [
        "%env TOKENIZERS_PARALLELISM=false\n",
        "from precompute_embeddings import main as emb_main\n",
        "emb_main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3) Train fusion classifier\n",
        "\n",
        "Để theo dõi tiến độ train trong tensorboard:\n",
        "\n",
        "- Mở terminal -> nhập: tensorboard --logdir train/task3_variant_prediction/runs -> truy cập vào link được in ra\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Dung\\anaconda3\\envs\\stable\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "TRAINING CONFIGURATION:\n",
            "======================================================================\n",
            "  Experiment Name: experiment_2\n",
            "  Device: cuda\n",
            "  Learning Rate: 0.0001\n",
            "  Epochs: 30\n",
            "  Batch Size: 128\n",
            "  Patience: 5\n",
            "  Dropout: 0.3\n",
            "  Seed: 42\n",
            "  Proj Dim: 512\n",
            "  Fusion Hidden: [512, 256]\n",
            "  Log Dir: runs\\experiment_2\n",
            "  Experiment Dir: d:\\Bio_sequence_Research_AITALAB\\train\\task3_variant_prediction\\embeddings\\experiments\\experiment_2\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1] Train Loss: 0.1802 | Val Loss: 0.1539 | Train Acc: 0.9306 | Val Acc: 0.9396\n",
            "--> Saved best model checkpoint to d:\\Bio_sequence_Research_AITALAB\\train\\task3_variant_prediction\\embeddings\\best_fusion_model.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2] Train Loss: 0.1386 | Val Loss: 0.1491 | Train Acc: 0.9467 | Val Acc: 0.9425\n",
            "--> Saved best model checkpoint to d:\\Bio_sequence_Research_AITALAB\\train\\task3_variant_prediction\\embeddings\\best_fusion_model.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[3] Train Loss: 0.1198 | Val Loss: 0.1560 | Train Acc: 0.9538 | Val Acc: 0.9410\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[4] Train Loss: 0.1019 | Val Loss: 0.1635 | Train Acc: 0.9616 | Val Acc: 0.9447\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5] Train Loss: 0.0848 | Val Loss: 0.1723 | Train Acc: 0.9681 | Val Acc: 0.9406\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[6] Train Loss: 0.0686 | Val Loss: 0.1897 | Train Acc: 0.9751 | Val Acc: 0.9417\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                              \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[7] Train Loss: 0.0432 | Val Loss: 0.2519 | Train Acc: 0.9845 | Val Acc: 0.9412\n",
            "Early stopping triggered.\n",
            "\n",
            "--- Testing with Best Model ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TEST] Loss: 0.1584 | AUC: 0.9363 | MCC: 0.8726 | Acc: 0.9375\n",
            "[TEST] Balanced Acc: 0.9363 | F1_macro: 0.9363 | Precision: 0.9273 | Recall: 0.9278\n",
            "\n",
            "✓ Experiment saved to: d:\\Bio_sequence_Research_AITALAB\\train\\task3_variant_prediction\\embeddings\\experiments\\experiment_2\n",
            "  - Config: d:\\Bio_sequence_Research_AITALAB\\train\\task3_variant_prediction\\embeddings\\experiments\\experiment_2\\config.json\n",
            "  - Args: d:\\Bio_sequence_Research_AITALAB\\train\\task3_variant_prediction\\embeddings\\experiments\\experiment_2\\args.json\n",
            "  - Results: d:\\Bio_sequence_Research_AITALAB\\train\\task3_variant_prediction\\embeddings\\experiments\\experiment_2\\results.json\n",
            "  - Model: d:\\Bio_sequence_Research_AITALAB\\train\\task3_variant_prediction\\embeddings\\experiments\\experiment_2\\best_model.pt\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'acc': 0.9375274181365967,\n",
              " 'auc': 0.9363436102867126,\n",
              " 'balanced_acc': 0.9363436698913574,\n",
              " 'f1_macro': 0.936316728591919,\n",
              " 'mcc': 0.8726336359977722,\n",
              " 'precision': 0.9273004531860352,\n",
              " 'recall': 0.9277721047401428,\n",
              " 'loss': 0.15842028631731142}"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from train import train\n",
        "from config import LR, EPOCHS, BATCH_SIZE, PATIENCE, DROPOUT, SEED, PROJ_DIM, FUSION_HIDDEN, WEIGHT_DECAY\n",
        "import argparse\n",
        "\n",
        "parser = argparse.ArgumentParser(description=\"Train fusion classifier with enhanced features.\")\n",
        "parser.add_argument(\"--proj_dim\", type=int, default=PROJ_DIM)\n",
        "parser.add_argument(\"--fusion_hidden\", type=list, default=FUSION_HIDDEN)\n",
        "parser.add_argument(\"--lr\", type=float, default=1e-4, help=\"Learning rate\")\n",
        "parser.add_argument(\"--epochs\", type=int, default=EPOCHS)\n",
        "parser.add_argument(\"--batch_size\", type=int, default=BATCH_SIZE)\n",
        "parser.add_argument(\"--patience\", type=int, default=PATIENCE)\n",
        "parser.add_argument(\"--dropout\", type=float, default=0.3)\n",
        "parser.add_argument(\"--weight_decay\", type=float, default=WEIGHT_DECAY, help=\"L2 regularization lambda\")\n",
        "parser.add_argument(\"--seed\", type=int, default=SEED)\n",
        "parser.add_argument(\"--exp_name\", type=str, default=\"experiment_2\", help=\"Experiment name (auto-generated if not provided)\")\n",
        "parser.add_argument(\"--log_dir\", type=str, default=None, help=\"TensorBoard log directory (auto: runs/exp_name)\")\n",
        "\n",
        "args = parser.parse_args([])\n",
        "\n",
        "result = train(args)\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4) Xem lại kết quả experiments\n",
        "\n",
        "Các experiments được lưu tự động trong `embeddings/experiments/<exp_name>/`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Danh sách experiments:\n",
            "    exp_name                  timestamp  test_auc  test_acc  test_mcc  test_balanced_acc  test_f1_macro  test_precision  test_recall  best_val_loss  epochs\n",
            "experiment_2 2025-12-26T22:01:18.202990  0.936344  0.937527  0.872634           0.936344       0.936317          0.9273     0.927772       0.149093       7\n"
          ]
        }
      ],
      "source": [
        "# Xem danh sách tất cả experiments\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "exp_base_dir = \"embeddings/experiments\"\n",
        "if os.path.exists(exp_base_dir):\n",
        "    experiments = []\n",
        "    for exp_name in os.listdir(exp_base_dir):\n",
        "        exp_dir = os.path.join(exp_base_dir, exp_name)\n",
        "        results_file = os.path.join(exp_dir, \"results.json\")\n",
        "        if os.path.exists(results_file):\n",
        "            with open(results_file, \"r\") as f:\n",
        "                data = json.load(f)\n",
        "                experiments.append({\n",
        "                    \"exp_name\": exp_name,\n",
        "                    \"timestamp\": data.get(\"timestamp\", \"\"),\n",
        "                    \"test_auc\": data[\"test_results\"].get(\"auc\", 0),\n",
        "                    \"test_acc\": data[\"test_results\"].get(\"acc\", 0),\n",
        "                    \"test_mcc\": data[\"test_results\"].get(\"mcc\", 0),\n",
        "                    \"test_balanced_acc\": data[\"test_results\"].get(\"balanced_acc\", 0),\n",
        "                    \"test_f1_macro\": data[\"test_results\"].get(\"f1_macro\", 0),\n",
        "                    \"test_precision\": data[\"test_results\"].get(\"precision\", 0),\n",
        "                    \"test_recall\": data[\"test_results\"].get(\"recall\", 0),\n",
        "                    \"best_val_loss\": data.get(\"best_val_loss\", 0),\n",
        "                    \"epochs\": data.get(\"epochs_trained\", 0),\n",
        "                })\n",
        "    \n",
        "    if experiments:\n",
        "        df = pd.DataFrame(experiments)\n",
        "        df = df.sort_values(\"timestamp\", ascending=False)\n",
        "        print(\"Danh sách experiments:\")\n",
        "        print(df.to_string(index=False))\n",
        "    else:\n",
        "        print(\"Chưa có experiments nào.\")\n",
        "else:\n",
        "    print(f\"Thư mục {exp_base_dir} chưa tồn tại.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Experiment: experiment_2 ===\n",
            "\n",
            "Config:\n",
            "  exp_name: experiment_2\n",
            "  timestamp: 2025-12-26T21:59:59.432663\n",
            "  lr: 0.0001\n",
            "  epochs: 30\n",
            "  batch_size: 128\n",
            "  patience: 5\n",
            "  dropout: 0.3\n",
            "  seed: 42\n",
            "  proj_dim: 512\n",
            "  fusion_hidden: [512, 256]\n",
            "  log_dir: runs\\experiment_2\n",
            "\n",
            "Results:\n",
            "  Best Val Loss: 0.1491\n",
            "  Test AUC: 0.9363\n",
            "  Test Acc: 0.9375\n",
            "  Test MCC: 0.8726\n",
            "  Test Balanced Acc: 0.9363\n",
            "  Test F1_macro: 0.9363\n",
            "  Test Precision: 0.9273\n",
            "  Test Recall: 0.9278\n",
            "  Epochs Trained: 7\n"
          ]
        }
      ],
      "source": [
        "# Xem chi tiết một experiment cụ thể\n",
        "exp_name = \"experiment_2\"  # Thay bằng exp_name muốn xem\n",
        "\n",
        "exp_dir = f\"embeddings/experiments/{exp_name}\"\n",
        "if os.path.exists(exp_dir):\n",
        "    print(f\"=== Experiment: {exp_name} ===\\n\")\n",
        "    \n",
        "    # Xem config\n",
        "    config_file = os.path.join(exp_dir, \"config.json\")\n",
        "    if os.path.exists(config_file):\n",
        "        with open(config_file, \"r\") as f:\n",
        "            config = json.load(f)\n",
        "        print(\"Config:\")\n",
        "        for k, v in config.items():\n",
        "            print(f\"  {k}: {v}\")\n",
        "        print()\n",
        "    \n",
        "    # Xem results\n",
        "    results_file = os.path.join(exp_dir, \"results.json\")\n",
        "    if os.path.exists(results_file):\n",
        "        with open(results_file, \"r\") as f:\n",
        "            results = json.load(f)\n",
        "        print(\"Results:\")\n",
        "        print(f\"  Best Val Loss: {results.get('best_val_loss', 0):.4f}\")\n",
        "        print(f\"  Test AUC: {results['test_results'].get('auc', 0):.4f}\")\n",
        "        print(f\"  Test Acc: {results['test_results'].get('acc', 0):.4f}\")\n",
        "        print(f\"  Test MCC: {results['test_results'].get('mcc', 0):.4f}\")\n",
        "        print(f\"  Test Balanced Acc: {results['test_results'].get('balanced_acc', 0):.4f}\")\n",
        "        print(f\"  Test F1_macro: {results['test_results'].get('f1_macro', 0):.4f}\")\n",
        "        print(f\"  Test Precision: {results['test_results'].get('precision', 0):.4f}\")\n",
        "        print(f\"  Test Recall: {results['test_results'].get('recall', 0):.4f}\")\n",
        "        print(f\"  Epochs Trained: {results.get('epochs_trained', 0)}\")\n",
        "else:\n",
        "    print(f\"Experiment '{exp_name}' không tồn tại.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NT + ESM-2 FINE-TUNED Ver\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "stable",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
