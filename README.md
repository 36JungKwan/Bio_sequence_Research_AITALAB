# ğŸ§¬ Bioinformatics Sequence Research - AiTA Lab

Multi-task deep learning framework for biosequence analysis, pathogenicity prediction, and protein/nucleotide feature extraction.

**Research Focus:** Utilize pre-trained language models (Nucleotide Transformer, ESM-2) to build models for predicting biological properties of genetic variants.

---

## ğŸ“‹ Project Overview

This project focuses on 3 main tasks:

| Task | Description | Data | Model |
|------|-------------|------|-------|
| **Task 1: Splicing Prediction** | Predict splicing site type (donor/acceptor) | Sequence ~200bp | LSTM/Transformer |
| **Task 2: Protein Prediction** | Predict protein properties from sequence | Protein sequence | ESM-2 embeddings |
| **Task 3: Variant Pathogenicity** | Classify variants (pathogenic/benign) | ClinVar + DNA/Protein seq | Multi-modal Fusion Model |

---

## ğŸ“ Directory Structure

```
Bio_sequence_Research_AITALAB/
â”‚
â”œâ”€â”€ data_processing/                          # ğŸ“Š Data preprocessing & preparation
â”‚   â”œâ”€â”€ dataset1_ClinVar_preprocess_variant_summary.ipynb
â”‚   â”œâ”€â”€ dataset2_map_csq_hgvsc_aDun.ipynb     # Map CSQ & HGVS-C
â”‚   â”œâ”€â”€ dataset2_map_ref_alt_sequence_dna.ipynb
â”‚   â”œâ”€â”€ dataset2_map_ref_alt_sequence_protein.ipynb
â”‚   â”œâ”€â”€ dataset3_sequence_gencode.ipynb       # Extract sequences from GENCODE
â”‚
â”œâ”€â”€ tools/                                     # ğŸ› ï¸ Supporting tools
â”‚   â”œâ”€â”€ gnomAD_map_vep.ipynb                  # Map VEP annotations
â”‚   â”œâ”€â”€ test_parse_hgvsc_offset.ipynb         # Parse HGVS-C format
â”‚
â”œâ”€â”€ train/                                     # ğŸ¯ Training pipelines
â”‚   â”‚
â”‚   â”œâ”€â”€ task1_splicing_prediction/            # Splicing site prediction
â”‚   â”‚   â”œâ”€â”€ data_preparation/
â”‚   â”‚   â”‚   â”œâ”€â”€ data_prepare.ipynb            # Data preparation
â”‚   â”‚   â”‚   â”œâ”€â”€ train_test_split.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ratio_split.py
â”‚   â”‚   â”‚   â””â”€â”€ extract_embed.py
â”‚   â”‚   â””â”€â”€ training/
â”‚   â”‚       â”œâ”€â”€ main.ipynb                    # Training notebook
â”‚   â”‚       â”œâ”€â”€ model.py                      # LSTM model
â”‚   â”‚       â”œâ”€â”€ dataset.py                    # PyTorch Dataset
â”‚   â”‚       â”œâ”€â”€ train_set.py
â”‚   â”‚       â”œâ”€â”€ train_full.py
â”‚   â”‚       â”œâ”€â”€ metrics.py
â”‚   â”‚       â”œâ”€â”€ cm_visualize.py
â”‚   â”‚       â””â”€â”€ fileio.py
â”‚   â”‚
â”‚   â”œâ”€â”€ task2_protein_prediction/             # Protein property prediction
â”‚   â”‚
â”‚   â””â”€â”€ task3_variant_prediction/             # â­ Variant pathogenicity prediction (MAIN)
â”‚       â”œâ”€â”€ config.py                         # Configuration
â”‚       â”œâ”€â”€ split_data.py                     # Split by chromosome
â”‚       â”œâ”€â”€ precompute_embeddings.py          # Extract NT + ESM-2 embeddings
â”‚       â”œâ”€â”€ dataset.py                        # PyTorch Dataset
â”‚       â”œâ”€â”€ model.py                          # Multi-modal Fusion model
â”‚       â”œâ”€â”€ train.py                          # Training with tracking
â”‚       â”œâ”€â”€ main.ipynb                        # Full pipeline
â”‚       â”œâ”€â”€ README.md                         # Task-specific guide
â”‚       â”œâ”€â”€ data/                             # Train/Val/Test splits
â”‚       â”œâ”€â”€ embeddings/                       # Precomputed embeddings
â”‚       â”œâ”€â”€ experiments/                      # Experiment configs & results
â”‚       â””â”€â”€ runs/                             # TensorBoard logs
â”‚
â””â”€â”€ README.md                                  # This file
```

---

## ğŸš€ Quick Start

### Prerequisites

```bash
# Python 3.9+
# CUDA 11.8+ (recommended for GPU support)

pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
pip install transformers datasets numpy pandas scikit-learn matplotlib seaborn tensorboard jupyter
pip install pyarrow biopython pysam  # Bioinformatics tools
```

### Environment Configuration

Create a `.env` file or set environment variables:

```bash
# Task 3 data path
TASK3_PARQUET=<path_to>/variant_protein_sequence_101aa.parquet

# Hugging Face token (if needed)
HUGGING_FACE_HUB_TOKEN=<your_token>
```

---

## ğŸ“Š Project Pipeline

### 1ï¸âƒ£ Data Processing (`data_processing/`)

**Goal:** Prepare data from different sources (ClinVar, GENCODE, VEP) into standard format

| Notebook | Purpose |
|----------|---------|
| `dataset1_ClinVar_preprocess_variant_summary.ipynb` | Filter & preprocess ClinVar variants |
| `dataset2_map_csq_hgvsc_aDun.ipynb` | Map CSQ â†’ HGVS-C nomenclature |
| `dataset2_map_ref_alt_sequence_dna.ipynb` | Extract DNA sequences (ref & alt) |
| `dataset2_map_ref_alt_sequence_protein.ipynb` | Extract protein sequences |
| `dataset3_sequence_gencode.ipynb` | Get sequences from GENCODE reference |

**Output:** Parquet files with variant + sequences (DNA 601bp, Protein 101aa)

---

### 2ï¸âƒ£ Task 1: Splicing Prediction (`train/task1_splicing_prediction/`)

**Goal:** Predict splicing site type from DNA sequence

**Pipeline:**
```
Raw Data (.csv) â†’ Train/Test Split â†’ Val Split â†’ Model Training â†’ Metrics
```

**Run:**
```bash
cd train/task1_splicing_prediction/data_preparation/
jupyter notebook data_prepare.ipynb

cd ../training/
jupyter notebook main.ipynb
```

---

### 3ï¸âƒ£ Task 2: Protein Prediction (`train/task2_protein_prediction/`)

**Goal:** Predict protein properties/functions (TODO/In Progress)

---

### 4ï¸âƒ£ Task 3: Variant Pathogenicity Prediction â­ (`train/task3_variant_prediction/`)

**Goal:** Classify genetic variants as Pathogenic or Benign

**Model Architecture:**
```
Input: DNA & Protein sequences from variants
       â†“
[DNA Seq] â†’ Nucleotide Transformer (NT) â†’ E_dna_ref, E_dna_alt
[Prot Seq] â†’ ESM-2 â†’ E_prot_ref, E_prot_alt
       â†“
Fusion Layer: [E_ref, E_alt, E_alt - E_ref]
       â†“
Concat DNA + Protein embeddings
       â†“
MLP Classifier â†’ Pathogenic (1) / Benign (0)
```

**Pipeline:**

```bash
cd train/task3_variant_prediction/

# 1. Split data by chromosome (chr20/21 â†’ test, rest â†’ train/val)
python split_data.py

# 2. Precompute embeddings (NT + ESM-2)
python precompute_embeddings.py

# 3. Run training with experiment tracking
python train.py

# Or run full pipeline from notebook
jupyter notebook main.ipynb
```

**Key Features:**
- âœ… Multi-modal fusion (DNA + Protein)
- âœ… Automatic experiment tracking (config, results, checkpoints)
- âœ… TensorBoard logging
- âœ… Best model selection
- âœ… Train/Val/Test splits

**View Results:**
```bash
# TensorBoard
tensorboard --logdir=runs/

# Results JSON
cat experiments/experiment_*/results.json
```

---

## ğŸ§  Models & Pre-trained Embeddings

| Model | Purpose | Source | Input Size |
|-------|---------|--------|-----------|
| **Nucleotide Transformer (NT)** | DNA embedding extraction | InstaDeepAI/nucleotide-transformer-500m-human-ref | 601bp |
| **ESM-2** | Protein embedding extraction | facebook/esm2_t33_650M_UR50D | 101aa |
| **Custom MLP Classifier** | Pathogenicity prediction | Fusion model | 1024 (512*2) |

---

## ğŸ“ˆ Data Statistics

### Task 3 (Variant Prediction)
- **Source:** ClinVar variants + mapped sequences
- **Splits:**
  - **Train:** All variants except chr20/21
  - **Val:** 15% of training (stratified)
  - **Test:** chr20, chr21
- **Labels:** Pathogenic (1), Benign (0)
- **Sequence Length:** DNA 601bp, Protein 101aa

---

## ğŸ”§ Configuration

**Main Config File:** [`train/task3_variant_prediction/config.py`](train/task3_variant_prediction/config.py)

```python
# Hyperparameters
LR = 1e-3
EPOCHS = 30
BATCH_SIZE = 128
DROPOUT = 0.2
PATIENCE = 5

# Embeddings
PROJ_DIM = 512
FUSION_HIDDEN = [512, 256]

# Paths
TEST_CHROMS = {"chr20", "chr21"}
VAL_RATIO = 0.15
SEED = 42
```

---

## ğŸ“Š Results & Monitoring

### Experiment Tracking

Each training run saves:
- **args.json:** Command-line arguments
- **config.json:** Configuration parameters
- **config.py:** Copy of config file
- **results.json:** Final metrics (accuracy, precision, recall, F1)
- **tensorboard/:** TensorBoard events

```
experiments/
â”œâ”€â”€ experiment_1/
â”‚   â”œâ”€â”€ args.json
â”‚   â”œâ”€â”€ config.json
â”‚   â”œâ”€â”€ results.json
â”‚   â””â”€â”€ tensorboard/
â””â”€â”€ experiment_N/
    â””â”€â”€ ...
```

### View Results

```bash
# List all experiments
ls train/task3_variant_prediction/experiments/

# View results
cat train/task3_variant_prediction/experiments/experiment_4/results.json
```

---

## ğŸ’¡ Usage Examples

### Inference (New Variants)

```python
import torch
from train.task3_variant_prediction.model import FusionClassifier
from train.task3_variant_prediction.dataset import VariantDataset

# Load trained model
model = FusionClassifier(dna_emb_dim=1024, prot_emb_dim=1024)
model.load_state_dict(torch.load('best_fusion_model.pt'))

# Make predictions
logits = model(dna_embedding, prot_embedding)
predictions = torch.sigmoid(logits)
```

### Add New Dataset

1. Add preprocessing script to `data_processing/`
2. Output parquet format: `[variant_id, sequence_dna, sequence_protein, label, chrom]`
3. Update `config.py` path
4. Run training pipeline

---

## ğŸ“š References

- **ClinVar:** https://www.ncbi.nlm.nih.gov/clinvar/
- **Nucleotide Transformer:** https://github.com/instadeepai/nucleotide-transformer
- **ESM-2:** https://github.com/facebookresearch/protein-folding
- **VEP:** https://www.ensembl.org/info/docs/tools/vep/

---

## ğŸ¤ Contributing

To add features or fix bugs:

1. Create feature branch: `git checkout -b feature/your-feature`
2. Commit changes: `git commit -m "Add your feature"`
3. Push: `git push origin feature/your-feature`
4. Create pull request

---

## ğŸ“ Notes

- All embeddings are precomputed from pre-trained models (not fine-tuned)
- Test set is fixed as chr20/21 for benchmarking
- Experiment tracking is automatic - no manual logging needed
- Stratified train/val split is used to balance classes

---

## ğŸ“ Contact & Support

- **Lab:** AiTA Lab, FPTU
- **Project:** Biosequence Research & Variant Prediction
- **Date:** January 2026

---

**Last Updated:** 2026-01-07
